{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Standard imports"
   ]
  },
  {
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('WebAgg')\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***import ete3 Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree\n",
    "\n",
    "tree_name = \"/home/eecs/khalil.ouardini/cas_scvi_topologies/newick_objects/100cells/high_fitness/topology16.nwk\"\n",
    "tree = Tree(tree_name, 1)\n",
    "\n",
    "#tree = Tree()\n",
    "#tree.populate(30)\n",
    "\n",
    "leaves = tree.get_leaves()\n",
    "\n",
    "for i, n in enumerate(tree.traverse('levelorder')):\n",
    "    n.add_features(index=i)\n",
    "    if not n.is_leaf():\n",
    "        n.name = str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9002. The TBB threading layer is disabled.\u001b[0m\n  warnings.warn(problem)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "from anndata import AnnData\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from external.dataset.tree import TreeDataset, GeneExpressionDataset\n",
    "from external.dataset.ppca import PPCA\n",
    "from external.dataset.anndataset import AnnDatasetFromAnnData\n",
    "\n",
    "# Models\n",
    "import scanpy as sc\n",
    "from external.inference.gaussian_inference import GaussianTrainer\n",
    "from external.inference.gaussian_tree_inference import GaussianTreeTrainer\n",
    "from external.inference.gaussian_tree_inference import GaussianTreePosterior\n",
    "from inference import posterior\n",
    "from external.models.treevae import TreeVAE\n",
    "from external.models.gaussian_vae import GaussianVAE\n",
    "from external.models.gaussian_treevae import GaussianTreeVAE\n",
    "\n",
    "# Utils\n",
    "from external.utils.data_util import get_leaves, get_internal\n",
    "from external.utils.metrics import ks_pvalue, accuracy_imputation, correlations, mse, knn_purity, knn_purity_stratified\n",
    "from external.utils.plots_util import plot_histograms, plot_scatter_mean, plot_ecdf_ks, plot_density, plot_embedding\n",
    "from external.utils.plots_util import plot_losses, plot_elbo, plot_common_ancestor, plot_one_gene, training_dashboard\n",
    "from external.utils.baselines import avg_weighted_baseline, scvi_baseline, scvi_baseline_z, cascvi_baseline_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulations (Gaussian Likelihood model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the latent variables $z \\in \\mathbb{R}^{N \\times D}$ are gaussian (correlated). A phylogenetic tree $\\tau$ (with $N$ nodes) encodes the covariance $\\Sigma$ of $z$. \n",
    "\n",
    "$$\\mathbf{z}=(z_1, ..., z_N) \\sim \\mathcal{N}(0, \\Sigma)$$\n",
    "\n",
    "$z$ is partitionned into two groups:\n",
    "\n",
    "- the leaves $\\mathcal{L} = {1, ..., L}$\n",
    "- the internal nodes $\\mathcal{I} = {L + 1, ..., N}$\n",
    "\n",
    "***\n",
    "\n",
    "***We describe the generative model***:\n",
    "\n",
    "Consider a dataset of $ X={x_n}_{n=1}^{L} $ (also partitioned such that $1, ..., N = \\mathcal{L} \\bigcup \\mathcal{I}$) such that $x_n \\in \\mathbb{R}^{P}$. We aim to represent each $x_n$ under a latent variable $z_n \\in \\mathbb{R}^{D}$ with  with $D << P$ lower dimension. \n",
    "We only observe data at the leaves. the generative model is defined $\\forall n \\in \\mathcal{L}$\n",
    "\n",
    "The set of principal axes $W$ relates the latent variables to the data.\n",
    "\n",
    "The corresponding data point is generated via a projection:\n",
    "\n",
    "$$\n",
    "\\forall n \\in \\mathcal{L}, x_n =  W z_n + e_n\n",
    "$$\n",
    "\n",
    "with $W \\in \\mathbb{R}^{P x D}$ and $e_n \\sim \\mathcal{N}(0, \\sigma^2 I_P)$. Thus:\n",
    "\n",
    "\n",
    "$$\n",
    "\\forall n \\in \\mathcal{L},  x_n | z_n \\sim \\mathcal{N}(W z_n, \\sigma^2 I_P)\n",
    "$$\n",
    "\n",
    "After marginalization\n",
    "\n",
    "$$\n",
    "\\forall n \\in \\mathcal{L}, x_n \\sim \\mathcal{N}(0, W^T W + \\sigma^2 I_P)\n",
    "$$\n",
    "\n",
    "The posterior $p(z_n|x_n)$ for each $n$ is also ***tractable***, indeed\n",
    "\n",
    "$\\begin{pmatrix} x_n \\\\ z_n \\end{pmatrix} = \\begin{pmatrix} W z_n + e \\\\ z_n \\end{pmatrix}$ is a gaussian vector (because for $a \\in \\mathbb{R}$, $b \\in \\mathbb{R}$, $a(W z_n + e) + bz_n$ is still gaussian) such that:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} x_n \\\\ z_n \\end{pmatrix} \\sim \\mathcal{N}(\\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} W^T W + \\sigma^2 I_P  & W\\Sigma_n \\\\ (W\\Sigma_n)^T & \\Sigma_n \\end{pmatrix})\n",
    "$$\n",
    "\n",
    "where $\\Sigma_n$ is the marginalized covariance $\\Sigma$ of $z_n$\n",
    "\n",
    "Therefore we can use the conditioning formula to infer the mean and the covariance of the (gaussian) posterior $p(z_n|x_n)$:\n",
    "\n",
    "$$\n",
    "\\mu_{z_n|x_n} = (W\\Sigma_{n}(W^{T} W + \\sigma^{2} I_{P})^{-1}\\Sigma_{n}^{T}W^{T}) x_{n} \\\\\n",
    "\\Sigma_{z_n|x_n} = \\Sigma_n - W\\Sigma_{n}(W^{T} W + \\sigma^{2} I_{P})^{-1}\\Sigma_{n}^{T}W^{T}\n",
    "$$\n",
    "\n",
    "***\n",
    "\n",
    "***Imputation at internal nodes***\n",
    "\n",
    "Let $j \\in \\mathcal{I}$, and $X_{\\mathcal{L}} = {x_1, ... x_L}$ the set of leaves.\n",
    "We want to infer $p(x_j|X_{\\mathcal{L}})$. If we consider that the data at the internal nodes is \"seen\" and that the generative model is also known $\\forall n \\in \\mathcal{I}$, we could easily (and accurately) compute $p(x_j|X_{\\mathcal{L}})$ by using the gaussian conditioning formula on the gaussian vector:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} x_j \\\\ X_{\\mathcal{L}} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In the case of unseen data at the internal nodes, one can estimate the posterior predictive density:\n",
    "\n",
    "1. $$\n",
    "p(x_j|X_{\\mathcal{L}}) = p(x_j|x_1, ..., x_L) = \\int p(x_j|z_j)p(z_j|z_1,...,z_L)\\prod_{i=1}^{L}p(z_i|x_i)(dz_j,dz_1,...,dz_L)\n",
    "$$\n",
    "\n",
    "Therefore:\n",
    "$$\n",
    "p(x_j|x_1, ..., x_L) \\approx  p(x_j|z_j)p(z_j|z_1,...,z_L)\\prod_{i=1}^{L}p(z_i|x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x_j|x_1, ..., x_L) \\approx  \\mathcal{N}(x_j|Wz_j, \\sigma^2I_P)  \\mathcal{N}(z_j|\\mu_{j|\\mathcal{I}}, \\Sigma_{j|\\mathcal{I}}) \\prod_{i=1}^{L} \\mathcal{N}(z_i|\\mu_{z_i|x_i}, \\Sigma_{z_i|x_i})\n",
    "$$\n",
    "\n",
    "2. $ p(x_j|X_{\\mathcal{L}}) = Wp(z_j|X_{\\mathcal{L}}) + p(e_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n                  /-c148\n               /-|\n              |   \\-c149\n            /-|\n           |  |   /-c198\n         /-|   \\-|\n        |  |      \\-c199\n        |  |\n        |   \\-c11\n        |\n        |         /-c46\n        |        |\n        |        |      /-c62\n        |        |   /-|\n        |      /-|  |   \\-c63\n        |     |  |  |\n        |     |  |  |         /-c138\n        |     |  |  |      /-|\n        |     |  |  |     |   \\-c139\n        |     |   \\-|   /-|\n        |     |     |  |  |      /-c196\n        |     |     |  |  |   /-|\n        |     |     |  |   \\-|   \\-c197\n        |     |     |  |     |\n        |     |     |  |      \\-c167\n        |     |      \\-|\n        |     |        |            /-c176\n        |     |        |         /-|\n        |   /-|        |      /-|   \\-c177\n        |  |  |        |     |  |\n        |  |  |        |   /-|   \\-c141\n        |  |  |        |  |  |\n        |  |  |         \\-|   \\-c123\n        |  |  |           |\n        |  |  |            \\-c101\n        |  |  |\n        |  |  |         /-c54\n        |  |  |      /-|\n        |  |  |     |  |   /-c56\n        |  |  |     |   \\-|\n        |  |  |   /-|      \\-c108\n        |  |  |  |  |\n      /-|  |  |  |  |   /-c132\n     |  |  |   \\-|   \\-|\n     |  |  |     |      \\-c133\n     |  |  |     |\n     |  |  |     |   /-c42\n     |  |  |      \\-|\n     |  |  |         \\-c43\n     |  |  |\n     |  |  |                  /-c180\n     |  |  |               /-|\n     |  |  |              |  |   /-c188\n     |  |  |              |   \\-|\n     |  |  |            /-|      \\-c189\n     |  |  |           |  |\n     |  |  |           |  |   /-c164\n     |  |  |         /-|   \\-|\n     |  |  |        |  |      \\-c165\n     |  |  |      /-|  |\n     |  |  |     |  |   \\-c91\n     |  |  |     |  |\n     |  |  |     |   \\-c39\n     |  |  |     |\n     |  |  |     |   /-c20\n     |  |  |     |  |\n     |  |  |     |  |                     /-c200\n     |  |  |     |  |                  /-|\n     |  |  |     |  |                 |   \\-c201\n     |  |  |     |  |                 |\n     |  |  |     |  |               /-|      /-c190\n     |  |  |     |  |              |  |   /-|\n     |  |  |     |  |              |  |  |   \\-c191\n     |  |  |     |  |              |   \\-|\n     |  |  |     |  |              |     |      /-c202\n     |  |  |     |  |              |     |   /-|\n     |  |  |     |  |              |      \\-|   \\-c203\n     |  |  |   /-|  |              |        |\n     |  |  |  |  |  |            /-|         \\-c195\n     |  |  |  |  |  |           |  |\n     |   \\-|  |  |  |           |  |            /-c156\n     |     |  |  |  |           |  |         /-|\n     |     |  |  |  |           |  |      /-|   \\-c157\n     |     |  |  |  |           |  |     |  |\n     |     |  |  |  |           |  |   /-|   \\-c151\n     |     |  |  |  |           |  |  |  |\n     |     |  |  |  |           |  |  |  |   /-c124\n     |     |  |  |  |           |   \\-|   \\-|\n     |     |  |  |  |         /-|     |      \\-c125\n     |     |  |  |  |        |  |     |\n     |     |  |  |  |        |  |     |   /-c118\n     |     |  |  |  |        |  |      \\-|\n     |     |  |  |  |        |  |         \\-c119\n     |     |  |  |  |        |  |\n     |     |  |  |  |        |  |         /-c158\n     |     |  |   \\-|        |  |      /-|\n     |     |  |     |      /-|  |     |   \\-c159\n     |     |  |     |     |  |  |   /-|\n     |     |  |     |     |  |  |  |  |   /-c170\n     |     |  |     |     |  |   \\-|   \\-|\n     |     |  |     |     |  |     |      \\-c171\n     |     |  |     |     |  |     |\n     |     |  |     |     |  |      \\-c107\n     |     |  |     |     |  |\n     |     |  |     |     |  |   /-c154\n     |     |  |     |     |   \\-|\n     |     |  |     |   /-|     |   /-c208\n     |     |  |     |  |  |      \\-|\n     |     |  |     |  |  |         \\-c209\n     |     |  |     |  |  |\n     |     |  |     |  |  |      /-c102\n     |     |  |     |  |  |   /-|\n     |     |  |     |  |  |  |  |   /-c172\n     |     |  |     |  |  |  |   \\-|\n     |     |  |     |  |  |  |      \\-c173\n     |     |  |     |  |  |  |\n     |     |  |     |  |   \\-|      /-c110\n     |     |  |     |  |     |   /-|\n-- /-|     |  |     |  |     |  |  |   /-c160\n     |     |  |     |  |     |  |   \\-|\n     |     |  |     |  |     |  |     |   /-c206\n     |     |  |     |  |      \\-|      \\-|\n     |     |  |     |  |        |         \\-c207\n     |     |  |     |  |        |\n     |     |  |     |  |        |   /-c204\n     |     |  |     |  |         \\-|\n     |     |  |      \\-|            \\-c205\n     |     |  |        |\n     |     |  |        |      /-c34\n     |     |  |        |     |\n     |     |  |        |     |            /-c174\n     |     |  |        |     |         /-|\n     |     |  |        |   /-|      /-|   \\-c175\n     |      \\-|        |  |  |     |  |\n     |        |        |  |  |   /-|   \\-c169\n     |        |        |  |  |  |  |\n     |        |        |  |   \\-|   \\-c73\n     |        |        |  |     |\n     |        |        |  |     |   /-c52\n     |        |        |  |      \\-|\n     |        |        |  |        |   /-c144\n     |        |        |  |         \\-|\n     |        |        |  |            \\-c145\n     |        |        |  |\n     |        |        |  |            /-c126\n     |        |        |  |         /-|\n     |        |        |  |      /-|   \\-c127\n     |        |         \\-|     |  |\n     |        |           |     |   \\-c105\n     |        |           |     |\n     |        |           |     |      /-c142\n     |        |           |   /-|   /-|\n     |        |           |  |  |  |   \\-c143\n     |        |           |  |  |  |\n     |        |           |  |  |  |            /-c186\n     |        |           |  |  |  |         /-|\n     |        |           |  |  |  |      /-|   \\-c187\n     |        |           |  |   \\-|     |  |\n     |        |           |  |     |   /-|   \\-c117\n     |        |           |  |     |  |  |\n     |        |           |  |     |  |   \\-c77\n     |        |           |  |     |  |\n     |        |           |  |     |  |            /-c134\n     |        |            \\-|      \\-|         /-|\n     |        |              |        |      /-|   \\-c135\n     |        |              |        |     |  |\n     |        |              |        |   /-|   \\-c113\n     |        |              |        |  |  |\n     |        |              |         \\-|   \\-c89\n     |        |              |           |\n     |        |              |           |   /-c130\n     |        |              |            \\-|\n     |        |              |               \\-c131\n     |        |              |\n     |        |              |   /-c80\n     |        |              |  |\n     |        |               \\-|   /-c96\n     |        |                 |  |\n     |        |                  \\-|      /-c162\n     |        |                    |   /-|\n     |        |                    |  |  |   /-c192\n     |        |                     \\-|   \\-|\n     |        |                       |      \\-c193\n     |        |                       |\n     |        |                        \\-c147\n     |        |\n     |        |      /-c178\n     |        |   /-|\n     |        |  |  |   /-c184\n     |         \\-|   \\-|\n     |           |      \\-c185\n     |           |\n     |            \\-c137\n     |\n     |   /-c24\n      \\-|\n        |   /-c60\n         \\-|\n            \\-c61\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  },
  {
   "source": [
    "***Branch Length***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-3\n",
    "branch_length = {}\n",
    "for node in tree.traverse('levelorder'):\n",
    "    if node.name == '0':\n",
    "        branch_length[node.name] = 1.0\n",
    "        continue\n",
    "    branch_length[node.name] = node.dist\n",
    "branch_length['prior_root'] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f65d2c383f0>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "import torch\n",
    "    \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5\n",
    "p = 100\n",
    "vis = True\n",
    "leaves_only = False\n",
    "var = 1.0\n",
    "sigma_scale = 1.0\n",
    "\n",
    "#ppca = PPCA(tree, p, d, vis, leaves_only, var, sigma_scale)\n",
    "ppca = PPCA(tree=tree, \n",
    "            dim=p, \n",
    "            latent=d, \n",
    "            vis=vis, \n",
    "            only=leaves_only,\n",
    "            branch_length=branch_length, \n",
    "            sigma_scale=sigma_scale\n",
    "            )\n",
    "\n",
    "ppca.simulate_latent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Marginalization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "ppca.simulate_normal()\n",
    "ppca.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Log-Likelihood of the tree -30893.548139778148\nLogLikelihood of the leaves -15440.49366990377\n"
     ]
    }
   ],
   "source": [
    "lik_tree = ppca.likelihood_obs(leaves_only=False)\n",
    "lik_leaves = ppca.likelihood_obs(leaves_only=True)\n",
    "\n",
    "print(\"Log-Likelihood of the tree {}\".format(lik_tree))\n",
    "print(\"LogLikelihood of the leaves {}\".format(lik_leaves))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100, 100), (100, 100), (100, 100), (100, 100), (100, 5))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Latent vectors\n",
    "leaves_z, _, _ = get_leaves(ppca.z, ppca.mu, tree)\n",
    "\n",
    "#FIXED training set\n",
    "leaves_X, leaves_idx, mu = get_leaves(ppca.X, ppca.mu, tree)\n",
    "\n",
    "# internal nodes data (for imputation)\n",
    "internal_X, internal_idx, internal_mu = get_internal(ppca.X, ppca.mu, tree)\n",
    "\n",
    "# internal nodes z\n",
    "internal_z, _, _ = get_internal(ppca.z, ppca.mu, tree)\n",
    "\n",
    "leaves_X.shape, mu.shape, internal_X.shape, internal_mu.shape, leaves_z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Posterior Distributions***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***evidence***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "evidence_leaves = ppca.get_evidence_leaves_levelorder(X=ppca.X, dim=ppca.dim)\n",
    "evidence_leaves.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Leaves covariance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppca.compute_leaves_covariance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Posterior mean and covariance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean, posterior_cov = ppca.compute_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Posterior predictive density***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_mean, predictive_cov = ppca.compute_posterior_predictive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary: Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1: Unweighted Average of gene expression in Clade\n",
    "\n",
    "The simple idea here is to impute the value of an internal node, with the (un)weighted average of the gene expression values of the leaves, taking the query internal node as the root of the subtree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_avg = avg_weighted_baseline(tree=tree, \n",
    "                                    weighted=False, \n",
    "                                    X=ppca.X,\n",
    "                                    rounding=False\n",
    "                                   )\n",
    "\n",
    "#get internal nodes\n",
    "avg_X = np.array([x for x in imputed_avg.values()]).reshape(-1, ppca.X.shape[1])\n",
    "internal_avg_X, _, _ = get_internal(avg_X, ppca.mu, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2: (groundtruth) posterior predictive density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: covariance is not positive-semidefinite.\n  \n"
     ]
    }
   ],
   "source": [
    "imputed_ppca = {}\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        samples = np.array([np.random.multivariate_normal(mean=predictive_mean[n.name],\n",
    "                                                            cov=predictive_cov[n.name])\n",
    "                           for i in range(20)])\n",
    "        imputed_ppca[n.name] = np.mean(samples, axis=0)\n",
    "\n",
    "internal_ppca_X = np.array([x for x in imputed_ppca.values()]).reshape(-1, ppca.X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 3: Approximation through Message Passing (Oracle)\n",
    "\n",
    "\n",
    "i.e, \n",
    "\n",
    "1. sample from $z_1, ..., z_n \\sim p(z_1, ..., z_n|x_1, ..., x_n)$ (conditionning formula)\n",
    "2. impute $z_i \\sim p(z_i | z_1, ..., z_n)$ (Message Passing)\n",
    "3. Decode $p(x_i|z_i) = W z_i + \\sigma^2 I_P$ (Generative model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean_corr, posterior_cov_corr = ppca.compute_correlated_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external/dataset/ppca.py:357: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  cov=posterior_cov).reshape(-1, self.latent) for i in range(sample_size)])\n",
      "go\n",
      "[2021-05-03 21:45:53,285] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-03 21:45:53,286] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-03 21:45:53,287] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-03 21:45:53,294] INFO - scvi.dataset.dataset | Merging datasets. Input objects are modified in place.\n",
      "[2021-05-03 21:45:53,294] INFO - scvi.dataset.dataset | Gene names and cell measurement names are assumed to have a non-null intersection between datasets.\n",
      "[2021-05-03 21:45:53,295] INFO - scvi.dataset.dataset | Keeping 100 genes\n",
      "[2021-05-03 21:45:53,296] WARNING - scvi.dataset.dataset | X contains continuous and/or negative values. Please use raw UMI/read counts with scVI\n",
      "[2021-05-03 21:45:53,296] INFO - scvi.dataset.dataset | Computing the library size for the new data\n",
      "[2021-05-03 21:45:53,298] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-03 21:45:53,298] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-03 21:45:53,299] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-03 21:45:53,300] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-03 21:45:53,301] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-03 21:45:53,301] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-03 21:45:53,303] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n"
     ]
    }
   ],
   "source": [
    "imputed_mp, imputed_z_mp = ppca.compute_approx_posterior_predictive(iid=False, use_MP=True, sample_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_X = np.array([x for x in imputed_mp.values()]).reshape(-1, ppca.X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 4: Approximation through Message Passing + iid posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e, \n",
    "\n",
    "1. sample from marginal conditional $z_l \\sim p(z_l|x_1) \\forall l \\in (1, ...,L)$ (conditionning formula)\n",
    "2. impute $z_i \\sim p(z_i | z_1, ..., z_n)$ (Message Passing)\n",
    "3. Decode $p(x_i|z_i) = W z_i + \\sigma^2 I_P$ (Generative model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external/dataset/ppca.py:364: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  cov=posterior_cov[k]) for i in range(sample_size)])\n",
      "go\n",
      "[2021-05-03 21:46:14,398] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-03 21:46:14,400] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-03 21:46:14,401] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-03 21:46:14,407] INFO - scvi.dataset.dataset | Merging datasets. Input objects are modified in place.\n",
      "[2021-05-03 21:46:14,408] INFO - scvi.dataset.dataset | Gene names and cell measurement names are assumed to have a non-null intersection between datasets.\n",
      "[2021-05-03 21:46:14,409] INFO - scvi.dataset.dataset | Keeping 100 genes\n",
      "[2021-05-03 21:46:14,412] WARNING - scvi.dataset.dataset | X contains continuous and/or negative values. Please use raw UMI/read counts with scVI\n",
      "[2021-05-03 21:46:14,412] INFO - scvi.dataset.dataset | Computing the library size for the new data\n",
      "[2021-05-03 21:46:14,414] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-03 21:46:14,415] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-03 21:46:14,416] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-03 21:46:14,419] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-03 21:46:14,419] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-03 21:46:14,420] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-03 21:46:14,422] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n"
     ]
    }
   ],
   "source": [
    "imputed_mp2, imputed_z_mp2 = ppca.compute_approx_posterior_predictive(iid=True, use_MP=True, sample_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_X2 = np.array([x for x in imputed_mp2.values()]).reshape(-1, ppca.X.shape[1])"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 5: Gaussian VAE decoded averaged latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2021-05-03 21:46:26,478] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-03 21:46:26,480] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-03 21:46:26,481] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n"
     ]
    }
   ],
   "source": [
    "# anndata\n",
    "gene_dataset = GeneExpressionDataset()\n",
    "gene_dataset.populate_from_data(leaves_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "\n",
    "vae = GaussianVAE(gene_dataset.nb_genes,\n",
    "                  n_hidden=64,\n",
    "                  n_layers=1,\n",
    "                  n_latent=ppca.latent,\n",
    "                  sigma_ldvae=None\n",
    "              )\n",
    "\n",
    "#new_weight = torch.from_numpy(ppca.W).float()\n",
    "\n",
    "#with torch.no_grad():\n",
    "    #vae.decoder.factor_regressor.fc_layers[0][0].weight = torch.nn.Parameter(new_weight)\n",
    "    \n",
    "#for param in vae.decoder.factor_regressor.fc_layers[0][0].parameters():\n",
    "    #param.requires_grad = False\n",
    "    \n",
    "#vae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance is 4.236195116252171\n"
     ]
    }
   ],
   "source": [
    "p_m, p_v = vae.decoder.forward(torch.from_numpy(leaves_z).float())\n",
    "p_m = p_m.detach().numpy()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(p_m, mu)\n",
    "print(\"the distance is {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "\n",
    "trainer = GaussianTrainer(model=vae,\n",
    "                          gene_dataset=gene_dataset,\n",
    "                          train_size=1.0,\n",
    "                          use_cuda=use_cuda,\n",
    "                          frequency=10,\n",
    "                          n_epochs_kl_warmup=None,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "computing elbo\n",
      "ELBO: 36955.26953125\n",
      "computing elbo\n",
      "ELBO: 36971.0234375\n",
      "computing elbo\n",
      "ELBO: 36961.27734375\n",
      "training:   1%|▏         | 7/500 [00:00<00:07, 64.87it/s]computing elbo\n",
      "ELBO: 28474.59375\n",
      "computing elbo\n",
      "ELBO: 28790.3671875\n",
      "computing elbo\n",
      "ELBO: 28929.29296875\n",
      "training:   4%|▍         | 19/500 [00:00<00:05, 93.02it/s]computing elbo\n",
      "ELBO: 30706.1484375\n",
      "computing elbo\n",
      "ELBO: 32072.056640625\n",
      "computing elbo\n",
      "ELBO: 31596.259765625\n",
      "computing elbo\n",
      "ELBO: 29247.15625\n",
      "computing elbo\n",
      "ELBO: 29418.73046875\n",
      "computing elbo\n",
      "ELBO: 29420.63671875\n",
      "training:   6%|▌         | 30/500 [00:00<00:04, 98.17it/s]computing elbo\n",
      "ELBO: 25250.009765625\n",
      "computing elbo\n",
      "ELBO: 25239.40625\n",
      "computing elbo\n",
      "ELBO: 25224.63671875\n",
      "training:   8%|▊         | 42/500 [00:00<00:04, 104.44it/s]computing elbo\n",
      "ELBO: 24048.978515625\n",
      "computing elbo\n",
      "ELBO: 24010.6796875\n",
      "computing elbo\n",
      "ELBO: 23955.333984375\n",
      "training:  11%|█         | 54/500 [00:00<00:04, 107.95it/s]computing elbo\n",
      "ELBO: 22088.640625\n",
      "computing elbo\n",
      "ELBO: 22089.984375\n",
      "computing elbo\n",
      "ELBO: 22081.81640625\n",
      "training:  13%|█▎        | 66/500 [00:00<00:03, 110.09it/s]computing elbo\n",
      "ELBO: 20305.67578125\n",
      "computing elbo\n",
      "ELBO: 20257.208984375\n",
      "computing elbo\n",
      "ELBO: 20308.240234375\n",
      "training:  16%|█▌        | 78/500 [00:00<00:03, 111.41it/s]computing elbo\n",
      "ELBO: 17588.244140625\n",
      "computing elbo\n",
      "ELBO: 17555.8359375\n",
      "computing elbo\n",
      "ELBO: 17589.59375\n",
      "computing elbo\n",
      "ELBO: 17713.294921875\n",
      "computing elbo\n",
      "ELBO: 17697.27734375\n",
      "computing elbo\n",
      "ELBO: 17780.9453125\n",
      "training:  18%|█▊        | 90/500 [00:00<00:03, 109.58it/s]computing elbo\n",
      "ELBO: 17125.6953125\n",
      "computing elbo\n",
      "ELBO: 17025.5234375\n",
      "computing elbo\n",
      "ELBO: 17053.140625\n",
      "training:  20%|██        | 102/500 [00:00<00:03, 110.73it/s]computing elbo\n",
      "ELBO: 16149.9287109375\n",
      "computing elbo\n",
      "ELBO: 16172.2119140625\n",
      "computing elbo\n",
      "ELBO: 16126.689453125\n",
      "training:  23%|██▎       | 114/500 [00:01<00:03, 111.62it/s]computing elbo\n",
      "ELBO: 16551.92578125\n",
      "computing elbo\n",
      "ELBO: 16421.41796875\n",
      "computing elbo\n",
      "ELBO: 16497.36328125\n",
      "training:  25%|██▌       | 126/500 [00:01<00:03, 112.11it/s]computing elbo\n",
      "ELBO: 16105.658203125\n",
      "computing elbo\n",
      "ELBO: 15985.2099609375\n",
      "computing elbo\n",
      "ELBO: 16096.724609375\n",
      "training:  28%|██▊       | 138/500 [00:01<00:03, 112.36it/s]computing elbo\n",
      "ELBO: 15627.1328125\n",
      "computing elbo\n",
      "ELBO: 15514.1328125\n",
      "computing elbo\n",
      "ELBO: 15566.0810546875\n",
      "computing elbo\n",
      "ELBO: 15354.9765625\n",
      "computing elbo\n",
      "ELBO: 15357.697265625\n",
      "computing elbo\n",
      "ELBO: 15252.9765625\n",
      "training:  30%|███       | 150/500 [00:01<00:03, 110.37it/s]computing elbo\n",
      "ELBO: 15461.4736328125\n",
      "computing elbo\n",
      "ELBO: 15364.251953125\n",
      "computing elbo\n",
      "ELBO: 15522.2353515625\n",
      "training:  32%|███▏      | 162/500 [00:01<00:03, 111.64it/s]computing elbo\n",
      "ELBO: 14573.1640625\n",
      "computing elbo\n",
      "ELBO: 14588.9658203125\n",
      "computing elbo\n",
      "ELBO: 14472.8408203125\n",
      "training:  35%|███▍      | 174/500 [00:01<00:02, 112.40it/s]computing elbo\n",
      "ELBO: 14550.3828125\n",
      "computing elbo\n",
      "ELBO: 14412.431640625\n",
      "computing elbo\n",
      "ELBO: 14383.34765625\n",
      "training:  37%|███▋      | 186/500 [00:01<00:02, 112.84it/s]computing elbo\n",
      "ELBO: 14057.3583984375\n",
      "computing elbo\n",
      "ELBO: 14053.2138671875\n",
      "computing elbo\n",
      "ELBO: 14003.466796875\n",
      "training:  40%|███▉      | 198/500 [00:01<00:02, 112.85it/s]computing elbo\n",
      "ELBO: 14412.693359375\n",
      "computing elbo\n",
      "ELBO: 14340.552734375\n",
      "computing elbo\n",
      "ELBO: 14468.8115234375\n",
      "computing elbo\n",
      "ELBO: 14493.4755859375\n",
      "computing elbo\n",
      "ELBO: 14424.41015625\n",
      "computing elbo\n",
      "ELBO: 14368.017578125\n",
      "training:  42%|████▏     | 210/500 [00:01<00:02, 110.62it/s]computing elbo\n",
      "ELBO: 14224.9140625\n",
      "computing elbo\n",
      "ELBO: 14257.2998046875\n",
      "computing elbo\n",
      "ELBO: 14310.9775390625\n",
      "training:  44%|████▍     | 222/500 [00:02<00:02, 111.80it/s]computing elbo\n",
      "ELBO: 14416.255859375\n",
      "computing elbo\n",
      "ELBO: 14681.248046875\n",
      "computing elbo\n",
      "ELBO: 14569.30859375\n",
      "training:  47%|████▋     | 234/500 [00:02<00:02, 112.76it/s]computing elbo\n",
      "ELBO: 14069.1484375\n",
      "computing elbo\n",
      "ELBO: 14047.7373046875\n",
      "computing elbo\n",
      "ELBO: 14076.90625\n",
      "training:  49%|████▉     | 246/500 [00:02<00:02, 113.48it/s]computing elbo\n",
      "ELBO: 14068.5380859375\n",
      "computing elbo\n",
      "ELBO: 14169.1611328125\n",
      "computing elbo\n",
      "ELBO: 14189.154296875\n",
      "training:  52%|█████▏    | 258/500 [00:02<00:02, 113.93it/s]computing elbo\n",
      "ELBO: 13623.4482421875\n",
      "computing elbo\n",
      "ELBO: 13581.248046875\n",
      "computing elbo\n",
      "ELBO: 13651.283203125\n",
      "computing elbo\n",
      "ELBO: 13382.37890625\n",
      "computing elbo\n",
      "ELBO: 13439.515625\n",
      "computing elbo\n",
      "ELBO: 13368.6337890625\n",
      "training:  54%|█████▍    | 270/500 [00:02<00:02, 110.80it/s]computing elbo\n",
      "ELBO: 13728.875\n",
      "computing elbo\n",
      "ELBO: 13805.1455078125\n",
      "computing elbo\n",
      "ELBO: 13695.904296875\n",
      "training:  57%|█████▋    | 284/500 [00:02<00:01, 117.68it/s]computing elbo\n",
      "ELBO: 13529.185546875\n",
      "computing elbo\n",
      "ELBO: 13476.6318359375\n",
      "computing elbo\n",
      "ELBO: 13568.8994140625\n",
      "training:  60%|█████▉    | 298/500 [00:02<00:01, 122.36it/s]computing elbo\n",
      "ELBO: 13177.728515625\n",
      "computing elbo\n",
      "ELBO: 13159.1689453125\n",
      "computing elbo\n",
      "ELBO: 13199.435546875\n",
      "computing elbo\n",
      "ELBO: 12782.55859375\n",
      "computing elbo\n",
      "ELBO: 12751.64453125\n",
      "computing elbo\n",
      "ELBO: 12586.1826171875\n",
      "training:  62%|██████▏   | 311/500 [00:02<00:01, 122.43it/s]computing elbo\n",
      "ELBO: 12600.068359375\n",
      "computing elbo\n",
      "ELBO: 12603.8642578125\n",
      "computing elbo\n",
      "ELBO: 12588.7509765625\n",
      "training:  65%|██████▌   | 325/500 [00:02<00:01, 125.94it/s]computing elbo\n",
      "ELBO: 12111.189453125\n",
      "computing elbo\n",
      "ELBO: 12048.197265625\n",
      "computing elbo\n",
      "ELBO: 12143.9423828125\n",
      "training:  68%|██████▊   | 339/500 [00:02<00:01, 127.71it/s]computing elbo\n",
      "ELBO: 11850.919921875\n",
      "computing elbo\n",
      "ELBO: 11971.0458984375\n",
      "computing elbo\n",
      "ELBO: 11881.578125\n",
      "computing elbo\n",
      "ELBO: 12204.69921875\n",
      "computing elbo\n",
      "ELBO: 12301.875\n",
      "computing elbo\n",
      "ELBO: 12343.208984375\n",
      "training:  70%|███████   | 352/500 [00:03<00:01, 127.21it/s]computing elbo\n",
      "ELBO: 12387.025390625\n",
      "computing elbo\n",
      "ELBO: 12477.9296875\n",
      "computing elbo\n",
      "ELBO: 12352.279296875\n",
      "training:  73%|███████▎  | 366/500 [00:03<00:01, 130.48it/s]computing elbo\n",
      "ELBO: 12228.8955078125\n",
      "computing elbo\n",
      "ELBO: 12280.1298828125\n",
      "computing elbo\n",
      "ELBO: 12297.587890625\n",
      "computing elbo\n",
      "ELBO: 11892.4052734375\n",
      "computing elbo\n",
      "ELBO: 11953.634765625\n",
      "computing elbo\n",
      "ELBO: 11975.0859375\n",
      "training:  76%|███████▌  | 380/500 [00:03<00:00, 126.92it/s]computing elbo\n",
      "ELBO: 12612.6259765625\n",
      "computing elbo\n",
      "ELBO: 12677.7705078125\n",
      "computing elbo\n",
      "ELBO: 12614.66015625\n",
      "training:  79%|███████▊  | 393/500 [00:03<00:00, 122.65it/s]computing elbo\n",
      "ELBO: 11808.6630859375\n",
      "computing elbo\n",
      "ELBO: 11893.9365234375\n",
      "computing elbo\n",
      "ELBO: 11846.4130859375\n",
      "training:  81%|████████  | 406/500 [00:03<00:00, 120.16it/s]computing elbo\n",
      "ELBO: 12829.02734375\n",
      "computing elbo\n",
      "ELBO: 12689.4921875\n",
      "computing elbo\n",
      "ELBO: 12692.51171875\n",
      "training:  84%|████████▍ | 419/500 [00:03<00:00, 118.47it/s]computing elbo\n",
      "ELBO: 12380.3955078125\n",
      "computing elbo\n",
      "ELBO: 12577.5\n",
      "computing elbo\n",
      "ELBO: 12522.82421875\n",
      "computing elbo\n",
      "ELBO: 12013.94921875\n",
      "computing elbo\n",
      "ELBO: 12088.302734375\n",
      "computing elbo\n",
      "ELBO: 12159.841796875\n",
      "training:  86%|████████▌ | 431/500 [00:03<00:00, 114.91it/s]computing elbo\n",
      "ELBO: 11770.68359375\n",
      "computing elbo\n",
      "ELBO: 11640.9052734375\n",
      "computing elbo\n",
      "ELBO: 12009.4228515625\n",
      "training:  89%|████████▊ | 443/500 [00:03<00:00, 114.56it/s]computing elbo\n",
      "ELBO: 12003.9775390625\n",
      "computing elbo\n",
      "ELBO: 12108.1630859375\n",
      "computing elbo\n",
      "ELBO: 12030.5224609375\n",
      "training:  91%|█████████ | 455/500 [00:03<00:00, 114.47it/s]computing elbo\n",
      "ELBO: 11474.82421875\n",
      "computing elbo\n",
      "ELBO: 11560.57421875\n",
      "computing elbo\n",
      "ELBO: 11580.650390625\n",
      "training:  93%|█████████▎| 467/500 [00:04<00:00, 114.30it/s]computing elbo\n",
      "ELBO: 11778.671875\n",
      "computing elbo\n",
      "ELBO: 11785.7802734375\n",
      "computing elbo\n",
      "ELBO: 11832.0751953125\n",
      "training:  96%|█████████▌| 479/500 [00:04<00:00, 114.26it/s]computing elbo\n",
      "ELBO: 11807.4267578125\n",
      "computing elbo\n",
      "ELBO: 11939.5615234375\n",
      "computing elbo\n",
      "ELBO: 12084.0244140625\n",
      "computing elbo\n",
      "ELBO: 11896.58984375\n",
      "computing elbo\n",
      "ELBO: 11591.814453125\n",
      "computing elbo\n",
      "ELBO: 11794.666015625\n",
      "training:  98%|█████████▊| 491/500 [00:04<00:00, 111.84it/s]computing elbo\n",
      "ELBO: 11261.7216796875\n",
      "computing elbo\n",
      "ELBO: 11147.556640625\n",
      "computing elbo\n",
      "ELBO: 11208.3017578125\n",
      "training: 100%|██████████| 500/500 [00:04<00:00, 114.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# train VAE\n",
    "trainer.train(n_epochs=n_epochs, lr=1e-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbo_train = trainer.history[\"elbo_train_set\"]\n",
    "x = np.linspace(0, 100, (len(elbo_train)))\n",
    "plt.plot(np.log(elbo_train), \n",
    "         label=\"train\", color='blue',\n",
    "         linestyle=':',\n",
    "         linewidth=3\n",
    "        )\n",
    "        \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.legend()\n",
    "plt.title(\"Train history Gaussian VAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.4091782390417955"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "posterior =  trainer.create_posterior(model=vae,\n",
    "                                      gene_dataset=gene_dataset\n",
    "                                      )\n",
    "latent = posterior.get_latent()\n",
    "mean_squared_error(latent, leaves_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "imputed_avg_vae, _ = scvi_baseline_z(tree=tree,\n",
    "                                 model=vae,\n",
    "                                 posterior=posterior,\n",
    "                                 weighted=False,\n",
    "                                 n_samples_z=1,\n",
    "                                 gaussian=True\n",
    "                                )\n",
    "\n",
    "internal_vae_X = np.array([x for x in imputed_avg_vae.values()]).reshape(-1, ppca.X.shape[1])\n",
    "internal_vae_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Our Model: CascVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "go\n",
      "[2021-05-03 21:46:31,786] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-03 21:46:31,788] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-03 21:46:31,788] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-03 21:46:31,798] INFO - scvi.dataset.dataset | Merging datasets. Input objects are modified in place.\n",
      "[2021-05-03 21:46:31,799] INFO - scvi.dataset.dataset | Gene names and cell measurement names are assumed to have a non-null intersection between datasets.\n",
      "[2021-05-03 21:46:31,801] INFO - scvi.dataset.dataset | Keeping 100 genes\n",
      "[2021-05-03 21:46:31,802] WARNING - scvi.dataset.dataset | X contains continuous and/or negative values. Please use raw UMI/read counts with scVI\n",
      "[2021-05-03 21:46:31,803] INFO - scvi.dataset.dataset | Computing the library size for the new data\n",
      "[2021-05-03 21:46:31,804] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-03 21:46:31,805] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-03 21:46:31,806] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-03 21:46:31,808] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-03 21:46:31,809] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-03 21:46:31,810] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-03 21:46:31,814] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GeneExpressionDataset object with n_cells x nb_genes = 100 x 100\n",
       "    gene_attribute_names: 'gene_names'\n",
       "    cell_attribute_names: 'batch_indices', 'barcodes', 'local_means', 'local_vars', 'labels'\n",
       "    cell_categorical_attribute_names: 'labels', 'batch_indices'"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "adata = AnnData(leaves_X)\n",
    "adata.obs_names = [n.name for n in tree.traverse('levelorder') if n.is_leaf()]\n",
    "scvi_dataset = AnnDatasetFromAnnData(adata, filtering=False)\n",
    "scvi_dataset.initialize_cell_attribute('barcodes', adata.obs_names)\n",
    "\n",
    "#TreeDataset\n",
    "cas_dataset = TreeDataset(scvi_dataset, tree=tree, filtering=False)\n",
    "cas_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "use_MP = True\n",
    "\n",
    "treevae = GaussianTreeVAE(cas_dataset.nb_genes,\n",
    "              tree = cas_dataset.tree,\n",
    "              n_latent=ppca.latent,\n",
    "              n_hidden=64,\n",
    "              n_layers=1,\n",
    "              prior_t = branch_length,\n",
    "              use_MP=use_MP,\n",
    "              sigma_ldvae=None\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Freezing the decoder***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_weight = torch.from_numpy(ppca.W).float()\n",
    "\n",
    "#with torch.no_grad():\n",
    "    #treevae.decoder.factor_regressor.fc_layers[0][0].weight = torch.nn.Parameter(new_weight)\n",
    "    \n",
    "#for param in treevae.decoder.factor_regressor.fc_layers[0][0].parameters():\n",
    "    #param.requires_grad = False\n",
    "    \n",
    "#treevae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert(treevae.decoder.factor_regressor.fc_layers[0][0].weight.numpy().all() == ppca.W.T.all())"
   ]
  },
  {
   "source": [
    "\n",
    "***Are we able to generate the gene expression data by decoding the simulated latent space?***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_m, p_v = treevae.decoder.forward(torch.from_numpy(leaves_z).float())\n",
    "#p_m = p_m.detach().numpy()\n",
    "#p_m.shape, mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse = mean_squared_error(p_m, mu)\n",
    "#print(\"the distance is {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Training***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_leaves:  [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99]]\ntest_leaves:  []\nvalidation leaves:  []\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "lr = 1e-2\n",
    "lambda_ = 1.0\n",
    "freq = 10\n",
    "\n",
    "tree_trainer = GaussianTreeTrainer(\n",
    "        model = treevae,\n",
    "        gene_dataset = cas_dataset,\n",
    "        lambda_ = lambda_,\n",
    "        train_size=1.0,\n",
    "        test_size=0,\n",
    "        use_cuda=use_cuda,\n",
    "        frequency=freq,\n",
    "        n_epochs_kl_warmup=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "computing elbo\n",
      "training:   2%|▏         | 9/500 [00:00<00:17, 27.93it/s]computing elbo\n",
      "training:   4%|▎         | 18/500 [00:00<00:16, 28.37it/s]computing elbo\n",
      "training:   5%|▌         | 27/500 [00:00<00:16, 28.16it/s]computing elbo\n",
      "training:   8%|▊         | 39/500 [00:01<00:16, 28.40it/s]computing elbo\n",
      "training:  10%|▉         | 48/500 [00:01<00:18, 24.92it/s]computing elbo\n",
      "training:  11%|█▏        | 57/500 [00:02<00:19, 23.19it/s]computing elbo\n",
      "training:  14%|█▍        | 69/500 [00:02<00:18, 23.21it/s]computing elbo\n",
      "training:  16%|█▌        | 78/500 [00:03<00:18, 22.73it/s]computing elbo\n",
      "training:  17%|█▋        | 87/500 [00:03<00:17, 22.97it/s]computing elbo\n",
      "training:  20%|█▉        | 99/500 [00:04<00:17, 23.27it/s]computing elbo\n",
      "training:  22%|██▏       | 108/500 [00:04<00:17, 22.94it/s]computing elbo\n",
      "training:  23%|██▎       | 117/500 [00:04<00:16, 22.90it/s]computing elbo\n",
      "training:  26%|██▌       | 129/500 [00:05<00:15, 23.21it/s]computing elbo\n",
      "training:  28%|██▊       | 138/500 [00:05<00:15, 22.78it/s]computing elbo\n",
      "training:  29%|██▉       | 147/500 [00:06<00:15, 22.97it/s]computing elbo\n",
      "training:  32%|███▏      | 159/500 [00:06<00:14, 23.06it/s]computing elbo\n",
      "training:  34%|███▎      | 168/500 [00:07<00:14, 22.90it/s]computing elbo\n",
      "training:  35%|███▌      | 177/500 [00:07<00:14, 22.92it/s]computing elbo\n",
      "training:  38%|███▊      | 189/500 [00:08<00:13, 23.12it/s]computing elbo\n",
      "training:  40%|███▉      | 198/500 [00:08<00:13, 23.00it/s]computing elbo\n",
      "training:  41%|████▏     | 207/500 [00:08<00:12, 22.93it/s]computing elbo\n",
      "training:  44%|████▍     | 219/500 [00:09<00:12, 23.28it/s]computing elbo\n",
      "training:  46%|████▌     | 228/500 [00:09<00:11, 23.07it/s]computing elbo\n",
      "training:  47%|████▋     | 237/500 [00:10<00:11, 23.06it/s]computing elbo\n",
      "training:  50%|████▉     | 249/500 [00:10<00:10, 23.21it/s]computing elbo\n",
      "training:  52%|█████▏    | 258/500 [00:11<00:10, 22.87it/s]computing elbo\n",
      "training:  53%|█████▎    | 267/500 [00:11<00:10, 22.94it/s]computing elbo\n",
      "training:  56%|█████▌    | 279/500 [00:12<00:10, 21.76it/s]computing elbo\n",
      "training:  58%|█████▊    | 288/500 [00:12<00:09, 22.52it/s]computing elbo\n",
      "training:  59%|█████▉    | 297/500 [00:12<00:08, 22.73it/s]computing elbo\n",
      "training:  62%|██████▏   | 309/500 [00:13<00:08, 22.92it/s]computing elbo\n",
      "training:  64%|██████▎   | 318/500 [00:13<00:07, 22.95it/s]computing elbo\n",
      "training:  65%|██████▌   | 327/500 [00:14<00:07, 22.78it/s]computing elbo\n",
      "training:  68%|██████▊   | 339/500 [00:14<00:06, 23.10it/s]computing elbo\n",
      "training:  70%|██████▉   | 348/500 [00:15<00:06, 23.03it/s]computing elbo\n",
      "training:  71%|███████▏  | 357/500 [00:15<00:06, 23.01it/s]computing elbo\n",
      "training:  74%|███████▍  | 369/500 [00:16<00:05, 23.31it/s]computing elbo\n",
      "training:  76%|███████▌  | 378/500 [00:16<00:05, 23.10it/s]computing elbo\n",
      "training:  77%|███████▋  | 387/500 [00:16<00:04, 23.05it/s]computing elbo\n",
      "training:  80%|███████▉  | 399/500 [00:17<00:04, 23.31it/s]computing elbo\n",
      "training:  82%|████████▏ | 408/500 [00:17<00:04, 21.73it/s]computing elbo\n",
      "training:  83%|████████▎ | 417/500 [00:18<00:03, 22.47it/s]computing elbo\n",
      "training:  86%|████████▌ | 429/500 [00:18<00:03, 23.04it/s]computing elbo\n",
      "training:  88%|████████▊ | 438/500 [00:19<00:02, 23.01it/s]computing elbo\n",
      "training:  89%|████████▉ | 447/500 [00:19<00:02, 22.87it/s]computing elbo\n",
      "training:  92%|█████████▏| 459/500 [00:20<00:01, 20.82it/s]computing elbo\n",
      "training:  94%|█████████▎| 468/500 [00:20<00:01, 23.89it/s]computing elbo\n",
      "training:  95%|█████████▌| 477/500 [00:20<00:00, 26.68it/s]computing elbo\n",
      "training:  97%|█████████▋| 487/500 [00:21<00:00, 28.27it/s]computing elbo\n",
      "training: 100%|█████████▉| 499/500 [00:21<00:00, 28.66it/s]computing elbo\n",
      "training: 100%|██████████| 500/500 [00:21<00:00, 23.14it/s]\n"
     ]
    }
   ],
   "source": [
    "tree_trainer.train(n_epochs=n_epochs,\n",
    "              lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dashboard(tree_trainer, treevae.encoder_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100, 5), (100, 5))"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "tree_posterior = tree_trainer.create_posterior(model=treevae,\n",
    "                                              gene_dataset=cas_dataset,\n",
    "                                               clades=tree_trainer.clades,\n",
    "                                               indices=np.arange(len(cas_dataset))\n",
    "                                              )\n",
    "tree_latent = tree_posterior.get_latent()\n",
    "tree_latent.shape, internal_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.264154237669033"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "tree_latent = tree_posterior.get_latent()\n",
    "mean_squared_error(tree_latent, leaves_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Missing Value Imputation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CascVI imputations\n",
    "imputed = {}\n",
    "imputed_z = {}\n",
    "\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        imputed[n.name], imputed_z[n.name] = tree_posterior.imputation_internal(query_node=n.name,\n",
    "                                                            pp_averaging=200,\n",
    "                                                            z_averaging=None                           \n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_treevae_X = [x for x in imputed.values()]\n",
    "internal_treevae_X = np.array(internal_treevae_X).reshape(-1, cas_dataset.X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Evaluation: Correlations***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = {'groundtruth': internal_X, 'average': internal_avg_X, 'ppca':internal_ppca_X,\n",
    "#        'approx ppca Oracle':imputed_X, 'approx ppca mean field': imputed_X2,\n",
    "#        'gaussian VAE': internal_vae_X, 'gaussian treeVAE': internal_treevae_X\n",
    "#      }\n",
    "\n",
    "data = {'groundtruth': internal_X.T, 'average': internal_avg_X.T, 'ppca':internal_ppca_X.T,\n",
    "        'approx ppca Oracle':imputed_X.T, 'approx ppca iid': imputed_X2.T,\n",
    "        'gaussian VAE': internal_vae_X.T\n",
    "        , 'gaussian treeVAE': internal_treevae_X.T\n",
    "       }\n",
    "\n",
    "df1 = correlations(data, 'None', True)\n",
    "df1.head(5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Spearman CC    0.756487\n",
       " Pearson CC     0.767067\n",
       " Kendall Tau    0.574368\n",
       " dtype: float64,\n",
       " Spearman CC    0.812028\n",
       " Pearson CC     0.820406\n",
       " Kendall Tau    0.630683\n",
       " dtype: float64,\n",
       " Spearman CC    0.656615\n",
       " Pearson CC     0.603462\n",
       " Kendall Tau    0.490053\n",
       " dtype: float64)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "df1[df1.Method=='average'].mean(), df1[df1.Method=='ppca'].mean(), df1[df1.Method=='gaussian VAE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Spearman CC    0.815085\n",
       " Pearson CC     0.824786\n",
       " Kendall Tau    0.633762\n",
       " dtype: float64,\n",
       " Spearman CC    0.815705\n",
       " Pearson CC     0.824596\n",
       " Kendall Tau    0.634432\n",
       " dtype: float64,\n",
       " Spearman CC    0.782457\n",
       " Pearson CC     0.791754\n",
       " Kendall Tau    0.599818\n",
       " dtype: float64)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "df1[df1.Method=='approx ppca Oracle'].mean(), df1[df1.Method=='approx ppca iid'].mean(),  df1[df1.Method=='gaussian treeVAE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    Spearman CC  Pearson CC  Kendal Tau CC\n",
       "average                0.756487    0.767067       0.574368\n",
       "ppca                   0.812028    0.820406       0.630683\n",
       "approx ppca Oracle     0.815085    0.824786       0.633762\n",
       "approx ppca iid        0.815705    0.824596       0.634432\n",
       "gaussian VAE           0.656615    0.603462       0.490053\n",
       "gaussian treeVAE       0.782457    0.791754       0.599818"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendal Tau CC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>average</th>\n      <td>0.756487</td>\n      <td>0.767067</td>\n      <td>0.574368</td>\n    </tr>\n    <tr>\n      <th>ppca</th>\n      <td>0.812028</td>\n      <td>0.820406</td>\n      <td>0.630683</td>\n    </tr>\n    <tr>\n      <th>approx ppca Oracle</th>\n      <td>0.815085</td>\n      <td>0.824786</td>\n      <td>0.633762</td>\n    </tr>\n    <tr>\n      <th>approx ppca iid</th>\n      <td>0.815705</td>\n      <td>0.824596</td>\n      <td>0.634432</td>\n    </tr>\n    <tr>\n      <th>gaussian VAE</th>\n      <td>0.656615</td>\n      <td>0.603462</td>\n      <td>0.490053</td>\n    </tr>\n    <tr>\n      <th>gaussian treeVAE</th>\n      <td>0.782457</td>\n      <td>0.791754</td>\n      <td>0.599818</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "data_dict = {}\n",
    "methods = list(data.keys())[1:]\n",
    "for method in methods:\n",
    "    data_dict[method] = list(df1[df1.Method==method].mean())\n",
    "results_corr = pd.DataFrame.from_dict(data_dict, orient='index', columns=['Spearman CC', 'Pearson CC', 'Kendal Tau CC'])\n",
    "\n",
    "results_corr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Evaluation 2: MSE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = {'groundtruth': internal_X.T, 'average': internal_avg_X.T, 'ppca':internal_ppca_X.T,\n",
    "#        'approx ppca Oracle':imputed_X.T, 'approx ppca mean field': imputed_X2.T,\n",
    "#        'gaussian VAE': internal_vae_X.T, 'gaussian treeVAE': internal_treevae_X.T\n",
    "#       }\n",
    "\n",
    "from external.utils.metrics import mse\n",
    "\n",
    "data = {'groundtruth': internal_X, 'average': internal_avg_X, 'ppca':internal_ppca_X,\n",
    "        'approx ppca Oracle':imputed_X, 'approx ppca iid': imputed_X2,\n",
    "        'gaussian VAE': internal_vae_X, 'gaussian treeVAE': internal_treevae_X\n",
    "      }\n",
    "\n",
    "results = mse(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      average      ppca  approx ppca Oracle  approx ppca iid  gaussian VAE  \\\n",
       "MSE  1.676866  1.265429            1.257161         1.260095  3.457347e+07   \n",
       "std  0.505498  0.405923            0.430971         0.439821  3.012902e+08   \n",
       "\n",
       "     gaussian treeVAE  \n",
       "MSE          1.517241  \n",
       "std          0.507593  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>average</th>\n      <th>ppca</th>\n      <th>approx ppca Oracle</th>\n      <th>approx ppca iid</th>\n      <th>gaussian VAE</th>\n      <th>gaussian treeVAE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MSE</th>\n      <td>1.676866</td>\n      <td>1.265429</td>\n      <td>1.257161</td>\n      <td>1.260095</td>\n      <td>3.457347e+07</td>\n      <td>1.517241</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.505498</td>\n      <td>0.405923</td>\n      <td>0.430971</td>\n      <td>0.439821</td>\n      <td>3.012902e+08</td>\n      <td>0.507593</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "source": [
    "***Testing Message Passing***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evidence = ppca.get_evidence_leaves_levelorder(ppca.z, ppca.latent)\n",
    "#mean1, scale1 = ppca.compute_posterior_predictive_z_MP(evidence.reshape(-1, ppca.latent))\n",
    "#mean2, scale2 = ppca.compute_posterior_predictive_z(evidence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd08038a79804d646dd36b3762b0d60c87c86d89e40c61f6758cc1d2f18aca59864",
   "display_name": "Python 3.7.10 64-bit ('scvi-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "8038a79804d646dd36b3762b0d60c87c86d89e40c61f6758cc1d2f18aca59864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}