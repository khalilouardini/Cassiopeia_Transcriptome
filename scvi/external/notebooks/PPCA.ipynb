{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Standard imports"
   ]
  },
  {
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('WebAgg')\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 104,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***import ete3 Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree\n",
    "\n",
    "tree_name = \"/home/eecs/khalil.ouardini/cas_scvi_topologies/newick_objects/100cells/no_fitness/topology4.nwk\"\n",
    "tree = Tree(tree_name, 1)\n",
    "\n",
    "leaves = tree.get_leaves()\n",
    "\n",
    "for i, n in enumerate(tree.traverse('levelorder')):\n",
    "    n.add_features(index=i)\n",
    "    n.name = str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "from anndata import AnnData\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from external.dataset.tree import TreeDataset, GeneExpressionDataset\n",
    "from external.dataset.ppca import PPCA\n",
    "from external.dataset.anndataset import AnnDatasetFromAnnData\n",
    "\n",
    "# Models\n",
    "import scanpy as sc\n",
    "from external.inference.gaussian_inference import GaussianTrainer\n",
    "from external.inference.gaussian_tree_inference import GaussianTreeTrainer\n",
    "from external.inference.gaussian_tree_inference import GaussianTreePosterior\n",
    "from external.inference.gaussian_inference import GaussianPosterior\n",
    "from external.models.treevae import TreeVAE\n",
    "from external.models.gaussian_vae import GaussianVAE\n",
    "from external.models.gaussian_treevae import GaussianTreeVAE\n",
    "\n",
    "# Utils\n",
    "from external.utils.data_util import get_leaves, get_internal\n",
    "from external.utils.metrics import ks_pvalue, accuracy_imputation, correlations, mse, knn_purity, knn_purity_stratified\n",
    "from external.utils.plots_util import plot_histograms, plot_scatter_mean, plot_ecdf_ks, plot_density, plot_embedding\n",
    "from external.utils.plots_util import plot_losses, plot_elbo, plot_common_ancestor, plot_one_gene, training_dashboard\n",
    "from external.utils.baselines import avg_weighted_baseline, scvi_baseline, scvi_baseline_z, cascvi_baseline_z, avg_baseline_z, construct_latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulations (Gaussian Likelihood model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the latent variables $z \\in \\mathbb{R}^{N \\times D}$ are gaussian (correlated). A phylogenetic tree $\\tau$ (with $N$ nodes) encodes the covariance $\\Sigma$ of $z$. \n",
    "\n",
    "$$\\mathbf{z}=(z_1, ..., z_N) \\sim \\mathcal{N}(0, \\Sigma)$$\n",
    "\n",
    "$z$ is partitionned into two groups:\n",
    "\n",
    "- the leaves $\\mathcal{L} = {1, ..., L}$\n",
    "- the internal nodes $\\mathcal{I} = {L + 1, ..., N}$\n",
    "\n",
    "***\n",
    "\n",
    "***We describe the generative model***:\n",
    "\n",
    "Consider a dataset of $ X={x_n}_{n=1}^{L} $ (also partitioned such that $1, ..., N = \\mathcal{L} \\bigcup \\mathcal{I}$) such that $x_n \\in \\mathbb{R}^{P}$. We aim to represent each $x_n$ under a latent variable $z_n \\in \\mathbb{R}^{D}$ with  with $D << P$ lower dimension. \n",
    "We only observe data at the leaves. the generative model is defined $\\forall n \\in \\mathcal{L}$\n",
    "\n",
    "The set of principal axes $W$ relates the latent variables to the data.\n",
    "\n",
    "The corresponding data point is generated via a projection:\n",
    "\n",
    "$$\n",
    "\\forall n \\in \\mathcal{L}, x_n =  W z_n + e_n\n",
    "$$\n",
    "\n",
    "with $W \\in \\mathbb{R}^{P x D}$ and $e_n \\sim \\mathcal{N}(0, \\sigma^2 I_P)$. Thus:\n",
    "\n",
    "\n",
    "$$\n",
    "\\forall n \\in \\mathcal{L},  x_n | z_n \\sim \\mathcal{N}(W z_n, \\sigma^2 I_P)\n",
    "$$\n",
    "\n",
    "After marginalization\n",
    "\n",
    "$$\n",
    "\\forall n \\in \\mathcal{L}, x_n \\sim \\mathcal{N}(0, W^T W + \\sigma^2 I_P)\n",
    "$$\n",
    "\n",
    "The posterior $p(z_n|x_n)$ for each $n$ is also ***tractable***, indeed\n",
    "\n",
    "$\\begin{pmatrix} x_n \\\\ z_n \\end{pmatrix} = \\begin{pmatrix} W z_n + e \\\\ z_n \\end{pmatrix}$ is a gaussian vector (because for $a \\in \\mathbb{R}$, $b \\in \\mathbb{R}$, $a(W z_n + e) + bz_n$ is still gaussian) such that:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} x_n \\\\ z_n \\end{pmatrix} \\sim \\mathcal{N}(\\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} W^T W + \\sigma^2 I_P  & W\\Sigma_n \\\\ (W\\Sigma_n)^T & \\Sigma_n \\end{pmatrix})\n",
    "$$\n",
    "\n",
    "where $\\Sigma_n$ is the marginalized covariance $\\Sigma$ of $z_n$\n",
    "\n",
    "Therefore we can use the conditioning formula to infer the mean and the covariance of the (gaussian) posterior $p(z_n|x_n)$:\n",
    "\n",
    "$$\n",
    "\\mu_{z_n|x_n} = (W\\Sigma_{n}(W^{T} W + \\sigma^{2} I_{P})^{-1}\\Sigma_{n}^{T}W^{T}) x_{n} \\\\\n",
    "\\Sigma_{z_n|x_n} = \\Sigma_n - W\\Sigma_{n}(W^{T} W + \\sigma^{2} I_{P})^{-1}\\Sigma_{n}^{T}W^{T}\n",
    "$$\n",
    "\n",
    "***\n",
    "\n",
    "***Imputation at internal nodes***\n",
    "\n",
    "Let $j \\in \\mathcal{I}$, and $X_{\\mathcal{L}} = {x_1, ... x_L}$ the set of leaves.\n",
    "We want to infer $p(x_j|X_{\\mathcal{L}})$. If we consider that the data at the internal nodes is \"seen\" and that the generative model is also known $\\forall n \\in \\mathcal{I}$, we could easily (and accurately) compute $p(x_j|X_{\\mathcal{L}})$ by using the gaussian conditioning formula on the gaussian vector:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} x_j \\\\ X_{\\mathcal{L}} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In the case of unseen data at the internal nodes, one can estimate the posterior predictive density:\n",
    "\n",
    "1. $$\n",
    "p(x_j|X_{\\mathcal{L}}) = p(x_j|x_1, ..., x_L) = \\int p(x_j|z_j)p(z_j|z_1,...,z_L)\\prod_{i=1}^{L}p(z_i|x_i)(dz_j,dz_1,...,dz_L)\n",
    "$$\n",
    "\n",
    "Therefore:\n",
    "$$\n",
    "p(x_j|x_1, ..., x_L) \\approx  p(x_j|z_j)p(z_j|z_1,...,z_L)\\prod_{i=1}^{L}p(z_i|x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x_j|x_1, ..., x_L) \\approx  \\mathcal{N}(x_j|Wz_j, \\sigma^2I_P)  \\mathcal{N}(z_j|\\mu_{j|\\mathcal{I}}, \\Sigma_{j|\\mathcal{I}}) \\prod_{i=1}^{L} \\mathcal{N}(z_i|\\mu_{z_i|x_i}, \\Sigma_{z_i|x_i})\n",
    "$$\n",
    "\n",
    "2. $ p(x_j|X_{\\mathcal{L}}) = Wp(z_j|X_{\\mathcal{L}}) + p(e_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n                     /-54\n                  /-|\n               /-|   \\-55\n              |  |\n              |   \\-33\n              |\n              |   /-34\n              |  |\n            /-|  |               /-152\n           |  |  |            /-|\n           |  |  |           |   \\-153\n           |  |  |         /-|\n           |  |  |        |  |   /-154\n           |  |  |      /-|   \\-|\n           |  |  |     |  |      \\-155\n           |   \\-|     |  |\n           |     |     |   \\-105\n           |     |     |\n           |     |     |            /-176\n           |     |   /-|         /-|\n           |     |  |  |      /-|   \\-177\n           |     |  |  |     |  |\n           |     |  |  |   /-|   \\-157\n           |     |  |  |  |  |\n           |     |  |  |  |  |   /-158\n           |      \\-|   \\-|   \\-|\n           |        |     |      \\-159\n           |        |     |\n           |        |      \\-107\n           |        |\n           |        |   /-82\n           |         \\-|\n           |            \\-83\n           |\n           |                     /-160\n           |                  /-|\n           |                 |   \\-161\n           |               /-|\n           |              |  |      /-178\n           |              |  |   /-|\n           |            /-|   \\-|   \\-179\n           |           |  |     |\n           |           |  |      \\-163\n           |         /-|  |\n           |        |  |   \\-109\n           |        |  |\n           |        |  |   /-110\n           |        |   \\-|\n           |        |     |   /-134\n           |        |      \\-|\n           |        |        |   /-164\n           |        |         \\-|\n           |        |            \\-165\n         /-|        |\n        |  |      /-|            /-166\n        |  |     |  |         /-|\n        |  |     |  |      /-|   \\-167\n        |  |     |  |     |  |\n        |  |     |  |     |   \\-137\n        |  |     |  |   /-|\n        |  |     |  |  |  |      /-168\n        |  |     |  |  |  |   /-|\n        |  |     |  |  |   \\-|   \\-169\n        |  |     |  |  |     |\n        |  |     |  |  |      \\-139\n        |  |     |  |  |\n        |  |     |   \\-|   /-114\n        |  |     |     |  |\n        |  |     |     |  |            /-188\n        |  |     |     |  |         /-|\n        |  |     |     |  |        |   \\-189\n        |  |     |     |  |        |\n        |  |     |     |  |      /-|      /-196\n        |  |     |     |  |     |  |   /-|\n        |  |     |      \\-|     |  |  |   \\-197\n        |  |     |        |     |   \\-|\n        |  |     |        |   /-|     |   /-198\n        |  |     |        |  |  |      \\-|\n        |  |     |        |  |  |         \\-199\n        |  |   /-|        |  |  |\n        |  |  |  |        |  |  |   /-182\n        |  |  |  |        |  |   \\-|\n        |  |  |  |        |  |      \\-183\n        |  |  |  |         \\-|\n        |  |  |  |           |         /-192\n        |  |  |  |           |      /-|\n        |  |  |  |           |     |   \\-193\n        |  |  |  |           |   /-|\n        |  |  |  |           |  |  |   /-194\n        |  |  |  |           |  |   \\-|\n        |  |  |  |            \\-|      \\-195\n        |  |  |  |              |\n        |  |  |  |              |   /-186\n        |  |  |  |               \\-|\n        |  |  |  |                  \\-187\n        |  |  |  |\n        |  |  |  |         /-116\n      /-|  |  |  |      /-|\n     |  |   \\-|  |     |   \\-117\n     |  |     |  |     |\n     |  |     |  |   /-|      /-142\n     |  |     |  |  |  |   /-|\n     |  |     |  |  |  |  |   \\-143\n     |  |     |  |  |   \\-|\n     |  |     |   \\-|     |   /-144\n     |  |     |     |      \\-|\n     |  |     |     |         \\-145\n     |  |     |     |\n     |  |     |      \\-61\n     |  |     |\n     |  |     |      /-62\n     |  |     |   /-|\n     |  |     |  |   \\-63\n     |  |     |  |\n     |  |     |  |            /-146\n     |  |     |  |         /-|\n     |  |     |  |        |  |   /-174\n     |  |     |  |        |   \\-|\n     |  |      \\-|      /-|      \\-175\n     |  |        |     |  |\n     |  |        |     |  |   /-148\n     |  |        |   /-|   \\-|\n     |  |        |  |  |      \\-149\n     |  |        |  |  |\n     |  |        |  |   \\-91\n     |  |         \\-|\n     |  |           |      /-122\n     |  |           |   /-|\n     |  |           |  |   \\-123\n     |  |            \\-|\n     |  |              |   /-124\n     |  |               \\-|\n     |  |                  \\-125\n     |  |\n     |  |         /-40\n     |  |      /-|\n     |  |   /-|   \\-41\n-- /-|  |  |  |\n     |  |  |   \\-21\n     |  |  |\n     |  |  |         /-66\n     |  |  |      /-|\n     |   \\-|     |  |   /-94\n     |     |     |   \\-|\n     |     |   /-|      \\-95\n     |     |  |  |\n     |     |  |  |   /-68\n     |     |  |   \\-|\n     |      \\-|      \\-69\n     |        |\n     |        |   /-44\n     |        |  |\n     |         \\-|   /-70\n     |           |  |\n     |            \\-|   /-96\n     |              |  |\n     |               \\-|      /-150\n     |                 |   /-|\n     |                  \\-|   \\-151\n     |                    |\n     |                     \\-127\n     |\n     |            /-46\n     |           |\n     |         /-|      /-98\n     |        |  |   /-|\n     |        |  |  |   \\-99\n     |        |   \\-|\n     |      /-|     |   /-100\n     |     |  |      \\-|\n     |     |  |         \\-101\n     |   /-|  |\n     |  |  |   \\-25\n     |  |  |\n     |  |  |   /-26\n     |  |   \\-|\n     |  |      \\-27\n     |  |\n      \\-|            /-74\n        |         /-|\n        |      /-|   \\-75\n        |     |  |\n        |   /-|   \\-49\n        |  |  |\n        |  |   \\-29\n        |  |\n         \\-|      /-50\n           |   /-|\n           |  |  |   /-76\n           |  |   \\-|\n           |  |      \\-77\n            \\-|\n              |      /-78\n              |   /-|\n              |  |  |   /-102\n               \\-|   \\-|\n                 |      \\-103\n                 |\n                  \\-53\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  },
  {
   "source": [
    "***Branch Length***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-3\n",
    "branch_length = {}\n",
    "for node in tree.traverse('levelorder'):\n",
    "    if node.is_root():\n",
    "        branch_length[node.name] = 0.0\n",
    "    else:\n",
    "        branch_length[node.name] = node.dist\n",
    "branch_length['prior_root'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f15805ba3f0>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import torch\n",
    "    \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5\n",
    "p = 100\n",
    "vis = True\n",
    "leaves_only = False\n",
    "var = 1.0\n",
    "sigma_scale = 2.0\n",
    "\n",
    "#ppca = PPCA(tree, p, d, vis, leaves_only, var, sigma_scale)\n",
    "ppca = PPCA(tree=tree, \n",
    "            dim=p, \n",
    "            latent=d, \n",
    "            vis=vis, \n",
    "            only=leaves_only,\n",
    "            branch_length=branch_length, \n",
    "            sigma_scale=sigma_scale\n",
    "            )\n",
    "\n",
    "ppca.simulate_latent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Marginalization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "ppca.simulate_normal()\n",
    "ppca.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Log-Likelihood of the tree -37348.33439194971\nLogLikelihood of the leaves -18650.1273364016\n"
     ]
    }
   ],
   "source": [
    "lik_tree = ppca.likelihood_obs(leaves_only=False)\n",
    "lik_leaves = ppca.likelihood_obs(leaves_only=True)\n",
    "\n",
    "print(\"Log-Likelihood of the tree {}\".format(lik_tree))\n",
    "print(\"LogLikelihood of the leaves {}\".format(lik_leaves))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100, 100), (100, 100), (100, 100), (100, 100), (100, 5))"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Latent vectors\n",
    "leaves_z, _, _ = get_leaves(ppca.z, ppca.mu, tree)\n",
    "\n",
    "#FIXED training set\n",
    "leaves_X, leaves_idx, mu = get_leaves(ppca.X, ppca.mu, tree)\n",
    "\n",
    "# internal nodes data (for imputation)\n",
    "internal_X, internal_idx, internal_mu = get_internal(ppca.X, ppca.mu, tree)\n",
    "\n",
    "# internal nodes z\n",
    "internal_z, _, _ = get_internal(ppca.z, ppca.mu, tree)\n",
    "\n",
    "leaves_X.shape, mu.shape, internal_X.shape, internal_mu.shape, leaves_z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Posterior Distributions***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***evidence***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "evidence_leaves = ppca.get_evidence_leaves_levelorder(X=ppca.X, dim=ppca.dim)\n",
    "evidence_leaves.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Leaves covariance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data covariance computation + inversion took 57.30646324157715\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "ppca.compute_leaves_covariance()\n",
    "\n",
    "print('Data covariance computation + inversion took {}'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse_covariance_path = os.path.join('/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external/dataset/#inverse_covariances'\n",
    "#if os\n",
    "#tree_name = "
   ]
  },
  {
   "source": [
    "***Posterior mean and covariance***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean, posterior_cov = ppca.compute_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Posterior predictive density***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictive_mean, predictive_cov = ppca.compute_posterior_predictive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary: Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1: Unweighted Average of gene expression in Clade\n",
    "\n",
    "The simple idea here is to impute the value of an internal node, with the (un)weighted average of the gene expression values of the leaves, taking the query internal node as the root of the subtree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_avg = avg_weighted_baseline(tree=tree, \n",
    "                                    weighted=False, \n",
    "                                    X=ppca.X,\n",
    "                                    rounding=False\n",
    "                                   )\n",
    "\n",
    "#get internal nodes\n",
    "avg_X = np.array([x for x in imputed_avg.values()]).reshape(-1, ppca.X.shape[1])\n",
    "internal_avg_X, _, _ = get_internal(avg_X, ppca.mu, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2: (groundtruth) posterior predictive density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputed_ppca = {}\n",
    "#for n in tree.traverse('levelorder'):\n",
    "#    if not n.is_leaf():\n",
    "#        samples = np.array([np.random.multivariate_normal(mean=predictive_mean[n.name],\n",
    "#                                                            cov=predictive_cov[n.name])\n",
    "#                           for i in range(20)])\n",
    "#        imputed_ppca[n.name] = np.mean(samples, axis=0)\n",
    "\n",
    "#internal_ppca_X = np.array([x for x in imputed_ppca.values()]).reshape(-1, ppca.X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 3: Approximation through Message Passing (Oracle)\n",
    "\n",
    "\n",
    "i.e, \n",
    "\n",
    "1. sample from $z_1, ..., z_n \\sim p(z_1, ..., z_n|x_1, ..., x_n)$ (conditionning formula)\n",
    "2. impute $z_i \\sim p(z_i | z_1, ..., z_n)$ (Message Passing)\n",
    "3. Decode $p(x_i|z_i) = W z_i + \\sigma^2 I_P$ (Generative model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean_corr, posterior_cov_corr = ppca.compute_correlated_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external/dataset/ppca.py:357: RuntimeWarning: covariance is not positive-semidefinite.\n  cov=posterior_cov).reshape(-1, self.latent) for i in range(sample_size)])\n"
     ]
    }
   ],
   "source": [
    "imputed_mp, imputed_z_mp, predictive_mean_z, predictive_cov_z  = ppca.compute_approx_posterior_predictive(iid=False, use_MP=False, sample_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_X = np.array([x for x in imputed_mp.values()]).reshape(-1, ppca.X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 4: Approximation through Message Passing + iid posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e, \n",
    "\n",
    "1. sample from marginal conditional $z_l \\sim p(z_l|x_1) \\forall l \\in (1, ...,L)$ (conditionning formula)\n",
    "2. impute $z_i \\sim p(z_i | z_1, ..., z_n)$ (Message Passing)\n",
    "3. Decode $p(x_i|z_i) = W z_i + \\sigma^2 I_P$ (Generative model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external/dataset/ppca.py:364: RuntimeWarning: covariance is not positive-semidefinite.\n  cov=posterior_cov[k]) for i in range(sample_size)])\n"
     ]
    }
   ],
   "source": [
    "imputed_mp2, imputed_z_mp2, predictive_mean_z2, predictive_cov_z2  = ppca.compute_approx_posterior_predictive(iid=True, use_MP=False, sample_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_X2 = np.array([x for x in imputed_mp2.values()]).reshape(-1, ppca.X.shape[1])"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 5: Gaussian VAE decoded averaged latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n"
     ]
    }
   ],
   "source": [
    "# anndata\n",
    "gene_dataset = GeneExpressionDataset()\n",
    "gene_dataset.populate_from_data(leaves_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 400\n",
    "\n",
    "vae = GaussianVAE(gene_dataset.nb_genes,\n",
    "                  n_hidden=64,\n",
    "                  n_layers=1,\n",
    "                  n_latent=ppca.latent,\n",
    "                  sigma_ldvae=None\n",
    "              )\n",
    "\n",
    "#new_weight = torch.from_numpy(ppca.W).float()\n",
    "\n",
    "#with torch.no_grad():\n",
    "    #vae.decoder.factor_regressor.fc_layers[0][0].weight = torch.nn.Parameter(new_weight)\n",
    "    \n",
    "#for param in vae.decoder.factor_regressor.fc_layers[0][0].parameters():\n",
    "#    param.requires_grad = False\n",
    "    \n",
    "#vae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance is 4.171938935357741\n"
     ]
    }
   ],
   "source": [
    "cuda_z = torch.from_numpy(leaves_z).float()\n",
    "p_m, p_v = vae.decoder.forward( torch.from_numpy(leaves_z).float())\n",
    "p_m = p_m.detach().cpu().numpy()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(p_m, mu)\n",
    "print(\"the distance is {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "\n",
    "trainer = GaussianTrainer(model=vae,\n",
    "                          gene_dataset=gene_dataset,\n",
    "                          train_size=1.0,\n",
    "                          use_cuda=use_cuda,\n",
    "                          frequency=10,\n",
    "                          n_epochs_kl_warmup=None,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "computing elbo\n",
      "ELBO: 40738.41796875\n",
      "computing elbo\n",
      "ELBO: 40802.6875\n",
      "computing elbo\n",
      "ELBO: 40781.56640625\n",
      "training:   0%|          | 0/400 [00:00<?, ?it/s]computing elbo\n",
      "ELBO: 34870.8984375\n",
      "computing elbo\n",
      "ELBO: 34841.890625\n",
      "computing elbo\n",
      "ELBO: 34851.796875\n",
      "training:   2%|▎         | 10/400 [00:00<00:04, 94.03it/s]computing elbo\n",
      "ELBO: 28965.013671875\n",
      "computing elbo\n",
      "ELBO: 28946.02734375\n",
      "computing elbo\n",
      "ELBO: 29005.869140625\n",
      "training:   6%|▌         | 22/400 [00:00<00:03, 106.12it/s]computing elbo\n",
      "ELBO: 27393.78515625\n",
      "computing elbo\n",
      "ELBO: 27490.80078125\n",
      "computing elbo\n",
      "ELBO: 27400.142578125\n",
      "training:   8%|▊         | 34/400 [00:00<00:03, 109.35it/s]computing elbo\n",
      "ELBO: 25259.228515625\n",
      "computing elbo\n",
      "ELBO: 25235.6015625\n",
      "computing elbo\n",
      "ELBO: 25177.056640625\n",
      "training:  12%|█▏        | 46/400 [00:00<00:03, 110.99it/s]computing elbo\n",
      "ELBO: 23687.515625\n",
      "computing elbo\n",
      "ELBO: 23674.3125\n",
      "computing elbo\n",
      "ELBO: 23650.0625\n",
      "training:  14%|█▍        | 58/400 [00:00<00:03, 112.06it/s]computing elbo\n",
      "ELBO: 21656.0234375\n",
      "computing elbo\n",
      "ELBO: 21670.875\n",
      "computing elbo\n",
      "ELBO: 21628.234375\n",
      "computing elbo\n",
      "ELBO: 21001.72265625\n",
      "computing elbo\n",
      "ELBO: 20963.529296875\n",
      "computing elbo\n",
      "ELBO: 21020.837890625\n",
      "training:  18%|█▊        | 70/400 [00:00<00:03, 105.77it/s]computing elbo\n",
      "ELBO: 20283.98046875\n",
      "computing elbo\n",
      "ELBO: 20360.34375\n",
      "computing elbo\n",
      "ELBO: 20341.771484375\n",
      "training:  20%|██        | 82/400 [00:00<00:02, 108.38it/s]computing elbo\n",
      "ELBO: 19625.23046875\n",
      "computing elbo\n",
      "ELBO: 19685.32421875\n",
      "computing elbo\n",
      "ELBO: 19669.58984375\n",
      "training:  24%|██▎       | 94/400 [00:00<00:02, 110.33it/s]computing elbo\n",
      "ELBO: 18615.615234375\n",
      "computing elbo\n",
      "ELBO: 18672.498046875\n",
      "computing elbo\n",
      "ELBO: 18636.04296875\n",
      "training:  26%|██▋       | 106/400 [00:00<00:02, 110.93it/s]computing elbo\n",
      "ELBO: 18281.498046875\n",
      "computing elbo\n",
      "ELBO: 18258.791015625\n",
      "computing elbo\n",
      "ELBO: 18233.13671875\n",
      "computing elbo\n",
      "ELBO: 18071.640625\n",
      "computing elbo\n",
      "ELBO: 18089.564453125\n",
      "computing elbo\n",
      "ELBO: 18091.978515625\n",
      "training:  30%|███       | 120/400 [00:01<00:02, 117.65it/s]computing elbo\n",
      "ELBO: 17985.384765625\n",
      "computing elbo\n",
      "ELBO: 18029.451171875\n",
      "computing elbo\n",
      "ELBO: 18023.689453125\n",
      "training:  34%|███▍      | 135/400 [00:01<00:02, 125.28it/s]computing elbo\n",
      "ELBO: 17728.8671875\n",
      "computing elbo\n",
      "ELBO: 17777.02734375\n",
      "computing elbo\n",
      "ELBO: 17796.40625\n",
      "training:  37%|███▋      | 149/400 [00:01<00:01, 129.20it/s]computing elbo\n",
      "ELBO: 17545.81640625\n",
      "computing elbo\n",
      "ELBO: 17559.076171875\n",
      "computing elbo\n",
      "ELBO: 17568.58203125\n",
      "computing elbo\n",
      "ELBO: 17318.43359375\n",
      "computing elbo\n",
      "ELBO: 17398.177734375\n",
      "computing elbo\n",
      "ELBO: 17330.51171875\n",
      "training:  40%|████      | 162/400 [00:01<00:01, 129.33it/s]computing elbo\n",
      "ELBO: 17145.537109375\n",
      "computing elbo\n",
      "ELBO: 17239.572265625\n",
      "computing elbo\n",
      "ELBO: 17166.037109375\n",
      "training:  44%|████▍     | 177/400 [00:01<00:01, 133.09it/s]computing elbo\n",
      "ELBO: 16790.806640625\n",
      "computing elbo\n",
      "ELBO: 16799.912109375\n",
      "computing elbo\n",
      "ELBO: 16751.716796875\n",
      "computing elbo\n",
      "ELBO: 16916.125\n",
      "computing elbo\n",
      "ELBO: 16947.533203125\n",
      "computing elbo\n",
      "ELBO: 16956.890625\n",
      "training:  48%|████▊     | 191/400 [00:01<00:01, 132.85it/s]computing elbo\n",
      "ELBO: 17049.865234375\n",
      "computing elbo\n",
      "ELBO: 16999.365234375\n",
      "computing elbo\n",
      "ELBO: 17051.953125\n",
      "training:  52%|█████▏    | 206/400 [00:01<00:01, 136.10it/s]computing elbo\n",
      "ELBO: 16868.533203125\n",
      "computing elbo\n",
      "ELBO: 16830.87890625\n",
      "computing elbo\n",
      "ELBO: 16862.330078125\n",
      "computing elbo\n",
      "ELBO: 16477.37109375\n",
      "computing elbo\n",
      "ELBO: 16414.29296875\n",
      "computing elbo\n",
      "ELBO: 16434.3828125\n",
      "training:  55%|█████▌    | 220/400 [00:01<00:01, 134.19it/s]computing elbo\n",
      "ELBO: 16550.302734375\n",
      "computing elbo\n",
      "ELBO: 16600.974609375\n",
      "computing elbo\n",
      "ELBO: 16596.91796875\n",
      "training:  58%|█████▊    | 234/400 [00:01<00:01, 135.28it/s]computing elbo\n",
      "ELBO: 16413.150390625\n",
      "computing elbo\n",
      "ELBO: 16589.796875\n",
      "computing elbo\n",
      "ELBO: 16487.44140625\n",
      "training:  62%|██████▏   | 249/400 [00:02<00:01, 137.33it/s]computing elbo\n",
      "ELBO: 16132.271484375\n",
      "computing elbo\n",
      "ELBO: 16122.18359375\n",
      "computing elbo\n",
      "ELBO: 16181.8349609375\n",
      "computing elbo\n",
      "ELBO: 16149.9326171875\n",
      "computing elbo\n",
      "ELBO: 16190.447265625\n",
      "computing elbo\n",
      "ELBO: 16120.1708984375\n",
      "training:  66%|██████▌   | 263/400 [00:02<00:01, 134.94it/s]computing elbo\n",
      "ELBO: 16335.583984375\n",
      "computing elbo\n",
      "ELBO: 16127.2607421875\n",
      "computing elbo\n",
      "ELBO: 16203.560546875\n",
      "training:  69%|██████▉   | 277/400 [00:02<00:00, 135.65it/s]computing elbo\n",
      "ELBO: 15962.0634765625\n",
      "computing elbo\n",
      "ELBO: 15992.64453125\n",
      "computing elbo\n",
      "ELBO: 15958.8837890625\n",
      "computing elbo\n",
      "ELBO: 15871.84375\n",
      "computing elbo\n",
      "ELBO: 15839.8525390625\n",
      "computing elbo\n",
      "ELBO: 15850.623046875\n",
      "training:  73%|███████▎  | 291/400 [00:02<00:00, 130.16it/s]computing elbo\n",
      "ELBO: 16500.134765625\n",
      "computing elbo\n",
      "ELBO: 16472.6875\n",
      "computing elbo\n",
      "ELBO: 16532.05859375\n",
      "training:  76%|███████▋  | 305/400 [00:02<00:00, 130.91it/s]computing elbo\n",
      "ELBO: 16389.90625\n",
      "computing elbo\n",
      "ELBO: 16491.84765625\n",
      "computing elbo\n",
      "ELBO: 16416.9765625\n",
      "training:  80%|███████▉  | 319/400 [00:02<00:00, 132.85it/s]computing elbo\n",
      "ELBO: 16468.0703125\n",
      "computing elbo\n",
      "ELBO: 16396.369140625\n",
      "computing elbo\n",
      "ELBO: 16460.013671875\n",
      "computing elbo\n",
      "ELBO: 16207.2265625\n",
      "computing elbo\n",
      "ELBO: 16204.431640625\n",
      "computing elbo\n",
      "ELBO: 16060.51171875\n",
      "training:  83%|████████▎ | 333/400 [00:02<00:00, 131.75it/s]computing elbo\n",
      "ELBO: 16503.837890625\n",
      "computing elbo\n",
      "ELBO: 16402.279296875\n",
      "computing elbo\n",
      "ELBO: 16432.126953125\n",
      "training:  87%|████████▋ | 347/400 [00:02<00:00, 133.42it/s]computing elbo\n",
      "ELBO: 16268.6142578125\n",
      "computing elbo\n",
      "ELBO: 16218.7802734375\n",
      "computing elbo\n",
      "ELBO: 16216.310546875\n",
      "computing elbo\n",
      "ELBO: 16447.966796875\n",
      "computing elbo\n",
      "ELBO: 16582.05078125\n",
      "computing elbo\n",
      "ELBO: 16566.275390625\n",
      "training:  90%|█████████ | 361/400 [00:02<00:00, 131.94it/s]computing elbo\n",
      "ELBO: 15847.857421875\n",
      "computing elbo\n",
      "ELBO: 15812.7080078125\n",
      "computing elbo\n",
      "ELBO: 15830.0361328125\n",
      "training:  94%|█████████▍| 375/400 [00:02<00:00, 133.66it/s]computing elbo\n",
      "ELBO: 16032.7705078125\n",
      "computing elbo\n",
      "ELBO: 16004.6875\n",
      "computing elbo\n",
      "ELBO: 16017.1328125\n",
      "training:  97%|█████████▋| 389/400 [00:03<00:00, 134.86it/s]computing elbo\n",
      "ELBO: 15462.8984375\n",
      "computing elbo\n",
      "ELBO: 15460.546875\n",
      "computing elbo\n",
      "ELBO: 15463.673828125\n",
      "computing elbo\n",
      "ELBO: 15149.724609375\n",
      "computing elbo\n",
      "ELBO: 15255.5048828125\n",
      "computing elbo\n",
      "ELBO: 15252.697265625\n",
      "training: 100%|██████████| 400/400 [00:03<00:00, 126.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# train VAE\n",
    "trainer.train(n_epochs=n_epochs, lr=1e-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Press Ctrl+C to stop WebAgg server\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-8161294d1596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train history Gaussian VAE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/scvi-env/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \"\"\"\n\u001b[1;32m    352\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_backend_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/scvi-env/lib/python3.7/site-packages/matplotlib/backends/backend_webagg.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m()\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"To view figure, visit {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mWebAggApplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/scvi-env/lib/python3.7/site-packages/matplotlib/backends/backend_webagg.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcatch_sigint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mioloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/scvi-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyncio_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyncio_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/scvi-env/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;34m\"\"\"Run until stop() is called.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_runnung\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_coroutine_origin_tracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_debug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ident\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/scvi-env/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36m_check_runnung\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_runnung\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "elbo_train = trainer.history[\"elbo_train_set\"]\n",
    "x = np.linspace(0, 100, (len(elbo_train)))\n",
    "plt.plot(np.log(elbo_train), \n",
    "         label=\"train\", color='blue',\n",
    "         linestyle=':',\n",
    "         linewidth=3\n",
    "        )\n",
    "        \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.legend()\n",
    "plt.title(\"Train history Gaussian VAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.2993859185397083"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "posterior =  trainer.create_posterior(model=vae,\n",
    "                                      gene_dataset=gene_dataset\n",
    "                                      )\n",
    "                                      \n",
    "qz_m, qz_v = posterior.get_latent(give_mean=True, give_cov=True)\n",
    "mean_squared_error(qz_m, leaves_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "imputed_avg_vae, imputed_avg_z, imputed_avg_cov_z = avg_baseline_z(tree=tree,\n",
    "                                 model=vae,\n",
    "                                 posterior=posterior,\n",
    "                                 weighted=False,\n",
    "                                 n_samples_z=1,\n",
    "                                 gaussian=True,\n",
    "                                 use_cuda=False,\n",
    "                                 give_cov=True\n",
    "                                )\n",
    "\n",
    "internal_vae_X = np.array([x for x in imputed_avg_vae.values()]).reshape(-1, ppca.X.shape[1])\n",
    "internal_vae_X.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "computing elbo\nELBO: 15272.53515625\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "152.7253515625"
      ]
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "source": [
    "posterior.elbo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Our Model: GaussianTreeVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "X contains continuous and/or negative values. Please use raw UMI/read counts with scVI\n",
      "This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "go\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GeneExpressionDataset object with n_cells x nb_genes = 100 x 100\n",
       "    gene_attribute_names: 'gene_names'\n",
       "    cell_attribute_names: 'local_vars', 'labels', 'batch_indices', 'barcodes', 'local_means'\n",
       "    cell_categorical_attribute_names: 'batch_indices', 'labels'"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "adata = AnnData(leaves_X)\n",
    "adata.obs_names = [n.name for n in tree.traverse('levelorder') if n.is_leaf()]\n",
    "scvi_dataset = AnnDatasetFromAnnData(adata, filtering=False)\n",
    "scvi_dataset.initialize_cell_attribute('barcodes', adata.obs_names)\n",
    "\n",
    "#TreeDataset\n",
    "cas_dataset = TreeDataset(scvi_dataset, tree=tree, filtering=False)\n",
    "cas_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "use_MP = True\n",
    "\n",
    "treevae = GaussianTreeVAE(cas_dataset.nb_genes,\n",
    "              tree = cas_dataset.tree,\n",
    "              n_latent=ppca.latent,\n",
    "              n_hidden=64,\n",
    "              n_layers=1,\n",
    "              prior_t = branch_length,\n",
    "              use_MP=use_MP,\n",
    "              sigma_ldvae=None\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Freezing the decoder***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_weight = torch.from_numpy(ppca.W).float()\n",
    "\n",
    "#with torch.no_grad():\n",
    "    #treevae.decoder.factor_regressor.fc_layers[0][0].weight = torch.nn.Parameter(new_weight)\n",
    "    \n",
    "#for param in treevae.decoder.factor_regressor.fc_layers[0][0].parameters():\n",
    "    #param.requires_grad = False\n",
    "    \n",
    "#treevae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert(treevae.decoder.factor_regressor.fc_layers[0][0].weight.numpy().all() == ppca.W.T.all())"
   ]
  },
  {
   "source": [
    "\n",
    "***Are we able to generate the gene expression data by decoding the simulated latent space?***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_m, p_v = treevae.decoder.forward(torch.from_numpy(leaves_z).float())\n",
    "#p_m = p_m.detach().numpy()\n",
    "#p_m.shape, mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse = mean_squared_error(p_m, mu)\n",
    "#print(\"the distance is {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Training***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_leaves:  [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99]]\ntest_leaves:  []\nvalidation leaves:  []\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 600\n",
    "lr = 1e-2\n",
    "lambda_ = 1.0\n",
    "freq = 10\n",
    "\n",
    "tree_trainer = GaussianTreeTrainer(\n",
    "        model = treevae,\n",
    "        gene_dataset = cas_dataset,\n",
    "        lambda_ = lambda_,\n",
    "        train_size=1.0,\n",
    "        test_size=0,\n",
    "        use_cuda=use_cuda,\n",
    "        frequency=freq,\n",
    "        n_epochs_kl_warmup=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "computing elbo\n",
      "training:   2%|▏         | 9/600 [00:00<00:23, 25.16it/s]computing elbo\n",
      "training:   3%|▎         | 18/600 [00:00<00:23, 24.89it/s]computing elbo\n",
      "training:   4%|▍         | 27/600 [00:01<00:23, 24.70it/s]computing elbo\n",
      "training:   6%|▋         | 39/600 [00:01<00:22, 25.11it/s]computing elbo\n",
      "training:   8%|▊         | 48/600 [00:01<00:22, 24.76it/s]computing elbo\n",
      "training:  10%|▉         | 57/600 [00:02<00:22, 23.85it/s]computing elbo\n",
      "training:  12%|█▏        | 69/600 [00:02<00:21, 24.72it/s]computing elbo\n",
      "training:  13%|█▎        | 78/600 [00:03<00:20, 24.86it/s]computing elbo\n",
      "training:  14%|█▍        | 87/600 [00:03<00:20, 24.84it/s]computing elbo\n",
      "training:  16%|█▋        | 99/600 [00:04<00:19, 25.18it/s]computing elbo\n",
      "training:  18%|█▊        | 108/600 [00:04<00:19, 24.73it/s]computing elbo\n",
      "training:  20%|█▉        | 117/600 [00:04<00:19, 24.62it/s]computing elbo\n",
      "training:  22%|██▏       | 129/600 [00:05<00:18, 24.86it/s]computing elbo\n",
      "training:  23%|██▎       | 138/600 [00:05<00:18, 24.44it/s]computing elbo\n",
      "training:  24%|██▍       | 147/600 [00:06<00:18, 24.22it/s]computing elbo\n",
      "training:  26%|██▋       | 159/600 [00:06<00:17, 25.00it/s]computing elbo\n",
      "training:  28%|██▊       | 168/600 [00:06<00:17, 24.84it/s]computing elbo\n",
      "training:  30%|██▉       | 177/600 [00:07<00:17, 24.77it/s]computing elbo\n",
      "training:  32%|███▏      | 189/600 [00:07<00:16, 25.15it/s]computing elbo\n",
      "training:  33%|███▎      | 198/600 [00:08<00:16, 24.90it/s]computing elbo\n",
      "training:  34%|███▍      | 207/600 [00:08<00:16, 24.24it/s]computing elbo\n",
      "training:  36%|███▋      | 219/600 [00:09<00:15, 24.15it/s]computing elbo\n",
      "training:  38%|███▊      | 228/600 [00:09<00:15, 24.60it/s]computing elbo\n",
      "training:  40%|███▉      | 237/600 [00:09<00:14, 24.67it/s]computing elbo\n",
      "training:  42%|████▏     | 249/600 [00:10<00:14, 24.03it/s]computing elbo\n",
      "training:  43%|████▎     | 258/600 [00:10<00:14, 24.23it/s]computing elbo\n",
      "training:  44%|████▍     | 267/600 [00:11<00:14, 23.48it/s]computing elbo\n",
      "training:  46%|████▋     | 279/600 [00:11<00:13, 24.30it/s]computing elbo\n",
      "training:  48%|████▊     | 288/600 [00:11<00:12, 24.63it/s]computing elbo\n",
      "training:  50%|████▉     | 297/600 [00:12<00:12, 24.10it/s]computing elbo\n",
      "training:  52%|█████▏    | 309/600 [00:12<00:11, 24.75it/s]computing elbo\n",
      "training:  53%|█████▎    | 318/600 [00:13<00:11, 24.58it/s]computing elbo\n",
      "training:  55%|█████▍    | 327/600 [00:13<00:11, 24.31it/s]computing elbo\n",
      "training:  56%|█████▋    | 339/600 [00:13<00:10, 25.85it/s]computing elbo\n",
      "training:  58%|█████▊    | 348/600 [00:14<00:09, 26.10it/s]computing elbo\n",
      "training:  60%|█████▉    | 357/600 [00:14<00:11, 21.32it/s]computing elbo\n",
      "training:  62%|██████▏   | 369/600 [00:15<00:10, 22.65it/s]computing elbo\n",
      "training:  63%|██████▎   | 378/600 [00:15<00:08, 25.46it/s]computing elbo\n",
      "training:  64%|██████▍   | 387/600 [00:16<00:07, 26.82it/s]computing elbo\n",
      "training:  66%|██████▋   | 399/600 [00:16<00:07, 27.49it/s]computing elbo\n",
      "training:  68%|██████▊   | 408/600 [00:16<00:07, 26.29it/s]computing elbo\n",
      "training:  70%|██████▉   | 417/600 [00:17<00:06, 27.40it/s]computing elbo\n",
      "training:  72%|███████▏  | 429/600 [00:17<00:06, 28.14it/s]computing elbo\n",
      "training:  73%|███████▎  | 438/600 [00:17<00:05, 27.91it/s]computing elbo\n",
      "training:  74%|███████▍  | 447/600 [00:18<00:05, 27.79it/s]computing elbo\n",
      "training:  76%|███████▋  | 459/600 [00:18<00:05, 27.50it/s]computing elbo\n",
      "training:  78%|███████▊  | 468/600 [00:19<00:04, 26.58it/s]computing elbo\n",
      "training:  80%|███████▉  | 477/600 [00:19<00:04, 27.17it/s]computing elbo\n",
      "training:  82%|████████▏ | 489/600 [00:19<00:03, 27.81it/s]computing elbo\n",
      "training:  83%|████████▎ | 498/600 [00:20<00:03, 27.32it/s]computing elbo\n",
      "training:  84%|████████▍ | 507/600 [00:20<00:03, 26.59it/s]computing elbo\n",
      "training:  86%|████████▋ | 519/600 [00:20<00:02, 27.71it/s]computing elbo\n",
      "training:  88%|████████▊ | 528/600 [00:21<00:02, 27.75it/s]computing elbo\n",
      "training:  90%|████████▉ | 537/600 [00:21<00:02, 26.50it/s]computing elbo\n",
      "training:  92%|█████████▏| 549/600 [00:22<00:01, 27.52it/s]computing elbo\n",
      "training:  93%|█████████▎| 558/600 [00:22<00:01, 26.03it/s]computing elbo\n",
      "training:  94%|█████████▍| 567/600 [00:22<00:01, 26.25it/s]computing elbo\n",
      "training:  96%|█████████▋| 579/600 [00:23<00:00, 26.39it/s]computing elbo\n",
      "training:  98%|█████████▊| 588/600 [00:23<00:00, 27.22it/s]computing elbo\n",
      "training: 100%|█████████▉| 597/600 [00:23<00:00, 27.56it/s]computing elbo\n",
      "training: 100%|██████████| 600/600 [00:23<00:00, 25.01it/s]\n"
     ]
    }
   ],
   "source": [
    "tree_trainer.train(n_epochs=n_epochs,\n",
    "              lr=lr\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dashboard(tree_trainer, treevae.encoder_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100, 5), (100, 5))"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "tree_posterior = tree_trainer.create_posterior(model=treevae,\n",
    "                                              gene_dataset=cas_dataset,\n",
    "                                               clades=tree_trainer.clades,\n",
    "                                               indices=np.arange(len(cas_dataset))\n",
    "                                              )\n",
    "tree_latent = tree_posterior.get_latent()\n",
    "tree_latent.shape, internal_z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Missing Value Imputation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CascVI imputations\n",
    "imputed = {}\n",
    "imputed_z = {}\n",
    "imputed_cov_z = {}\n",
    "imputed_mean_z = {}\n",
    "\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        imputed[n.name], z, imputed_mean_z[n.name], imputed_cov_z[n.name] = tree_posterior.imputation_internal(query_node=n,\n",
    "                                                                                             pp_averaging=None,\n",
    "                                                                                              z_averaging=None,\n",
    "                                                                                              give_mean=True \n",
    "                                                                                            )  \n",
    "        imputed_z[n.name] = z.cpu().numpy()\n",
    "                                                                                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_treevae_X = [x for x in imputed.values()]\n",
    "internal_treevae_X = np.array(internal_treevae_X).reshape(-1, cas_dataset.X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "computing elbo\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(150.2321, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "tree_posterior.compute_elbo(treevae)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation 1.a.i: MSE/MAE L2/L1 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from external.utils.metrics import mse\n",
    "\n",
    "data = {'groundtruth': imputed_X, 'average': internal_avg_X,\n",
    "        'gaussian VAE': internal_vae_X\n",
    "        , 'gaussian treeVAE': internal_treevae_X\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "L2\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      average  gaussian VAE  gaussian treeVAE\n",
       "MSE  0.716805      0.817597          0.566842\n",
       "std  0.308642      0.387916          0.224257"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>average</th>\n      <th>gaussian VAE</th>\n      <th>gaussian treeVAE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MSE</th>\n      <td>0.716805</td>\n      <td>0.817597</td>\n      <td>0.566842</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.308642</td>\n      <td>0.387916</td>\n      <td>0.224257</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "results = mse(data=data, metric='MSE')\n",
    "print('L2')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "L1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       average  gaussian VAE  gaussian treeVAE\n",
       "MSE  26.317424  4.725809e+01      5.716029e+01\n",
       "std   0.000000  1.421085e-14      2.131628e-14"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>average</th>\n      <th>gaussian VAE</th>\n      <th>gaussian treeVAE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MSE</th>\n      <td>26.317424</td>\n      <td>4.725809e+01</td>\n      <td>5.716029e+01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.000000</td>\n      <td>1.421085e-14</td>\n      <td>2.131628e-14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "results = mse(data=data, metric='L1')\n",
    "print('L1')\n",
    "results"
   ]
  },
  {
   "source": [
    "## Evaluation 1.a.ii: Correlations "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'groundtruth': imputed_X, 'average': internal_avg_X,\n",
    "        'gaussian VAE': internal_vae_X\n",
    "        , 'gaussian treeVAE': internal_treevae_X\n",
    "       }\n",
    "\n",
    "df1 = correlations(data, 'None', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gene-gene correlation\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Spearman CC  Pearson CC  Kendal Tau CC\n",
       "average              0.757535    0.781487       0.583554\n",
       "gaussian VAE         0.771515    0.798094       0.598016\n",
       "gaussian treeVAE     0.771032    0.806599       0.601248"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendal Tau CC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>average</th>\n      <td>0.757535</td>\n      <td>0.781487</td>\n      <td>0.583554</td>\n    </tr>\n    <tr>\n      <th>gaussian VAE</th>\n      <td>0.771515</td>\n      <td>0.798094</td>\n      <td>0.598016</td>\n    </tr>\n    <tr>\n      <th>gaussian treeVAE</th>\n      <td>0.771032</td>\n      <td>0.806599</td>\n      <td>0.601248</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "data_dict = {}\n",
    "methods = list(data.keys())[1:]\n",
    "for method in methods:\n",
    "    data_dict[method] = list(df1[df1.Method==method].mean())\n",
    "results_corr = pd.DataFrame.from_dict(data_dict, orient='index', columns=['Spearman CC', 'Pearson CC', 'Kendal Tau CC'])\n",
    "\n",
    "print('gene-gene correlation')\n",
    "results_corr.head(10)"
   ]
  },
  {
   "source": [
    "## Evaluation 1.a.iii: MSE/MAE (L1/L2) of variance in latent space"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***Compute MCMC estimates of mean and variance parameters of internal_nodes***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external/inference/gaussian_tree_inference.py:294: RuntimeWarning: covariance is not positive-semidefinite.\n  cov=cov).reshape(-1, self.model.n_latent)\n"
     ]
    }
   ],
   "source": [
    "imputed_mcmc_cov = {}\n",
    "imputed_mcmc_mean = {}\n",
    "\n",
    "mcmc_mean = {}\n",
    "mcmc_cov = {}\n",
    "M = 5\n",
    "\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        # with Approximate posterior q(z|x)\n",
    "        imputed_mcmc_mean[n.name], imputed_mcmc_cov[n.name] = tree_posterior.mcmc_estimate(query_node=n,\n",
    "                                                                                            n_samples=M\n",
    "                                                                                            )\n",
    "        # with groundtruth posterior p(z|x)\n",
    "        mean=posterior_mean_corr\n",
    "        cov=posterior_cov_corr\n",
    "\n",
    "        mcmc_mean[n.name], mcmc_cov[n.name] = tree_posterior.mcmc_estimate(query_node=n,\n",
    "                                                            n_samples=M,\n",
    "                                                            known_latent_dist=(mean, cov)\n",
    "                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_var = {'groundtruth': mcmc_cov, 'gaussian VAE':imputed_avg_cov_z, 'gaussian treeVAE': imputed_mcmc_cov}\n",
    "data_mean = {'groundtruth': mcmc_mean, 'gaussian VAE':imputed_avg_z, 'gaussian treeVAE': imputed_mcmc_mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_latent(tree, predictive_z, imputed_avg_z, imputed_z, do_variance=False):\n",
    "    mse_treevae = 0\n",
    "    mse_vae = 0\n",
    "    N = 0\n",
    "    for n in tree.traverse('levelorder'):\n",
    "        if not n.is_leaf():\n",
    "            if do_variance:\n",
    "                true_cov = predictive_z[n.name]\n",
    "                vae_cov = imputed_avg_z[n.name].cpu().numpy()\n",
    "                treevae_cov = imputed_z[n.name]\n",
    "\n",
    "                mse_treevae += mean_squared_error(true_cov, treevae_cov)\n",
    "                mse_vae += mean_squared_error(true_cov, vae_cov)\n",
    "            else:\n",
    "                mse_treevae += mean_squared_error(predictive_z[n.name], imputed_z[n.name])\n",
    "                mse_vae += mean_squared_error(predictive_z[n.name], imputed_avg_z[n.name][0])\n",
    "            N += 1\n",
    "    mse_treevae /= N\n",
    "    mse_vae /= N\n",
    "\n",
    "    return mse_treevae, mse_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0004237482295142097, 0.00035844850200526855)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "print('MCMC total Variance')\n",
    "error_latent(tree, mcmc_cov, imputed_avg_cov_z, imputed_mcmc_cov, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MCMC mean\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.9143929862687368, 1.85150199980163)"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "print('MCMC mean')\n",
    "error_latent(tree, mcmc_mean, imputed_avg_z, imputed_mcmc_mean)"
   ]
  },
  {
   "source": [
    "## Evaluation 1.a.iv: Averaged KL divergence (internal nodes)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***TreeVAE***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Kl divergence 129776636.19200827\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions import Normal, kl_divergence\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "kl_mean = 0\n",
    "N = 0\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        # true distribution\n",
    "        mean_true = torch.from_numpy(mcmc_mean[n.name])\n",
    "        cov_true = torch.sqrt(torch.from_numpy(mcmc_cov[n.name]))\n",
    "        dist_true = Normal(mean_true,\n",
    "                        cov_true\n",
    "                        )\n",
    "        \n",
    "        # Approx\n",
    "        mean_approx = torch.from_numpy(imputed_mcmc_mean[n.name])\n",
    "        cov_approx = torch.sqrt(torch.from_numpy(imputed_mcmc_cov[n.name]))\n",
    "        dist_approx = Normal(mean_approx,\n",
    "                        cov_approx\n",
    "                        )\n",
    "\n",
    "        kl_mean += kl_divergence(dist_true, dist_approx).sum()\n",
    "        N += 1\n",
    "kl_mean /= N\n",
    "print('Average Kl divergence {}'.format(kl_mean))"
   ]
  },
  {
   "source": [
    "***VAE***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Kl divergence 5374.677030454518\n"
     ]
    }
   ],
   "source": [
    "kl_mean = 0\n",
    "N = 0\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        mean_true = torch.from_numpy(mcmc_mean[n.name])\n",
    "        cov_true = torch.sqrt(torch.from_numpy(mcmc_cov[n.name]))\n",
    "        dist_true = Normal(mean_true,\n",
    "                        cov_true\n",
    "                        )\n",
    "\n",
    "        dist_approx = Normal(torch.from_numpy(imputed_avg_z[n.name]),\n",
    "                        torch.sqrt(imputed_avg_cov_z[n.name].cpu())\n",
    "                        )\n",
    "        kl_mean += kl_divergence(dist_true, dist_approx).sum()\n",
    "        N += 1\n",
    "kl_mean /= N\n",
    "print('Average Kl divergence {}'.format(kl_mean))"
   ]
  },
  {
   "source": [
    "## Evaluation 1.a.v: Likelihood (internal nodes)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-461.48781196850234, -251.76246046200959]"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def mean_posterior_lik(tree, predictive_mean_z, imputed_avg_z, imputed_mean_z, predictive_cov_z, imputed_avg_cov_z, imputed_cov_z):\n",
    "    treevae_lik = 0\n",
    "    vae_lik = 0\n",
    "    N = 0\n",
    "    for n in tree.traverse('levelorder'):\n",
    "        if not n.is_leaf():\n",
    "            # mean\n",
    "            true_mean = predictive_mean_z[n.name]\n",
    "            vae_mean = imputed_avg_z[n.name][0]\n",
    "            treevae_mean = imputed_mean_z[n.name].cpu().numpy()\n",
    "\n",
    "            # covariance\n",
    "            true_cov = np.diag(predictive_cov_z[n.name])\n",
    "            vae_cov = np.diag(imputed_avg_cov_z[n.name].cpu().numpy())\n",
    "            treevae_cov = np.diag(imputed_cov_z[n.name] * np.ones((d)))\n",
    "\n",
    "            sample_treevae = np.random.multivariate_normal(mean=treevae_mean,\n",
    "                                                            cov=treevae_cov)\n",
    "            sample_vae = np.random.multivariate_normal(mean=vae_mean,\n",
    "                                                        cov=vae_cov)\n",
    "\n",
    "            treevae_lik += multivariate_normal.logpdf(sample_treevae,\n",
    "                                                    true_mean,\n",
    "                                                    true_cov)\n",
    "            vae_lik += multivariate_normal.logpdf(sample_vae,\n",
    "                                                    true_mean,\n",
    "                                                    true_cov)\n",
    "            \n",
    "            N += 1\n",
    "\n",
    "    vae_lik /= N\n",
    "    treevae_lik /= N\n",
    "    return [vae_lik, treevae_lik]\n",
    "\n",
    "mean_posterior_lik(tree, predictive_mean_z, imputed_avg_z, imputed_mean_z, predictive_cov_z, imputed_avg_cov_z, imputed_cov_z)"
   ]
  },
  {
   "source": [
    "## Evaluation 1.a.vi: (More) Latent space metrics "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1. Prior likelihood"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100, 5), (100, 5))"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "cascvi_latent = tree_posterior.get_latent()\n",
    "scvi_latent = posterior.get_latent()\n",
    "\n",
    "scvi_latent.shape, cascvi_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood of scVI encodings:  -2826.691510321084\n"
     ]
    }
   ],
   "source": [
    "treevae.initialize_visit()\n",
    "treevae.initialize_messages(scvi_latent, cas_dataset.barcodes, scvi_latent.shape[1])\n",
    "treevae.perform_message_passing((treevae.tree & treevae.root), scvi_latent.shape[1], False)\n",
    "mp_lik_vae = treevae.aggregate_messages_into_leaves_likelihood(d, add_prior=True)\n",
    "print(\"Likelihood of scVI encodings: \", mp_lik_vae.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood of cascVI encodings:  -369.6501111715011\n"
     ]
    }
   ],
   "source": [
    "treevae.initialize_visit()\n",
    "treevae.initialize_messages(cascvi_latent, cas_dataset.barcodes, cascvi_latent.shape[1])\n",
    "treevae.perform_message_passing((treevae.tree & treevae.root), cascvi_latent.shape[1], False)\n",
    "mp_lik_cascvi = treevae.aggregate_messages_into_leaves_likelihood(d, add_prior=True)\n",
    "print(\"Likelihood of cascVI encodings: \", mp_lik_cascvi.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood of observations:  -222.3884709247602\n"
     ]
    }
   ],
   "source": [
    "treevae.initialize_visit()\n",
    "treevae.initialize_messages(leaves_z, cas_dataset.barcodes, cascvi_latent.shape[1])\n",
    "treevae.perform_message_passing((treevae.tree & treevae.root), cascvi_latent.shape[1], False)\n",
    "mp_lik = treevae.aggregate_messages_into_leaves_likelihood(d, add_prior=True)\n",
    "print(\"Likelihood of observations: \", mp_lik.item())"
   ]
  },
  {
   "source": [
    "### 2. k-nn purity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cascvi_latent = construct_latent(tree, cascvi_latent, imputed_z)\n",
    "full_scvi_latent = construct_latent(tree, scvi_latent, imputed_avg_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Leaves Only\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.446926282876483, 0.5216776947687367)"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "source": [
    "print(\"Leaves Only\")\n",
    "data = {'groundtruth': leaves_z, 'scVI': scvi_latent,\n",
    "        'cascVI': cascvi_latent\n",
    "        }\n",
    "scores = knn_purity(max_neighbors=30,\n",
    "                    data=data,\n",
    "                    plot=False,\n",
    "                    save_fig='/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/knn_purity_plot.png'\n",
    "                    )\n",
    "np.mean(scores['scVI']), np.mean(scores['cascVI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 204
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = list(range(2, 30))\n",
    "data = {'K': neighbors, 'scVI': scores['scVI'], 'cascVI': scores['cascVI']}\n",
    "df2 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     K      scVI    cascVI\n",
       "0    2  0.492537  0.532567\n",
       "1    3  0.431981  0.507538\n",
       "2    4  0.449275  0.520913\n",
       "3    5  0.432665  0.536098\n",
       "4    6  0.413428  0.540436\n",
       "5    7  0.398601  0.526718\n",
       "6    8  0.412180  0.523810\n",
       "7    9  0.413983  0.505017\n",
       "8   10  0.424501  0.500375\n",
       "9   11  0.422107  0.503759\n",
       "10  12  0.433692  0.512287\n",
       "11  13  0.429357  0.502890\n",
       "12  14  0.428571  0.494928\n",
       "13  15  0.433349  0.496259\n",
       "14  16  0.434978  0.494629\n",
       "15  17  0.433994  0.500441\n",
       "16  18  0.440000  0.508801\n",
       "17  19  0.448171  0.514548\n",
       "18  20  0.446655  0.518027\n",
       "19  21  0.451780  0.523948\n",
       "20  22  0.461794  0.527247\n",
       "21  23  0.464968  0.527732\n",
       "22  24  0.473297  0.530612\n",
       "23  25  0.481481  0.537515\n",
       "24  26  0.479374  0.545779\n",
       "25  27  0.487603  0.553063\n",
       "26  28  0.494130  0.556853\n",
       "27  29  0.499483  0.564186"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>K</th>\n      <th>scVI</th>\n      <th>cascVI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0.492537</td>\n      <td>0.532567</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0.431981</td>\n      <td>0.507538</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>0.449275</td>\n      <td>0.520913</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>0.432665</td>\n      <td>0.536098</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>0.413428</td>\n      <td>0.540436</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7</td>\n      <td>0.398601</td>\n      <td>0.526718</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>8</td>\n      <td>0.412180</td>\n      <td>0.523810</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>9</td>\n      <td>0.413983</td>\n      <td>0.505017</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10</td>\n      <td>0.424501</td>\n      <td>0.500375</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>11</td>\n      <td>0.422107</td>\n      <td>0.503759</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>12</td>\n      <td>0.433692</td>\n      <td>0.512287</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>13</td>\n      <td>0.429357</td>\n      <td>0.502890</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14</td>\n      <td>0.428571</td>\n      <td>0.494928</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>15</td>\n      <td>0.433349</td>\n      <td>0.496259</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>16</td>\n      <td>0.434978</td>\n      <td>0.494629</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>17</td>\n      <td>0.433994</td>\n      <td>0.500441</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>18</td>\n      <td>0.440000</td>\n      <td>0.508801</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>19</td>\n      <td>0.448171</td>\n      <td>0.514548</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>20</td>\n      <td>0.446655</td>\n      <td>0.518027</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>21</td>\n      <td>0.451780</td>\n      <td>0.523948</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>22</td>\n      <td>0.461794</td>\n      <td>0.527247</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>23</td>\n      <td>0.464968</td>\n      <td>0.527732</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>24</td>\n      <td>0.473297</td>\n      <td>0.530612</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>25</td>\n      <td>0.481481</td>\n      <td>0.537515</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>26</td>\n      <td>0.479374</td>\n      <td>0.545779</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>27</td>\n      <td>0.487603</td>\n      <td>0.553063</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>28</td>\n      <td>0.494130</td>\n      <td>0.556853</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>29</td>\n      <td>0.499483</td>\n      <td>0.564186</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "source": [
    "df = df.append(df2)\n",
    "df"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Internal nodes Only\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.36514020314439677, 0.45141649792859023)"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "print(\"Internal nodes Only\")\n",
    "internal_z, internal_idx, internal_mu = get_internal(ppca.z, ppca.mu, tree)\n",
    "internal_scvi_z, _, _ = get_internal(full_scvi_latent, ppca.mu, tree)\n",
    "internal_cascvi_z, _, _ = get_internal(full_cascvi_latent, ppca.mu, tree)\n",
    "\n",
    "data = {'groundtruth': internal_z, 'scVI': internal_scvi_z,\n",
    "        'cascVI': internal_cascvi_z\n",
    "        }\n",
    "\n",
    "scores = knn_purity(max_neighbors=30,\n",
    "              data=data,\n",
    "              plot=False,\n",
    "              save_fig='/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/knn_purity.png'\n",
    "              )\n",
    "\n",
    "np.mean(scores['scVI']), np.mean(scores['cascVI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Full tree\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.3584607764591899, 0.4458153596517597)"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "print(\"Full tree\")\n",
    "data = {'groundtruth': ppca.z, 'scVI': full_scvi_latent,\n",
    "        'cascVI': full_cascvi_latent\n",
    "        }\n",
    "scores = knn_purity(max_neighbors=30,\n",
    "              data=data,\n",
    "              plot=False)\n",
    "\n",
    "np.mean(scores['scVI']), np.mean(scores['cascVI'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd08038a79804d646dd36b3762b0d60c87c86d89e40c61f6758cc1d2f18aca59864",
   "display_name": "Python 3.7  ('scvi-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "8038a79804d646dd36b3762b0d60c87c86d89e40c61f6758cc1d2f18aca59864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}