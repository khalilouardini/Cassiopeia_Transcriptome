{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Standard imports"
   ]
  },
  {
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('WebAgg')\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***import ete3 Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree\n",
    "\n",
    "tree_name = \"/home/eecs/khalil.ouardini/cas_scvi_topologies/newick_objects/100cells/no_fitness/topology7.nwk\"\n",
    "tree = Tree(tree_name, 1)\n",
    "\n",
    "#tree = Tree()\n",
    "#tree.populate(30)\n",
    "\n",
    "leaves = tree.get_leaves()\n",
    "\n",
    "for i, n in enumerate(tree.traverse('levelorder')):\n",
    "    n.add_features(index=i)\n",
    "    if not n.is_leaf():\n",
    "        n.name = str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "from anndata import AnnData\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from external.dataset.tree import TreeDataset, GeneExpressionDataset\n",
    "from external.dataset.ppca import PPCA\n",
    "from external.dataset.anndataset import AnnDatasetFromAnnData\n",
    "\n",
    "# Models\n",
    "import scanpy as sc\n",
    "from external.inference.gaussian_inference import GaussianTrainer\n",
    "from external.inference.gaussian_tree_inference import GaussianTreeTrainer\n",
    "from external.inference.gaussian_tree_inference import GaussianTreePosterior\n",
    "from inference import posterior\n",
    "from external.models.treevae import TreeVAE\n",
    "from external.models.gaussian_vae import GaussianVAE\n",
    "from external.models.gaussian_treevae import GaussianTreeVAE\n",
    "\n",
    "# Utils\n",
    "from external.utils.data_util import get_leaves, get_internal\n",
    "from external.utils.metrics import ks_pvalue, accuracy_imputation, correlations, mse, knn_purity, knn_purity_stratified\n",
    "from external.utils.plots_util import plot_histograms, plot_scatter_mean, plot_ecdf_ks, plot_density, plot_embedding\n",
    "from external.utils.plots_util import plot_losses, plot_elbo, plot_common_ancestor, plot_one_gene, training_dashboard\n",
    "from external.utils.baselines import avg_weighted_baseline, scvi_baseline, scvi_baseline_z, cascvi_baseline_z, avg_baseline_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulations (Gaussian Likelihood model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the latent variables $z \\in \\mathbb{R}^{N \\times D}$ are gaussian (correlated). A phylogenetic tree $\\tau$ (with $N$ nodes) encodes the covariance $\\Sigma$ of $z$. \n",
    "\n",
    "$$\\mathbf{z}=(z_1, ..., z_N) \\sim \\mathcal{N}(0, \\Sigma)$$\n",
    "\n",
    "$z$ is partitionned into two groups:\n",
    "\n",
    "- the leaves $\\mathcal{L} = {1, ..., L}$\n",
    "- the internal nodes $\\mathcal{I} = {L + 1, ..., N}$\n",
    "\n",
    "***\n",
    "\n",
    "***We describe the generative model***:\n",
    "\n",
    "Consider a dataset of $ X={x_n}_{n=1}^{L} $ (also partitioned such that $1, ..., N = \\mathcal{L} \\bigcup \\mathcal{I}$) such that $x_n \\in \\mathbb{R}^{P}$. We aim to represent each $x_n$ under a latent variable $z_n \\in \\mathbb{R}^{D}$ with  with $D << P$ lower dimension. \n",
    "We only observe data at the leaves. the generative model is defined $\\forall n \\in \\mathcal{L}$\n",
    "\n",
    "The set of principal axes $W$ relates the latent variables to the data.\n",
    "\n",
    "The corresponding data point is generated via a projection:\n",
    "\n",
    "$$\n",
    "\\forall n \\in \\mathcal{L}, x_n =  W z_n + e_n\n",
    "$$\n",
    "\n",
    "with $W \\in \\mathbb{R}^{P x D}$ and $e_n \\sim \\mathcal{N}(0, \\sigma^2 I_P)$. Thus:\n",
    "\n",
    "\n",
    "$$\n",
    "\\forall n \\in \\mathcal{L},  x_n | z_n \\sim \\mathcal{N}(W z_n, \\sigma^2 I_P)\n",
    "$$\n",
    "\n",
    "After marginalization\n",
    "\n",
    "$$\n",
    "\\forall n \\in \\mathcal{L}, x_n \\sim \\mathcal{N}(0, W^T W + \\sigma^2 I_P)\n",
    "$$\n",
    "\n",
    "The posterior $p(z_n|x_n)$ for each $n$ is also ***tractable***, indeed\n",
    "\n",
    "$\\begin{pmatrix} x_n \\\\ z_n \\end{pmatrix} = \\begin{pmatrix} W z_n + e \\\\ z_n \\end{pmatrix}$ is a gaussian vector (because for $a \\in \\mathbb{R}$, $b \\in \\mathbb{R}$, $a(W z_n + e) + bz_n$ is still gaussian) such that:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} x_n \\\\ z_n \\end{pmatrix} \\sim \\mathcal{N}(\\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} W^T W + \\sigma^2 I_P  & W\\Sigma_n \\\\ (W\\Sigma_n)^T & \\Sigma_n \\end{pmatrix})\n",
    "$$\n",
    "\n",
    "where $\\Sigma_n$ is the marginalized covariance $\\Sigma$ of $z_n$\n",
    "\n",
    "Therefore we can use the conditioning formula to infer the mean and the covariance of the (gaussian) posterior $p(z_n|x_n)$:\n",
    "\n",
    "$$\n",
    "\\mu_{z_n|x_n} = (W\\Sigma_{n}(W^{T} W + \\sigma^{2} I_{P})^{-1}\\Sigma_{n}^{T}W^{T}) x_{n} \\\\\n",
    "\\Sigma_{z_n|x_n} = \\Sigma_n - W\\Sigma_{n}(W^{T} W + \\sigma^{2} I_{P})^{-1}\\Sigma_{n}^{T}W^{T}\n",
    "$$\n",
    "\n",
    "***\n",
    "\n",
    "***Imputation at internal nodes***\n",
    "\n",
    "Let $j \\in \\mathcal{I}$, and $X_{\\mathcal{L}} = {x_1, ... x_L}$ the set of leaves.\n",
    "We want to infer $p(x_j|X_{\\mathcal{L}})$. If we consider that the data at the internal nodes is \"seen\" and that the generative model is also known $\\forall n \\in \\mathcal{I}$, we could easily (and accurately) compute $p(x_j|X_{\\mathcal{L}})$ by using the gaussian conditioning formula on the gaussian vector:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} x_j \\\\ X_{\\mathcal{L}} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In the case of unseen data at the internal nodes, one can estimate the posterior predictive density:\n",
    "\n",
    "1. $$\n",
    "p(x_j|X_{\\mathcal{L}}) = p(x_j|x_1, ..., x_L) = \\int p(x_j|z_j)p(z_j|z_1,...,z_L)\\prod_{i=1}^{L}p(z_i|x_i)(dz_j,dz_1,...,dz_L)\n",
    "$$\n",
    "\n",
    "Therefore:\n",
    "$$\n",
    "p(x_j|x_1, ..., x_L) \\approx  p(x_j|z_j)p(z_j|z_1,...,z_L)\\prod_{i=1}^{L}p(z_i|x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x_j|x_1, ..., x_L) \\approx  \\mathcal{N}(x_j|Wz_j, \\sigma^2I_P)  \\mathcal{N}(z_j|\\mu_{j|\\mathcal{I}}, \\Sigma_{j|\\mathcal{I}}) \\prod_{i=1}^{L} \\mathcal{N}(z_i|\\mu_{z_i|x_i}, \\Sigma_{z_i|x_i})\n",
    "$$\n",
    "\n",
    "2. $ p(x_j|X_{\\mathcal{L}}) = Wp(z_j|X_{\\mathcal{L}}) + p(e_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n                  /-c214\n               /-|\n              |  |   /-c218\n              |   \\-|\n              |      \\-c219\n              |\n            /-|   /-c56\n           |  |  |\n           |  |  |            /-c178\n           |  |  |         /-|\n           |  |  |        |  |   /-c186\n           |  |  |      /-|   \\-|\n           |   \\-|     |  |      \\-c187\n           |     |   /-|  |\n           |     |  |  |   \\-c161\n           |     |  |  |\n           |     |  |   \\-c141\n           |     |  |\n           |      \\-|      /-c146\n           |        |   /-|\n           |        |  |   \\-c147\n           |        |  |\n         /-|        |  |      /-c172\n        |  |         \\-|   /-|\n        |  |           |  |  |   /-c190\n        |  |           |  |   \\-|\n        |  |           |  |     |   /-c208\n        |  |            \\-|      \\-|\n        |  |              |         \\-c209\n        |  |              |\n        |  |              |   /-c210\n        |  |               \\-|\n        |  |                  \\-c211\n        |  |\n        |  |      /-c152\n        |  |   /-|\n        |  |  |  |   /-c156\n      /-|  |  |   \\-|\n     |  |   \\-|      \\-c157\n     |  |     |\n     |  |     |   /-c120\n     |  |      \\-|\n     |  |        |   /-c132\n     |  |         \\-|\n     |  |           |   /-c136\n     |  |            \\-|\n     |  |               \\-c137\n     |  |\n     |  |         /-c212\n     |  |      /-|\n     |  |   /-|   \\-c213\n     |  |  |  |\n     |   \\-|   \\-c131\n     |     |\n     |      \\-c43\n     |\n     |                     /-c142\n     |                  /-|\n     |                 |  |   /-c182\n     |               /-|   \\-|\n     |              |  |      \\-c183\n     |              |  |\n     |              |   \\-c111\n     |              |\n     |            /-|         /-c164\n     |           |  |      /-|\n     |           |  |     |   \\-c165\n     |           |  |   /-|\n     |           |  |  |  |   /-c166\n     |           |  |  |   \\-|\n     |           |   \\-|      \\-c167\n     |           |     |\n     |         /-|     |   /-c222\n     |        |  |      \\-|\n     |        |  |         \\-c223\n     |        |  |\n     |        |  |      /-c134\n     |        |  |   /-|\n     |        |  |  |   \\-c135\n     |        |  |  |\n-- /-|        |  |  |            /-c200\n     |        |   \\-|         /-|\n     |        |     |      /-|   \\-c201\n     |        |     |     |  |\n     |      /-|     |   /-|   \\-c149\n     |     |  |     |  |  |\n     |     |  |      \\-|   \\-c145\n     |     |  |        |\n     |     |  |        |   /-c116\n     |     |  |         \\-|\n     |     |  |           |   /-c220\n     |     |  |            \\-|\n     |   /-|  |               \\-c221\n     |  |  |  |\n     |  |  |  |      /-c198\n     |  |  |  |   /-|\n     |  |  |   \\-|   \\-c199\n     |  |  |     |\n     |  |  |      \\-c139\n     |  |  |\n     |  |  |   /-c27\n     |  |   \\-|\n     |  |     |   /-c188\n     |  |      \\-|\n     |  |        |   /-c192\n     |  |         \\-|\n     |  |            \\-c193\n     |  |\n     |  |               /-c24\n     |  |              |\n     |  |              |      /-c126\n     |  |            /-|   /-|\n     |  |           |  |  |  |   /-c184\n     |  |           |  |  |   \\-|\n     |  |           |   \\-|      \\-c185\n     |  |           |     |\n     |  |           |     |   /-c170\n     |  |         /-|      \\-|\n     |  |        |  |        |   /-c196\n     |  |        |  |         \\-|\n     |  |        |  |            \\-c197\n     |  |        |  |\n     |  |        |  |   /-c206\n      \\-|      /-|   \\-|\n        |     |  |      \\-c207\n        |     |  |\n        |     |  |         /-c64\n        |     |  |      /-|\n        |     |  |   /-|   \\-c65\n        |     |  |  |  |\n        |   /-|   \\-|   \\-c63\n        |  |  |     |\n        |  |  |      \\-c45\n        |  |  |\n        |  |  |      /-c194\n        |  |  |   /-|\n        |  |  |  |   \\-c195\n        |  |   \\-|\n        |  |     |   /-c90\n        |  |      \\-|\n        |  |        |   /-c168\n        |  |         \\-|\n        |  |            \\-c169\n        |  |\n        |  |            /-c78\n        |  |         /-|\n        |  |        |   \\-c113\n        |  |        |\n        |  |        |            /-c74\n        |  |        |         /-|\n        |  |        |        |  |   /-c100\n        |  |        |        |   \\-|\n        |  |        |        |      \\-c101\n        |  |        |        |\n        |  |        |        |            /-c154\n         \\-|        |        |         /-|\n           |        |      /-|      /-|   \\-c155\n           |        |     |  |     |  |\n           |      /-|     |  |   /-|   \\-c103\n           |     |  |     |  |  |  |\n           |     |  |     |  |  |  |   /-c204\n           |     |  |     |  |  |   \\-|\n           |     |  |     |  |  |      \\-c205\n           |     |  |     |   \\-|\n           |     |  |     |     |      /-c108\n           |     |  |   /-|     |   /-|\n           |     |  |  |  |     |  |  |   /-c150\n           |     |  |  |  |     |  |   \\-|\n           |     |  |  |  |      \\-|      \\-c151\n           |     |  |  |  |        |\n           |     |  |  |  |        |   /-c216\n           |   /-|   \\-|  |         \\-|\n           |  |  |     |  |            \\-c217\n           |  |  |     |  |\n           |  |  |     |  |   /-c202\n           |  |  |     |   \\-|\n           |  |  |     |      \\-c203\n           |  |  |     |\n           |  |  |      \\-c59\n           |  |  |\n           |  |  |         /-c180\n            \\-|  |      /-|\n              |  |   /-|   \\-c181\n              |  |  |  |\n              |   \\-|   \\-c177\n              |     |\n              |      \\-c159\n              |\n              |   /-c50\n              |  |\n              |  |      /-c106\n               \\-|   /-|\n                 |  |  |   /-c174\n                 |  |   \\-|\n                  \\-|      \\-c175\n                    |\n                    |   /-c162\n                     \\-|\n                        \\-c163\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  },
  {
   "source": [
    "***Branch Length***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-3\n",
    "branch_length = {}\n",
    "for node in tree.traverse('levelorder'):\n",
    "    if node.name == '0':\n",
    "        branch_length[node.name] = 0.1\n",
    "        continue\n",
    "    branch_length[node.name] = node.dist\n",
    "branch_length['prior_root'] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff3544a9dd0>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import torch\n",
    "    \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5\n",
    "p = 100\n",
    "vis = True\n",
    "leaves_only = False\n",
    "var = 1.0\n",
    "sigma_scale = 2.0\n",
    "\n",
    "#ppca = PPCA(tree, p, d, vis, leaves_only, var, sigma_scale)\n",
    "ppca = PPCA(tree=tree, \n",
    "            dim=p, \n",
    "            latent=d, \n",
    "            vis=vis, \n",
    "            only=leaves_only,\n",
    "            branch_length=branch_length, \n",
    "            sigma_scale=sigma_scale\n",
    "            )\n",
    "\n",
    "ppca.simulate_latent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Marginalization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "ppca.simulate_normal()\n",
    "ppca.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Log-Likelihood of the tree -37571.643014424335\nLogLikelihood of the leaves -18761.67733934441\n"
     ]
    }
   ],
   "source": [
    "lik_tree = ppca.likelihood_obs(leaves_only=False)\n",
    "lik_leaves = ppca.likelihood_obs(leaves_only=True)\n",
    "\n",
    "print(\"Log-Likelihood of the tree {}\".format(lik_tree))\n",
    "print(\"LogLikelihood of the leaves {}\".format(lik_leaves))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100, 100), (100, 100), (100, 100), (100, 100), (100, 5))"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Latent vectors\n",
    "leaves_z, _, _ = get_leaves(ppca.z, ppca.mu, tree)\n",
    "\n",
    "#FIXED training set\n",
    "leaves_X, leaves_idx, mu = get_leaves(ppca.X, ppca.mu, tree)\n",
    "\n",
    "# internal nodes data (for imputation)\n",
    "internal_X, internal_idx, internal_mu = get_internal(ppca.X, ppca.mu, tree)\n",
    "\n",
    "# internal nodes z\n",
    "internal_z, _, _ = get_internal(ppca.z, ppca.mu, tree)\n",
    "\n",
    "leaves_X.shape, mu.shape, internal_X.shape, internal_mu.shape, leaves_z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Posterior Distributions***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***evidence***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "evidence_leaves = ppca.get_evidence_leaves_levelorder(X=ppca.X, dim=ppca.dim)\n",
    "evidence_leaves.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Leaves covariance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data covariance computation + inversion took 73.86596417427063\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t = time.time()\n",
    "ppca.compute_leaves_covariance()\n",
    "\n",
    "print('Data covariance computation + inversion took {}'.format(time.time() - t))"
   ]
  },
  {
   "source": [
    "***Posterior mean and covariance***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean, posterior_cov = ppca.compute_posterior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Posterior predictive density***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictive_mean, predictive_cov = ppca.compute_posterior_predictive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary: Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1: Unweighted Average of gene expression in Clade\n",
    "\n",
    "The simple idea here is to impute the value of an internal node, with the (un)weighted average of the gene expression values of the leaves, taking the query internal node as the root of the subtree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_avg = avg_weighted_baseline(tree=tree, \n",
    "                                    weighted=False, \n",
    "                                    X=ppca.X,\n",
    "                                    rounding=False\n",
    "                                   )\n",
    "\n",
    "#get internal nodes\n",
    "avg_X = np.array([x for x in imputed_avg.values()]).reshape(-1, ppca.X.shape[1])\n",
    "internal_avg_X, _, _ = get_internal(avg_X, ppca.mu, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2: (groundtruth) posterior predictive density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputed_ppca = {}\n",
    "#for n in tree.traverse('levelorder'):\n",
    "#    if not n.is_leaf():\n",
    "#        samples = np.array([np.random.multivariate_normal(mean=predictive_mean[n.name],\n",
    "#                                                            cov=predictive_cov[n.name])\n",
    "#                           for i in range(20)])\n",
    "#        imputed_ppca[n.name] = np.mean(samples, axis=0)\n",
    "\n",
    "#internal_ppca_X = np.array([x for x in imputed_ppca.values()]).reshape(-1, ppca.X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 3: Approximation through Message Passing (Oracle)\n",
    "\n",
    "\n",
    "i.e, \n",
    "\n",
    "1. sample from $z_1, ..., z_n \\sim p(z_1, ..., z_n|x_1, ..., x_n)$ (conditionning formula)\n",
    "2. impute $z_i \\sim p(z_i | z_1, ..., z_n)$ (Message Passing)\n",
    "3. Decode $p(x_i|z_i) = W z_i + \\sigma^2 I_P$ (Generative model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean_corr, posterior_cov_corr = ppca.compute_correlated_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "posterior_cov_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external/dataset/ppca.py:357: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  cov=posterior_cov).reshape(-1, self.latent) for i in range(sample_size)])\n",
      "go\n",
      "[2021-05-09 23:25:17,800] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-09 23:25:17,802] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-09 23:25:17,804] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-09 23:25:17,817] INFO - scvi.dataset.dataset | Merging datasets. Input objects are modified in place.\n",
      "[2021-05-09 23:25:17,819] INFO - scvi.dataset.dataset | Gene names and cell measurement names are assumed to have a non-null intersection between datasets.\n",
      "[2021-05-09 23:25:17,821] INFO - scvi.dataset.dataset | Keeping 100 genes\n",
      "[2021-05-09 23:25:17,823] WARNING - scvi.dataset.dataset | X contains continuous and/or negative values. Please use raw UMI/read counts with scVI\n",
      "[2021-05-09 23:25:17,825] INFO - scvi.dataset.dataset | Computing the library size for the new data\n",
      "[2021-05-09 23:25:17,827] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-09 23:25:17,829] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-09 23:25:17,831] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-09 23:25:17,833] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-09 23:25:17,835] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-09 23:25:17,837] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-09 23:25:17,839] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n"
     ]
    }
   ],
   "source": [
    "imputed_mp, imputed_z_mp, predictive_mean_z, predictive_cov_z  = ppca.compute_approx_posterior_predictive(iid=False, use_MP=True, sample_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_X = np.array([x for x in imputed_mp.values()]).reshape(-1, ppca.X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 4: Approximation through Message Passing + iid posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e, \n",
    "\n",
    "1. sample from marginal conditional $z_l \\sim p(z_l|x_1) \\forall l \\in (1, ...,L)$ (conditionning formula)\n",
    "2. impute $z_i \\sim p(z_i | z_1, ..., z_n)$ (Message Passing)\n",
    "3. Decode $p(x_i|z_i) = W z_i + \\sigma^2 I_P$ (Generative model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external/dataset/ppca.py:364: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  cov=posterior_cov[k]) for i in range(sample_size)])\n",
      "go\n",
      "[2021-05-09 23:32:16,734] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-09 23:32:16,736] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-09 23:32:16,737] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-09 23:32:16,743] INFO - scvi.dataset.dataset | Merging datasets. Input objects are modified in place.\n",
      "[2021-05-09 23:32:16,744] INFO - scvi.dataset.dataset | Gene names and cell measurement names are assumed to have a non-null intersection between datasets.\n",
      "[2021-05-09 23:32:16,745] INFO - scvi.dataset.dataset | Keeping 100 genes\n",
      "[2021-05-09 23:32:16,746] WARNING - scvi.dataset.dataset | X contains continuous and/or negative values. Please use raw UMI/read counts with scVI\n",
      "[2021-05-09 23:32:16,747] INFO - scvi.dataset.dataset | Computing the library size for the new data\n",
      "[2021-05-09 23:32:16,750] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-09 23:32:16,751] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-09 23:32:16,752] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-09 23:32:16,754] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-09 23:32:16,755] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-09 23:32:16,757] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-09 23:32:16,759] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n"
     ]
    }
   ],
   "source": [
    "imputed_mp2, imputed_z_mp2, predictive_mean_z2, predictive_cov_z2  = ppca.compute_approx_posterior_predictive(iid=True, use_MP=True, sample_size=200)\n",
    "imputed_X2 = np.array([x for x in imputed_mp2.values()]).reshape(-1, ppca.X.shape[1])"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 5: Gaussian VAE decoded averaged latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2021-05-09 23:25:34,314] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-09 23:25:34,315] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-09 23:25:34,316] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n"
     ]
    }
   ],
   "source": [
    "# anndata\n",
    "gene_dataset = GeneExpressionDataset()\n",
    "gene_dataset.populate_from_data(leaves_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 400\n",
    "\n",
    "vae = GaussianVAE(gene_dataset.nb_genes,\n",
    "                  n_hidden=64,\n",
    "                  n_layers=1,\n",
    "                  n_latent=ppca.latent,\n",
    "                  sigma_ldvae=None\n",
    "              )\n",
    "\n",
    "#new_weight = torch.from_numpy(ppca.W).float()\n",
    "\n",
    "#with torch.no_grad():\n",
    "    #vae.decoder.factor_regressor.fc_layers[0][0].weight = torch.nn.Parameter(new_weight)\n",
    "    \n",
    "#for param in vae.decoder.factor_regressor.fc_layers[0][0].parameters():\n",
    "#    param.requires_grad = False\n",
    "    \n",
    "#vae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance is 8.438525321796481\n"
     ]
    }
   ],
   "source": [
    "cuda_z = torch.from_numpy(leaves_z).float().to('cuda:0')\n",
    "p_m, p_v = vae.decoder.forward( torch.from_numpy(leaves_z).float())\n",
    "p_m = p_m.detach().cpu().numpy()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(p_m, mu)\n",
    "print(\"the distance is {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "\n",
    "trainer = GaussianTrainer(model=vae,\n",
    "                          gene_dataset=gene_dataset,\n",
    "                          train_size=1.0,\n",
    "                          use_cuda=use_cuda,\n",
    "                          frequency=10,\n",
    "                          n_epochs_kl_warmup=None,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "computing elbo\n",
      "ELBO: 63088.1171875\n",
      "computing elbo\n",
      "ELBO: 62904.734375\n",
      "computing elbo\n",
      "ELBO: 63180.953125\n",
      "training:   2%|▏         | 9/400 [00:00<00:04, 88.79it/s]computing elbo\n",
      "ELBO: 43775.8671875\n",
      "computing elbo\n",
      "ELBO: 43905.18359375\n",
      "computing elbo\n",
      "ELBO: 43930.2578125\n",
      "training:   4%|▍         | 18/400 [00:00<00:04, 78.64it/s]computing elbo\n",
      "ELBO: 35067.76953125\n",
      "computing elbo\n",
      "ELBO: 35050.078125\n",
      "computing elbo\n",
      "ELBO: 35004.34375\n",
      "training:   6%|▋         | 26/400 [00:00<00:05, 68.83it/s]computing elbo\n",
      "ELBO: 29081.15234375\n",
      "computing elbo\n",
      "ELBO: 29130.7734375\n",
      "computing elbo\n",
      "ELBO: 29184.95703125\n",
      "training:   8%|▊         | 34/400 [00:00<00:05, 71.59it/s]computing elbo\n",
      "ELBO: 27214.595703125\n",
      "computing elbo\n",
      "ELBO: 27207.9921875\n",
      "computing elbo\n",
      "ELBO: 27186.078125\n",
      "training:  10%|█         | 42/400 [00:00<00:05, 67.30it/s]computing elbo\n",
      "ELBO: 23923.00390625\n",
      "computing elbo\n",
      "ELBO: 23949.57421875\n",
      "computing elbo\n",
      "ELBO: 23939.91015625\n",
      "training:  12%|█▎        | 50/400 [00:00<00:05, 69.75it/s]computing elbo\n",
      "ELBO: 23054.4375\n",
      "computing elbo\n",
      "ELBO: 23029.478515625\n",
      "computing elbo\n",
      "ELBO: 23050.82421875\n",
      "training:  16%|█▌        | 62/400 [00:00<00:04, 83.58it/s]computing elbo\n",
      "ELBO: 22283.44921875\n",
      "computing elbo\n",
      "ELBO: 22248.232421875\n",
      "computing elbo\n",
      "ELBO: 22246.826171875\n",
      "training:  18%|█▊        | 74/400 [00:00<00:03, 93.32it/s]computing elbo\n",
      "ELBO: 21013.84375\n",
      "computing elbo\n",
      "ELBO: 21013.0\n",
      "computing elbo\n",
      "ELBO: 21044.921875\n",
      "training:  21%|██        | 84/400 [00:01<00:03, 92.16it/s]computing elbo\n",
      "ELBO: 20214.498046875\n",
      "computing elbo\n",
      "ELBO: 20296.099609375\n",
      "computing elbo\n",
      "ELBO: 20215.0\n",
      "training:  24%|██▎       | 94/400 [00:01<00:03, 83.14it/s]computing elbo\n",
      "ELBO: 19651.51171875\n",
      "computing elbo\n",
      "ELBO: 19628.66015625\n",
      "computing elbo\n",
      "ELBO: 19711.0859375\n",
      "training:  26%|██▌       | 103/400 [00:01<00:03, 78.75it/s]computing elbo\n",
      "ELBO: 19212.5234375\n",
      "computing elbo\n",
      "ELBO: 19145.5859375\n",
      "computing elbo\n",
      "ELBO: 19166.208984375\n",
      "training:  28%|██▊       | 112/400 [00:01<00:03, 80.80it/s]computing elbo\n",
      "ELBO: 18851.841796875\n",
      "computing elbo\n",
      "ELBO: 18894.642578125\n",
      "computing elbo\n",
      "ELBO: 18846.78515625\n",
      "training:  30%|███       | 122/400 [00:01<00:03, 84.44it/s]computing elbo\n",
      "ELBO: 18426.521484375\n",
      "computing elbo\n",
      "ELBO: 18372.82421875\n",
      "computing elbo\n",
      "ELBO: 18398.9453125\n",
      "training:  35%|███▍      | 139/400 [00:01<00:03, 75.80it/s]computing elbo\n",
      "ELBO: 18316.87890625\n",
      "computing elbo\n",
      "ELBO: 18365.8828125\n",
      "computing elbo\n",
      "ELBO: 18327.46484375\n",
      "training:  37%|███▋      | 147/400 [00:01<00:03, 74.51it/s]computing elbo\n",
      "ELBO: 18124.2265625\n",
      "computing elbo\n",
      "ELBO: 18194.435546875\n",
      "computing elbo\n",
      "ELBO: 18211.90625\n",
      "training:  39%|███▉      | 155/400 [00:01<00:03, 74.11it/s]computing elbo\n",
      "ELBO: 18111.96875\n",
      "computing elbo\n",
      "ELBO: 18098.236328125\n",
      "computing elbo\n",
      "ELBO: 18135.875\n",
      "training:  41%|████      | 163/400 [00:02<00:03, 71.76it/s]computing elbo\n",
      "ELBO: 17624.01953125\n",
      "computing elbo\n",
      "ELBO: 17591.64453125\n",
      "computing elbo\n",
      "ELBO: 17632.8046875\n",
      "training:  45%|████▍     | 179/400 [00:02<00:03, 72.51it/s]computing elbo\n",
      "ELBO: 17448.640625\n",
      "computing elbo\n",
      "ELBO: 17426.9375\n",
      "computing elbo\n",
      "ELBO: 17421.337890625\n",
      "training:  47%|████▋     | 187/400 [00:02<00:02, 74.57it/s]computing elbo\n",
      "ELBO: 17529.03125\n",
      "computing elbo\n",
      "ELBO: 17457.6796875\n",
      "computing elbo\n",
      "ELBO: 17421.68359375\n",
      "training:  49%|████▉     | 195/400 [00:02<00:02, 72.97it/s]computing elbo\n",
      "ELBO: 17368.828125\n",
      "computing elbo\n",
      "ELBO: 17434.6015625\n",
      "computing elbo\n",
      "ELBO: 17344.880859375\n",
      "training:  51%|█████     | 203/400 [00:02<00:02, 70.91it/s]computing elbo\n",
      "ELBO: 17454.345703125\n",
      "computing elbo\n",
      "ELBO: 17440.22265625\n",
      "computing elbo\n",
      "ELBO: 17457.87890625\n",
      "training:  55%|█████▍    | 219/400 [00:02<00:02, 74.17it/s]computing elbo\n",
      "ELBO: 17463.380859375\n",
      "computing elbo\n",
      "ELBO: 17587.705078125\n",
      "computing elbo\n",
      "ELBO: 17463.728515625\n",
      "training:  57%|█████▋    | 227/400 [00:02<00:02, 73.05it/s]computing elbo\n",
      "ELBO: 17028.720703125\n",
      "computing elbo\n",
      "ELBO: 16979.224609375\n",
      "computing elbo\n",
      "ELBO: 16937.248046875\n",
      "training:  59%|█████▉    | 235/400 [00:03<00:02, 71.20it/s]computing elbo\n",
      "ELBO: 16808.9921875\n",
      "computing elbo\n",
      "ELBO: 16826.185546875\n",
      "computing elbo\n",
      "ELBO: 16864.626953125\n",
      "training:  61%|██████    | 243/400 [00:03<00:02, 68.32it/s]computing elbo\n",
      "ELBO: 16689.1015625\n",
      "computing elbo\n",
      "ELBO: 16772.6171875\n",
      "computing elbo\n",
      "ELBO: 16743.212890625\n",
      "training:  63%|██████▎   | 251/400 [00:03<00:02, 71.16it/s]computing elbo\n",
      "ELBO: 16828.703125\n",
      "computing elbo\n",
      "ELBO: 16823.72265625\n",
      "computing elbo\n",
      "ELBO: 16939.8359375\n",
      "training:  65%|██████▌   | 260/400 [00:03<00:01, 72.10it/s]computing elbo\n",
      "ELBO: 16822.390625\n",
      "computing elbo\n",
      "ELBO: 16864.91796875\n",
      "computing elbo\n",
      "ELBO: 16845.908203125\n",
      "training:  68%|██████▊   | 270/400 [00:03<00:01, 77.49it/s]computing elbo\n",
      "ELBO: 16945.40625\n",
      "computing elbo\n",
      "ELBO: 16828.12890625\n",
      "computing elbo\n",
      "ELBO: 16939.712890625\n",
      "training:  71%|███████   | 284/400 [00:03<00:01, 93.43it/s]computing elbo\n",
      "ELBO: 16731.27734375\n",
      "computing elbo\n",
      "ELBO: 16759.921875\n",
      "computing elbo\n",
      "ELBO: 16855.8359375\n",
      "training:  75%|███████▍  | 299/400 [00:03<00:00, 108.14it/s]computing elbo\n",
      "ELBO: 16998.578125\n",
      "computing elbo\n",
      "ELBO: 17058.009765625\n",
      "computing elbo\n",
      "ELBO: 17191.45703125\n",
      "computing elbo\n",
      "ELBO: 16967.109375\n",
      "computing elbo\n",
      "ELBO: 16940.736328125\n",
      "computing elbo\n",
      "ELBO: 16940.798828125\n",
      "training:  78%|███████▊  | 310/400 [00:03<00:00, 96.39it/s] computing elbo\n",
      "ELBO: 16815.984375\n",
      "computing elbo\n",
      "ELBO: 16851.51171875\n",
      "computing elbo\n",
      "ELBO: 16831.86328125\n",
      "training:  81%|████████  | 324/400 [00:04<00:00, 107.81it/s]computing elbo\n",
      "ELBO: 16705.91796875\n",
      "computing elbo\n",
      "ELBO: 16856.15625\n",
      "computing elbo\n",
      "ELBO: 16870.25\n",
      "training:  84%|████████▍ | 338/400 [00:04<00:00, 115.39it/s]computing elbo\n",
      "ELBO: 16569.9296875\n",
      "computing elbo\n",
      "ELBO: 16575.93359375\n",
      "computing elbo\n",
      "ELBO: 16583.22265625\n",
      "computing elbo\n",
      "ELBO: 16465.08984375\n",
      "computing elbo\n",
      "ELBO: 16542.46875\n",
      "computing elbo\n",
      "ELBO: 16434.51953125\n",
      "training:  88%|████████▊ | 350/400 [00:04<00:00, 112.20it/s]computing elbo\n",
      "ELBO: 16576.0\n",
      "computing elbo\n",
      "ELBO: 16578.115234375\n",
      "computing elbo\n",
      "ELBO: 16485.94140625\n",
      "training:  90%|█████████ | 362/400 [00:04<00:00, 100.30it/s]computing elbo\n",
      "ELBO: 16231.9521484375\n",
      "computing elbo\n",
      "ELBO: 16196.0693359375\n",
      "computing elbo\n",
      "ELBO: 16180.6162109375\n",
      "training:  94%|█████████▍| 377/400 [00:04<00:00, 112.76it/s]computing elbo\n",
      "ELBO: 16027.974609375\n",
      "computing elbo\n",
      "ELBO: 16020.3671875\n",
      "computing elbo\n",
      "ELBO: 16101.37890625\n",
      "computing elbo\n",
      "ELBO: 15920.7666015625\n",
      "computing elbo\n",
      "ELBO: 15874.5361328125\n",
      "computing elbo\n",
      "ELBO: 15869.2421875\n",
      "training:  98%|█████████▊| 391/400 [00:04<00:00, 119.46it/s]computing elbo\n",
      "ELBO: 15988.35546875\n",
      "computing elbo\n",
      "ELBO: 16208.796875\n",
      "computing elbo\n",
      "ELBO: 16050.0439453125\n",
      "training: 100%|██████████| 400/400 [00:04<00:00, 85.97it/s] \n"
     ]
    }
   ],
   "source": [
    "# train VAE\n",
    "trainer.train(n_epochs=n_epochs, lr=1e-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbo_train = trainer.history[\"elbo_train_set\"]\n",
    "x = np.linspace(0, 100, (len(elbo_train)))\n",
    "plt.plot(np.log(elbo_train), \n",
    "         label=\"train\", color='blue',\n",
    "         linestyle=':',\n",
    "         linewidth=3\n",
    "        )\n",
    "        \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.legend()\n",
    "plt.title(\"Train history Gaussian VAE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.105403640113538"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "posterior =  trainer.create_posterior(model=vae,\n",
    "                                      gene_dataset=gene_dataset\n",
    "                                      )\n",
    "                                      \n",
    "qz_m, qz_v = posterior.get_latent(give_mean=True, give_cov=True)\n",
    "mean_squared_error(qz_m, leaves_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "imputed_avg_vae, imputed_avg_z, imputed_avg_cov_z = avg_baseline_z(tree=tree,\n",
    "                                 model=vae,\n",
    "                                 posterior=posterior,\n",
    "                                 weighted=False,\n",
    "                                 n_samples_z=1,\n",
    "                                 gaussian=True,\n",
    "                                 use_cuda=True\n",
    "                                )\n",
    "\n",
    "internal_vae_X = np.array([x for x in imputed_avg_vae.values()]).reshape(-1, ppca.X.shape[1])\n",
    "internal_vae_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Our Model: CascVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "go\n",
      "[2021-05-09 23:26:35,714] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-09 23:26:35,715] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-09 23:26:35,717] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-09 23:26:35,734] INFO - scvi.dataset.dataset | Merging datasets. Input objects are modified in place.\n",
      "[2021-05-09 23:26:35,735] INFO - scvi.dataset.dataset | Gene names and cell measurement names are assumed to have a non-null intersection between datasets.\n",
      "[2021-05-09 23:26:35,737] INFO - scvi.dataset.dataset | Keeping 100 genes\n",
      "[2021-05-09 23:26:35,739] WARNING - scvi.dataset.dataset | X contains continuous and/or negative values. Please use raw UMI/read counts with scVI\n",
      "[2021-05-09 23:26:35,740] INFO - scvi.dataset.dataset | Computing the library size for the new data\n",
      "[2021-05-09 23:26:35,743] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-09 23:26:35,745] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-09 23:26:35,747] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-09 23:26:35,749] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n",
      "[2021-05-09 23:26:35,750] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-09 23:26:35,751] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-09 23:26:35,755] WARNING - scvi.dataset.dataset | This dataset has some empty cells, this might fail scVI inference.Data should be filtered with `my_dataset.filter_cells_by_count()\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GeneExpressionDataset object with n_cells x nb_genes = 100 x 100\n",
       "    gene_attribute_names: 'gene_names'\n",
       "    cell_attribute_names: 'labels', 'local_means', 'batch_indices', 'barcodes', 'local_vars'\n",
       "    cell_categorical_attribute_names: 'batch_indices', 'labels'"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "adata = AnnData(leaves_X)\n",
    "adata.obs_names = [n.name for n in tree.traverse('levelorder') if n.is_leaf()]\n",
    "scvi_dataset = AnnDatasetFromAnnData(adata, filtering=False)\n",
    "scvi_dataset.initialize_cell_attribute('barcodes', adata.obs_names)\n",
    "\n",
    "#TreeDataset\n",
    "cas_dataset = TreeDataset(scvi_dataset, tree=tree, filtering=False)\n",
    "cas_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "use_MP = True\n",
    "\n",
    "treevae = GaussianTreeVAE(cas_dataset.nb_genes,\n",
    "              tree = cas_dataset.tree,\n",
    "              n_latent=ppca.latent,\n",
    "              n_hidden=64,\n",
    "              n_layers=1,\n",
    "              prior_t = branch_length,\n",
    "              use_MP=use_MP,\n",
    "              sigma_ldvae=None\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Freezing the decoder***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_weight = torch.from_numpy(ppca.W).float()\n",
    "\n",
    "#with torch.no_grad():\n",
    "    #treevae.decoder.factor_regressor.fc_layers[0][0].weight = torch.nn.Parameter(new_weight)\n",
    "    \n",
    "#for param in treevae.decoder.factor_regressor.fc_layers[0][0].parameters():\n",
    "    #param.requires_grad = False\n",
    "    \n",
    "#treevae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert(treevae.decoder.factor_regressor.fc_layers[0][0].weight.numpy().all() == ppca.W.T.all())"
   ]
  },
  {
   "source": [
    "\n",
    "***Are we able to generate the gene expression data by decoding the simulated latent space?***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_m, p_v = treevae.decoder.forward(torch.from_numpy(leaves_z).float())\n",
    "#p_m = p_m.detach().numpy()\n",
    "#p_m.shape, mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse = mean_squared_error(p_m, mu)\n",
    "#print(\"the distance is {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Training***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_leaves:  [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99]]\ntest_leaves:  []\nvalidation leaves:  []\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "lr = 1e-2\n",
    "lambda_ = 1.0\n",
    "freq = 10\n",
    "\n",
    "tree_trainer = GaussianTreeTrainer(\n",
    "        model = treevae,\n",
    "        gene_dataset = cas_dataset,\n",
    "        lambda_ = lambda_,\n",
    "        train_size=1.0,\n",
    "        test_size=0,\n",
    "        use_cuda=use_cuda,\n",
    "        frequency=freq,\n",
    "        n_epochs_kl_warmup=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "computing elbo\n",
      "training:   1%|▏         | 7/500 [00:00<00:26, 18.30it/s]computing elbo\n",
      "training:   4%|▍         | 19/500 [00:00<00:21, 22.65it/s]computing elbo\n",
      "training:   6%|▌         | 28/500 [00:01<00:19, 23.86it/s]computing elbo\n",
      "training:   7%|▋         | 37/500 [00:01<00:21, 21.93it/s]computing elbo\n",
      "training:  10%|▉         | 49/500 [00:02<00:18, 24.30it/s]computing elbo\n",
      "training:  12%|█▏        | 58/500 [00:02<00:20, 21.32it/s]computing elbo\n",
      "training:  13%|█▎        | 67/500 [00:03<00:18, 22.98it/s]computing elbo\n",
      "training:  16%|█▌        | 79/500 [00:03<00:17, 24.35it/s]computing elbo\n",
      "training:  18%|█▊        | 88/500 [00:03<00:18, 22.44it/s]computing elbo\n",
      "training:  19%|█▉        | 97/500 [00:04<00:17, 22.79it/s]computing elbo\n",
      "training:  22%|██▏       | 109/500 [00:04<00:16, 23.29it/s]computing elbo\n",
      "training:  24%|██▎       | 118/500 [00:05<00:16, 23.61it/s]computing elbo\n",
      "training:  25%|██▌       | 127/500 [00:05<00:16, 22.36it/s]computing elbo\n",
      "training:  28%|██▊       | 139/500 [00:06<00:15, 23.71it/s]computing elbo\n",
      "training:  30%|██▉       | 148/500 [00:06<00:15, 22.29it/s]computing elbo\n",
      "training:  31%|███▏      | 157/500 [00:06<00:14, 23.22it/s]computing elbo\n",
      "training:  34%|███▍      | 169/500 [00:07<00:14, 23.34it/s]computing elbo\n",
      "training:  36%|███▌      | 178/500 [00:07<00:13, 23.49it/s]computing elbo\n",
      "training:  37%|███▋      | 187/500 [00:08<00:14, 22.00it/s]computing elbo\n",
      "training:  40%|███▉      | 199/500 [00:08<00:12, 23.50it/s]computing elbo\n",
      "training:  42%|████▏     | 208/500 [00:09<00:12, 23.56it/s]computing elbo\n",
      "training:  43%|████▎     | 217/500 [00:09<00:11, 24.18it/s]computing elbo\n",
      "training:  46%|████▌     | 229/500 [00:10<00:11, 22.90it/s]computing elbo\n",
      "training:  48%|████▊     | 238/500 [00:10<00:10, 23.96it/s]computing elbo\n",
      "training:  49%|████▉     | 247/500 [00:10<00:10, 23.64it/s]computing elbo\n",
      "training:  52%|█████▏    | 259/500 [00:11<00:11, 21.71it/s]computing elbo\n",
      "training:  54%|█████▎    | 268/500 [00:11<00:10, 21.17it/s]computing elbo\n",
      "training:  55%|█████▌    | 277/500 [00:12<00:09, 23.12it/s]computing elbo\n",
      "training:  58%|█████▊    | 289/500 [00:12<00:08, 24.08it/s]computing elbo\n",
      "training:  60%|█████▉    | 298/500 [00:13<00:09, 21.11it/s]computing elbo\n",
      "training:  61%|██████▏   | 307/500 [00:13<00:09, 21.25it/s]computing elbo\n",
      "training:  64%|██████▍   | 319/500 [00:14<00:07, 23.85it/s]computing elbo\n",
      "training:  66%|██████▌   | 328/500 [00:14<00:07, 24.22it/s]computing elbo\n",
      "training:  67%|██████▋   | 337/500 [00:14<00:06, 24.15it/s]computing elbo\n",
      "training:  70%|██████▉   | 349/500 [00:15<00:06, 24.08it/s]computing elbo\n",
      "training:  72%|███████▏  | 358/500 [00:15<00:06, 23.44it/s]computing elbo\n",
      "training:  73%|███████▎  | 367/500 [00:16<00:05, 23.34it/s]computing elbo\n",
      "training:  76%|███████▌  | 379/500 [00:16<00:05, 22.82it/s]computing elbo\n",
      "training:  78%|███████▊  | 388/500 [00:17<00:04, 23.70it/s]computing elbo\n",
      "training:  79%|███████▉  | 397/500 [00:17<00:04, 24.08it/s]computing elbo\n",
      "training:  82%|████████▏ | 409/500 [00:18<00:03, 24.50it/s]computing elbo\n",
      "training:  84%|████████▎ | 418/500 [00:18<00:03, 24.59it/s]computing elbo\n",
      "training:  85%|████████▌ | 427/500 [00:18<00:02, 24.98it/s]computing elbo\n",
      "training:  88%|████████▊ | 439/500 [00:19<00:02, 24.27it/s]computing elbo\n",
      "training:  90%|████████▉ | 448/500 [00:19<00:02, 23.68it/s]computing elbo\n",
      "training:  91%|█████████▏| 457/500 [00:20<00:01, 23.81it/s]computing elbo\n",
      "training:  94%|█████████▍| 469/500 [00:20<00:01, 23.73it/s]computing elbo\n",
      "training:  96%|█████████▌| 478/500 [00:21<00:01, 21.89it/s]computing elbo\n",
      "training:  97%|█████████▋| 487/500 [00:21<00:00, 21.15it/s]computing elbo\n",
      "training: 100%|█████████▉| 499/500 [00:21<00:00, 23.95it/s]computing elbo\n",
      "training: 100%|██████████| 500/500 [00:21<00:00, 22.73it/s]\n"
     ]
    }
   ],
   "source": [
    "tree_trainer.train(n_epochs=n_epochs,\n",
    "              lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dashboard(tree_trainer, treevae.encoder_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100, 5), (100, 5))"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "tree_posterior = tree_trainer.create_posterior(model=treevae,\n",
    "                                              gene_dataset=cas_dataset,\n",
    "                                               clades=tree_trainer.clades,\n",
    "                                               indices=np.arange(len(cas_dataset))\n",
    "                                              )\n",
    "tree_latent = tree_posterior.get_latent()\n",
    "tree_latent.shape, internal_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.2012335955775315"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "tree_latent = tree_posterior.get_latent()\n",
    "mean_squared_error(tree_latent, leaves_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Missing Value Imputation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CascVI imputations\n",
    "imputed = {}\n",
    "imputed_z = {}\n",
    "imputed_cov_z = {}\n",
    "imputed_mean_z = {}\n",
    "\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        imputed[n.name], imputed_z[n.name], imputed_mean_z[n.name], imputed_cov_z[n.name] = tree_posterior.imputation_internal(query_node=n.name,\n",
    "                                                                                                                                pp_averaging=200,\n",
    "                                                                                                                                z_averaging=100,\n",
    "                                                                                                                                give_mean=True                           \n",
    "                                                                                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_treevae_X = [x for x in imputed.values()]\n",
    "internal_treevae_X = np.array(internal_treevae_X).reshape(-1, cas_dataset.X.shape[1])"
   ]
  },
  {
   "source": [
    "# Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation 1.a.i: MSE/MAE L2/L1 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from external.utils.metrics import mse\n",
    "\n",
    "data = {'groundtruth': imputed_X, 'average': internal_avg_X,\n",
    "        'gaussian VAE': internal_vae_X\n",
    "        , 'gaussian treeVAE': internal_treevae_X\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "L2\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      average  gaussian VAE  gaussian treeVAE\n",
       "MSE  0.784928      2.205904          0.530174\n",
       "std  0.389073      0.662961          0.208879"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>average</th>\n      <th>gaussian VAE</th>\n      <th>gaussian treeVAE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MSE</th>\n      <td>0.784928</td>\n      <td>2.205904</td>\n      <td>0.530174</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.389073</td>\n      <td>0.662961</td>\n      <td>0.208879</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "results = mse(data=data, metric='MSE')\n",
    "print('L2')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "L1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          average  gaussian VAE  gaussian treeVAE\n",
       "MSE  3.934260e+01  1.153276e+02      6.532607e+01\n",
       "std  7.105427e-15  1.421085e-14      1.421085e-14"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>average</th>\n      <th>gaussian VAE</th>\n      <th>gaussian treeVAE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MSE</th>\n      <td>3.934260e+01</td>\n      <td>1.153276e+02</td>\n      <td>6.532607e+01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7.105427e-15</td>\n      <td>1.421085e-14</td>\n      <td>1.421085e-14</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "results = mse(data=data, metric='L1')\n",
    "print('L1')\n",
    "results"
   ]
  },
  {
   "source": [
    "## Evaluation 1.a.ii: Correlations "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'groundtruth': imputed_X, 'average': internal_avg_X,\n",
    "        'gaussian VAE': internal_vae_X\n",
    "        , 'gaussian treeVAE': internal_treevae_X\n",
    "       }\n",
    "\n",
    "df1 = correlations(data, 'None', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gene-gene correlation\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Spearman CC  Pearson CC  Kendal Tau CC\n",
       "average              0.845984    0.871949       0.678044\n",
       "gaussian VAE         0.748121    0.765380       0.569386\n",
       "gaussian treeVAE     0.887167    0.914792       0.734691"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendal Tau CC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>average</th>\n      <td>0.845984</td>\n      <td>0.871949</td>\n      <td>0.678044</td>\n    </tr>\n    <tr>\n      <th>gaussian VAE</th>\n      <td>0.748121</td>\n      <td>0.765380</td>\n      <td>0.569386</td>\n    </tr>\n    <tr>\n      <th>gaussian treeVAE</th>\n      <td>0.887167</td>\n      <td>0.914792</td>\n      <td>0.734691</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "data_dict = {}\n",
    "methods = list(data.keys())[1:]\n",
    "for method in methods:\n",
    "    data_dict[method] = list(df1[df1.Method==method].mean())\n",
    "results_corr = pd.DataFrame.from_dict(data_dict, orient='index', columns=['Spearman CC', 'Pearson CC', 'Kendal Tau CC'])\n",
    "\n",
    "print('gene-gene correlation')\n",
    "results_corr.head(10)"
   ]
  },
  {
   "source": [
    "## Evaluation 1.a.iii: MSE/MAE (L1/L2) of variance in latent space"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_var = {'groundtruth': predictive_cov_z, 'gaussian VAE':imputed_avg_cov_z, 'gaussian treeVAE': imputed_cov_z}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 181
    }
   ],
   "source": [
    "predictive_cov_z['0'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7.294980110242236e-05, 0.012943967976536946)"
      ]
     },
     "metadata": {},
     "execution_count": 175
    }
   ],
   "source": [
    "def mean_variance_latent(tree, predictive_cov_z, imputed_avg_cov_z, imputed_cov_z):\n",
    "    mse_treevae = 0\n",
    "    mse_vae = 0\n",
    "    N = 0\n",
    "    for n in tree.traverse('levelorder'):\n",
    "        if not n.is_leaf():\n",
    "            true_cov = np.diag(predictive_cov_z[n.name])\n",
    "            vae_cov = imputed_avg_cov_z[n.name].cpu().numpy()\n",
    "            treevae_cov = imputed_cov_z[n.name] * np.ones((d))\n",
    "\n",
    "            mse_treevae += mean_squared_error(true_cov, treevae_cov)\n",
    "            mse_vae += mean_squared_error(true_cov, vae_cov)\n",
    "            N += 1\n",
    "    mse_treevae /= N\n",
    "    mse_vae /= N\n",
    "\n",
    "    return mse_treevae, mse_vae\n",
    "\n",
    "mean_variance_latent(tree, data_var, predictive_cov_z, imputed_avg_cov_z, imputed_cov_z)"
   ]
  },
  {
   "source": [
    "## Evaluation 1.a.iv: Averaged KL divergence (internal nodes)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***TreeVAE***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Kl divergence 22917.077406557542\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions import Normal, kl_divergence\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "kl_mean = 0\n",
    "N = 0\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        mean_true = normalize(np.array([predictive_mean_z[n.name].cpu().numpy()]))\n",
    "        cov_true = torch.diagonal(torch.from_numpy(predictive_cov_z[n.name]))\n",
    "        dist_true = Normal(torch.from_numpy(mean_true),\n",
    "                        cov_true\n",
    "                        )\n",
    "\n",
    "        # Approx\n",
    "        mean_approx = normalize(np.array([imputed_mean_z[n.name].cpu().numpy()]))                \n",
    "        dist_approx = Normal(torch.from_numpy(mean_approx),\n",
    "                        imputed_cov_z[n.name]* torch.ones((d,))\n",
    "                        )\n",
    "        kl_mean += kl_divergence(dist_true, dist_approx).sum()\n",
    "        N += 1\n",
    "kl_mean /= N\n",
    "print('Average Kl divergence {}'.format(kl_mean))"
   ]
  },
  {
   "source": [
    "***VAE***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Kl divergence 88.56559050523421\n"
     ]
    }
   ],
   "source": [
    "kl_mean = 0\n",
    "N = 0\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        cov_true = torch.diagonal(torch.from_numpy(predictive_cov_z[n.name]))\n",
    "        dist_true = Normal(predictive_mean_z[n.name],\n",
    "                        cov_true\n",
    "                        )\n",
    "                        \n",
    "        dist_approx = Normal(torch.from_numpy(imputed_avg_z[n.name]),\n",
    "                        torch.sqrt(imputed_avg_cov_z[n.name].cpu())\n",
    "                        )\n",
    "        kl_mean += torch.mean(kl_divergence(dist_true, dist_approx))\n",
    "        N += 1\n",
    "kl_mean /= N\n",
    "print('Average Kl divergence {}'.format(kl_mean))"
   ]
  },
  {
   "source": [
    "## Evaluation 1.a.v: Likelihood (internal nodes)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[-560.7132005861627, -385.35406114699333]"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def mean_posterior_lik(tree, predictive_mean_z, imputed_avg_z, imputed_mean_z, predictive_cov_z, imputed_avg_cov_z, imputed_cov_z):\n",
    "    treevae_lik = 0\n",
    "    vae_lik = 0\n",
    "    N = 0\n",
    "    for n in tree.traverse('levelorder'):\n",
    "        if not n.is_leaf():\n",
    "            # mean\n",
    "            true_mean = predictive_mean_z[n.name].cpu().numpy() \n",
    "            vae_mean = imputed_avg_z[n.name][0]\n",
    "            treevae_mean = imputed_mean_z[n.name].cpu().numpy()\n",
    "\n",
    "            # covariance\n",
    "            true_cov = np.diag(predictive_cov_z[n.name])\n",
    "            vae_cov = np.diag(imputed_avg_cov_z[n.name].cpu().numpy())\n",
    "            treevae_cov = np.diag(imputed_cov_z[n.name] * np.ones((d)))\n",
    "\n",
    "            sample_treevae = np.random.multivariate_normal(mean=treevae_mean,\n",
    "                                                            cov=treevae_cov)\n",
    "            sample_vae = np.random.multivariate_normal(mean=vae_mean,\n",
    "                                                        cov=vae_cov)\n",
    "\n",
    "            treevae_lik += multivariate_normal.logpdf(sample_treevae,\n",
    "                                                    true_mean,\n",
    "                                                    true_cov)\n",
    "            vae_lik += multivariate_normal.logpdf(sample_vae,\n",
    "                                                    true_mean,\n",
    "                                                    true_cov)\n",
    "            \n",
    "            N += 1\n",
    "\n",
    "    vae_lik /= N\n",
    "    treevae_lik /= N\n",
    "    return [vae_lik, treevae_lik]\n",
    "\n",
    "mean_posterior_lik(tree, predictive_mean_z, imputed_avg_z, imputed_mean_z, predictive_cov_z, imputed_avg_cov_z, imputed_cov_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd08038a79804d646dd36b3762b0d60c87c86d89e40c61f6758cc1d2f18aca59864",
   "display_name": "Python 3.7.10 64-bit ('scvi-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "8038a79804d646dd36b3762b0d60c87c86d89e40c61f6758cc1d2f18aca59864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}