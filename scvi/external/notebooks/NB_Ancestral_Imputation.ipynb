{
 "cells": [
  {
   "source": [
    "# 0. Standard imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline`\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('WebAgg')\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***import ete3 Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree\n",
    "\n",
    "tree_name = \"/home/eecs/khalil.ouardini/cas_scvi_topologies/newick_objects/500cells/high_fitness/topology1.nwk\"\n",
    "tree = Tree(tree_name, 1)\n",
    "\n",
    "for i, n in enumerate(tree.traverse('levelorder')):\n",
    "    n.add_features(index=i)\n",
    "    n.name = str(i)\n",
    "eps = 1e-3\n",
    "branch_length = {}\n",
    "for node in tree.traverse('levelorder'):\n",
    "    if node.is_root():\n",
    "        branch_length[node.name] = 0.0\n",
    "    else:\n",
    "        branch_length[node.name] = node.dist\n",
    "branch_length['prior_root'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_params_NB(mu, alpha):\n",
    "    \"\"\" \n",
    "    Convert mean/dispersion parameterization of a negative binomial to the ones scipy supports\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mu : float \n",
    "       Mean of NB distribution.\n",
    "    alpha : float\n",
    "       Overdispersion parameter used for variance calculation.\n",
    "\n",
    "    See https://en.wikipedia.org/wiki/Negative_binomial_distribution#Alternative_formulations\n",
    "    \"\"\"\n",
    "    var = mu + alpha * mu ** 2\n",
    "    p = (var - mu) / var\n",
    "    r = mu ** 2 / (var - mu)\n",
    "    return r, 1-p"
   ]
  },
  {
   "source": [
    "Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((array(4.82850859), array(7.1599581)), 4.828508585155636, 7.159958100847804)"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "mean = nb_glm.mu[1][0]\n",
    "var = mean + alpha * mean**2\n",
    "\n",
    "r, p = convert_params_NB(mean, alpha)\n",
    "nbinom.stats(r, p, moments='mv'), mean , var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "from anndata import AnnData\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from external.dataset.tree import TreeDataset, GeneExpressionDataset\n",
    "from external.dataset.poisson_glm import Poisson_GLM\n",
    "from external.dataset.anndataset import AnnDatasetFromAnnData\n",
    "\n",
    "# Models\n",
    "from models.vae import VAE\n",
    "import scanpy as sc\n",
    "from external.inference.tree_inference import TreeTrainer\n",
    "from inference.inference import UnsupervisedTrainer\n",
    "from inference import posterior\n",
    "from external.models.treevae import TreeVAE\n",
    "\n",
    "# Utils\n",
    "from external.utils.data_util import get_leaves, get_internal\n",
    "from external.utils.metrics import ks_pvalue, accuracy_imputation, correlations, knn_purity, knn_purity_stratified\n",
    "from external.utils.plots_util import plot_histograms, plot_scatter_mean, plot_ecdf_ks, plot_density\n",
    "from external.utils.plots_util import plot_losses, plot_elbo, plot_common_ancestor, plot_one_gene, training_dashboard\n",
    "from external.utils.baselines import avg_weighted_baseline, scvi_baseline, scvi_baseline_z, cascvi_baseline_z, avg_baseline_z, construct_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f94eeb4e9b0>"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "import torch\n",
    "    \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulations (Negative Binomial GLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 10\n",
    "g = 1000\n",
    "vis = False\n",
    "leaves_only = False\n",
    "var = 1.0\n",
    "negative_binomial = True\n",
    "# inverse dispersion parameter (inverse dispersion alpha  = 1 / theta controls how much variance we have in the simulations)\n",
    "alpha = 0.1\n",
    "\n",
    "nb_glm = Poisson_GLM(tree, g, d, vis, leaves_only, branch_length, alpha)\n",
    "\n",
    "nb_glm.simulate_latent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Generate gene expression count data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Negative Binomial simulations ===\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1000, 1000), (1000, 1000), (1000, 10), (1000,))"
      ]
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "source": [
    "nb_glm.simulate_ge(False)\n",
    "poisson_X = nb_glm.X\n",
    "nb_glm.simulate_ge(negative_binomial)\n",
    "\n",
    "# Quality Control (i.e Gene Filtering)\n",
    "#nb_glm.gene_qc()\n",
    "\n",
    "nb_glm.X.shape, poisson_X.shape, nb_glm.W.shape, nb_glm.beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "metadata": {},
     "execution_count": 238
    }
   ],
   "source": [
    "len(genes_to_inspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "v/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "n_samples = 40\n",
    "#idx = random.sample(range(1, 100), n_samples)\n",
    "idx = random.sample(genes_to_inspect, n_samples)\n",
    "\n",
    "n_rows = 4\n",
    "n_cols = int(n_samples / n_rows)\n",
    "\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(35, 15))\n",
    "\n",
    "h = 0\n",
    "for i in range(n_rows):\n",
    "    for j in range(n_cols):\n",
    "        k = idx[h]\n",
    "        h += 1\n",
    "        # density plots\n",
    "        sns.distplot(ax=ax[i][j], a=np.log(1 + poisson_X[:, k]), hist=False,\n",
    "                     kde=True, kde_kws={'shade': True}, label='Poisson')\n",
    "        sns.distplot(ax=ax[i][j], a=np.log(1 + nb_glm.X[:, k]), hist=False,\n",
    "                     kde=True, kde_kws={'shade': True}, label='NB')\n",
    "        # set title\n",
    "        ax[i][j].set_title('Gene ' + str(k))\n",
    "\n",
    "plt.legend()\n",
    "fig.suptitle(\"Combined gene density plots | dipsersion = {}\".format(alpha))\n",
    "plt.savefig('tmp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Binomial thinning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of dropouts: 0.439189\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of dropouts: {}\".format(np.mean(nb_glm.X == 0)))\n",
    "#glm.binomial_thinning(p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proportion of dropouts after Binomial thinning: 0.439189\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of dropouts after Binomial thinning: {}\".format(np.mean(nb_glm.X == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Get the data and the indexes at the leaves***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((500, 1000), (500, 1000), (500, 1000), (500, 1000), (500, 10))"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "# Latent vectors\n",
    "leaves_z, _, _ = get_leaves(nb_glm.z, nb_glm.mu, tree)\n",
    "\n",
    "#FIXED training set\n",
    "leaves_X, leaves_idx, mu = get_leaves(nb_glm.X, nb_glm.mu, tree)\n",
    "\n",
    "# internal nodes data (for imputation)\n",
    "internal_X, internal_idx, internal_mu = get_internal(nb_glm.X, nb_glm.mu, tree)\n",
    "\n",
    "leaves_X.shape, mu.shape, internal_X.shape, internal_mu.shape, leaves_z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fitting CascVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# anndata + gene and celle filtering\n",
    "adata = AnnData(leaves_X)\n",
    "leaves = [n for n in tree.traverse('levelorder') if n.is_leaf()]\n",
    "adata.obs_names = [n.name for n in leaves]\n",
    "#sc.pp.filter_genes(adata, min_counts=3)\n",
    "#sc.pp.filter_cells(adata, min_counts=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create a TreeDataset object***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "# treeVAE\n",
    "import copy\n",
    "\n",
    "tree_bis = copy.deepcopy(tree)\n",
    "scvi_dataset = AnnDatasetFromAnnData(adata, filtering=False)\n",
    "scvi_dataset.initialize_cell_attribute('barcodes', adata.obs_names)\n",
    "cas_dataset = TreeDataset(scvi_dataset, tree=tree_bis, filtering=False)\n",
    "\n",
    "# No batches beacause of the message passing\n",
    "use_cuda = True\n",
    "use_MP = True\n",
    "ldvae = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initialize model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "treevae = TreeVAE(cas_dataset.nb_genes,\n",
    "              tree = cas_dataset.tree,\n",
    "              n_latent=nb_glm.latent,\n",
    "              n_hidden=128,\n",
    "              n_layers=1,\n",
    "              reconstruction_loss='nb',\n",
    "              prior_t = branch_length,\n",
    "              ldvae = ldvae,\n",
    "              use_MP=use_MP\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "freeze = False\n",
    "if freeze:\n",
    "    new_weight = torch.from_numpy(glm.W).float()\n",
    "    new_bias = torch.from_numpy(glm.beta).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        treevae.decoder.factor_regressor.fc_layers[0][0].weight = torch.nn.Parameter(new_weight)\n",
    "        treevae.decoder.factor_regressor.fc_layers[0][0].bias = torch.nn.Parameter(new_bias)\n",
    "        \n",
    "    for param in treevae.decoder.factor_regressor.fc_layers[0][0].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert(treevae.decoder.factor_regressor.fc_layers[0][0].weight.numpy().all() == glm.W.T.all())\n",
    "#assert(treevae.decoder.factor_regressor.fc_layers[0][0].bias.numpy().all() == glm.beta.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Are we able to generate the gene expression data by decoding the simulated latent space?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance between the Poisson and the NB means is 106169.31102319187\n"
     ]
    }
   ],
   "source": [
    "px_scale, px_rate, raw_px_scale = treevae.decoder(treevae.dispersion,\n",
    "                                        torch.from_numpy(leaves_z).float(),\n",
    "                                        torch.from_numpy(np.array([np.log(10000)])).float()\n",
    "                                       )\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if ldvae:\n",
    "    foo = np.clip(a=np.exp(raw_px_scale.detach().cpu().numpy()),\n",
    "            a_min=0,\n",
    "            a_max=1e8\n",
    "    )\n",
    "    mse = mean_squared_error(mu, foo)\n",
    "else:\n",
    "    mse = mean_squared_error(mu, px_rate.detach().numpy())\n",
    "\n",
    "print(\"the distance between the Poisson and the NB means is {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hyperparameters***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "lr = 1e-3\n",
    "lambda_ = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***trainer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_leaves:  [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112], [113], [114], [115], [116], [117], [118], [119], [120], [121], [122], [123], [124], [125], [126], [127], [128], [129], [130], [131], [132], [133], [134], [135], [136], [137], [138], [139], [140], [141], [142], [143], [144], [145], [146], [147], [148], [149], [150], [151], [152], [153], [154], [155], [156], [157], [158], [159], [160], [161], [162], [163], [164], [165], [166], [167], [168], [169], [170], [171], [172], [173], [174], [175], [176], [177], [178], [179], [180], [181], [182], [183], [184], [185], [186], [187], [188], [189], [190], [191], [192], [193], [194], [195], [196], [197], [198], [199], [200], [201], [202], [203], [204], [205], [206], [207], [208], [209], [210], [211], [212], [213], [214], [215], [216], [217], [218], [219], [220], [221], [222], [223], [224], [225], [226], [227], [228], [229], [230], [231], [232], [233], [234], [235], [236], [237], [238], [239], [240], [241], [242], [243], [244], [245], [246], [247], [248], [249], [250], [251], [252], [253], [254], [255], [256], [257], [258], [259], [260], [261], [262], [263], [264], [265], [266], [267], [268], [269], [270], [271], [272], [273], [274], [275], [276], [277], [278], [279], [280], [281], [282], [283], [284], [285], [286], [287], [288], [289], [290], [291], [292], [293], [294], [295], [296], [297], [298], [299], [300], [301], [302], [303], [304], [305], [306], [307], [308], [309], [310], [311], [312], [313], [314], [315], [316], [317], [318], [319], [320], [321], [322], [323], [324], [325], [326], [327], [328], [329], [330], [331], [332], [333], [334], [335], [336], [337], [338], [339], [340], [341], [342], [343], [344], [345], [346], [347], [348], [349], [350], [351], [352], [353], [354], [355], [356], [357], [358], [359], [360], [361], [362], [363], [364], [365], [366], [367], [368], [369], [370], [371], [372], [373], [374], [375], [376], [377], [378], [379], [380], [381], [382], [383], [384], [385], [386], [387], [388], [389], [390], [391], [392], [393], [394], [395], [396], [397], [398], [399], [400], [401], [402], [403], [404], [405], [406], [407], [408], [409], [410], [411], [412], [413], [414], [415], [416], [417], [418], [419], [420], [421], [422], [423], [424], [425], [426], [427], [428], [429], [430], [431], [432], [433], [434], [435], [436], [437], [438], [439], [440], [441], [442], [443], [444], [445], [446], [447], [448], [449], [450], [451], [452], [453], [454], [455], [456], [457], [458], [459], [460], [461], [462], [463], [464], [465], [466], [467], [468], [469], [470], [471], [472], [473], [474], [475], [476], [477], [478], [479], [480], [481], [482], [483], [484], [485], [486], [487], [488], [489], [490], [491], [492], [493], [494], [495], [496], [497], [498], [499]]\ntest_leaves:  []\nvalidation leaves:  []\n"
     ]
    }
   ],
   "source": [
    "freq = 100\n",
    "trainer = TreeTrainer(\n",
    "    model = treevae,\n",
    "    gene_dataset = cas_dataset,\n",
    "    lambda_ = lambda_,\n",
    "    train_size=1.0,\n",
    "    test_size=0,\n",
    "    use_cuda=use_cuda,\n",
    "    frequency=freq,\n",
    "    n_epochs_kl_warmup=120\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Start training***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "odings MP Likelihood: 42.21582896242993\n",
      "ELBO Loss: 1858.5212699693311\n",
      "training:  70%|███████   | 350/500 [02:16<01:00,  2.49it/s]Encodings MP Likelihood: 15.766303824747016\n",
      "ELBO Loss: 1832.3281998294015\n",
      "training:  70%|███████   | 351/500 [02:17<00:59,  2.51it/s]Encodings MP Likelihood: 14.74318610586404\n",
      "ELBO Loss: 1830.9789094109358\n",
      "training:  70%|███████   | 352/500 [02:17<00:58,  2.51it/s]Encodings MP Likelihood: 34.831736745969735\n",
      "ELBO Loss: 1849.8612157242742\n",
      "training:  71%|███████   | 353/500 [02:18<00:58,  2.52it/s]Encodings MP Likelihood: 34.42903706674933\n",
      "ELBO Loss: 1849.713106030454\n",
      "training:  71%|███████   | 354/500 [02:18<00:58,  2.49it/s]Encodings MP Likelihood: 27.027991445770517\n",
      "ELBO Loss: 1842.4981227567127\n",
      "training:  71%|███████   | 355/500 [02:18<00:58,  2.47it/s]Encodings MP Likelihood: 25.37585682777694\n",
      "ELBO Loss: 1840.839514124826\n",
      "training:  71%|███████   | 356/500 [02:19<00:57,  2.49it/s]Encodings MP Likelihood: 21.832259792878418\n",
      "ELBO Loss: 1836.7246739747395\n",
      "training:  71%|███████▏  | 357/500 [02:19<00:57,  2.47it/s]Encodings MP Likelihood: 18.983799802082675\n",
      "ELBO Loss: 1832.810077273808\n",
      "training:  72%|███████▏  | 358/500 [02:20<00:57,  2.49it/s]Encodings MP Likelihood: 25.6418310602274\n",
      "ELBO Loss: 1839.4645448313722\n",
      "training:  72%|███████▏  | 359/500 [02:20<00:56,  2.51it/s]Encodings MP Likelihood: 26.587775131393446\n",
      "ELBO Loss: 1840.976263950408\n",
      "training:  72%|███████▏  | 360/500 [02:20<00:55,  2.53it/s]Encodings MP Likelihood: 29.60752519522289\n",
      "ELBO Loss: 1842.2484318804213\n",
      "training:  72%|███████▏  | 361/500 [02:21<00:56,  2.47it/s]Encodings MP Likelihood: 17.099006122548687\n",
      "ELBO Loss: 1830.29448161709\n",
      "training:  72%|███████▏  | 362/500 [02:21<00:55,  2.48it/s]Encodings MP Likelihood: 18.978906772107347\n",
      "ELBO Loss: 1833.4790277646425\n",
      "training:  73%|███████▎  | 363/500 [02:22<00:55,  2.49it/s]Encodings MP Likelihood: 18.19526386566474\n",
      "ELBO Loss: 1831.7270928947987\n",
      "training:  73%|███████▎  | 364/500 [02:22<00:54,  2.51it/s]Encodings MP Likelihood: 24.35022848455028\n",
      "ELBO Loss: 1838.3255207070883\n",
      "training:  73%|███████▎  | 365/500 [02:22<00:53,  2.52it/s]Encodings MP Likelihood: 20.253979772540948\n",
      "ELBO Loss: 1833.291893253115\n",
      "training:  73%|███████▎  | 366/500 [02:23<00:52,  2.53it/s]Encodings MP Likelihood: 12.869330549468408\n",
      "ELBO Loss: 1824.095494269619\n",
      "training:  73%|███████▎  | 367/500 [02:23<00:52,  2.54it/s]Encodings MP Likelihood: 17.083324169234746\n",
      "ELBO Loss: 1828.3492478031367\n",
      "training:  74%|███████▎  | 368/500 [02:24<00:51,  2.55it/s]Encodings MP Likelihood: 17.686169916030217\n",
      "ELBO Loss: 1828.7153987110066\n",
      "training:  74%|███████▍  | 369/500 [02:24<00:51,  2.55it/s]Encodings MP Likelihood: 22.000932871103924\n",
      "ELBO Loss: 1833.796781863439\n",
      "training:  74%|███████▍  | 370/500 [02:24<00:52,  2.47it/s]Encodings MP Likelihood: 23.30162214545166\n",
      "ELBO Loss: 1835.4289501624107\n",
      "training:  74%|███████▍  | 371/500 [02:25<00:51,  2.50it/s]Encodings MP Likelihood: 11.421765024771894\n",
      "ELBO Loss: 1824.3073793099513\n",
      "training:  74%|███████▍  | 372/500 [02:25<00:50,  2.51it/s]Encodings MP Likelihood: 39.69662385933366\n",
      "ELBO Loss: 1850.1246483239486\n",
      "training:  75%|███████▍  | 373/500 [02:26<00:50,  2.53it/s]Encodings MP Likelihood: 26.057835648549855\n",
      "ELBO Loss: 1836.9029234045993\n",
      "training:  75%|███████▍  | 374/500 [02:26<00:54,  2.30it/s]Encodings MP Likelihood: 49.87942964198502\n",
      "ELBO Loss: 1861.516752502652\n",
      "training:  75%|███████▌  | 375/500 [02:27<00:52,  2.37it/s]Encodings MP Likelihood: 43.540661028493176\n",
      "ELBO Loss: 1853.175776572029\n",
      "training:  75%|███████▌  | 376/500 [02:27<00:51,  2.42it/s]Encodings MP Likelihood: 14.800317418433922\n",
      "ELBO Loss: 1824.58445547808\n",
      "training:  75%|███████▌  | 377/500 [02:27<00:50,  2.46it/s]Encodings MP Likelihood: 14.138039583151677\n",
      "ELBO Loss: 1823.5606710267366\n",
      "training:  76%|███████▌  | 378/500 [02:28<00:51,  2.39it/s]Encodings MP Likelihood: 26.3152009050269\n",
      "ELBO Loss: 1835.387741559315\n",
      "training:  76%|███████▌  | 379/500 [02:28<00:49,  2.44it/s]Encodings MP Likelihood: 30.443295662940507\n",
      "ELBO Loss: 1838.9337122395038\n",
      "training:  76%|███████▌  | 380/500 [02:29<00:48,  2.47it/s]Encodings MP Likelihood: 12.113720120349248\n",
      "ELBO Loss: 1819.0054720596156\n",
      "training:  76%|███████▌  | 381/500 [02:29<00:47,  2.49it/s]Encodings MP Likelihood: 79.05526640578552\n",
      "ELBO Loss: 1887.5073544865008\n",
      "training:  76%|███████▋  | 382/500 [02:29<00:48,  2.45it/s]Encodings MP Likelihood: 22.032295144708474\n",
      "ELBO Loss: 1829.5256874081815\n",
      "training:  77%|███████▋  | 383/500 [02:30<00:47,  2.48it/s]Encodings MP Likelihood: 9.068842038919614\n",
      "ELBO Loss: 1816.8132067135466\n",
      "training:  77%|███████▋  | 384/500 [02:30<00:46,  2.50it/s]Encodings MP Likelihood: 12.814967004978696\n",
      "ELBO Loss: 1819.1786374188162\n",
      "training:  77%|███████▋  | 385/500 [02:31<00:45,  2.52it/s]Encodings MP Likelihood: 10.813626231772732\n",
      "ELBO Loss: 1817.9924560231086\n",
      "training:  77%|███████▋  | 386/500 [02:31<00:46,  2.45it/s]Encodings MP Likelihood: 28.66983766877657\n",
      "ELBO Loss: 1836.5332063270646\n",
      "training:  77%|███████▋  | 387/500 [02:31<00:45,  2.47it/s]Encodings MP Likelihood: 10.685351012755408\n",
      "ELBO Loss: 1816.8418120628226\n",
      "training:  78%|███████▊  | 388/500 [02:32<00:44,  2.50it/s]Encodings MP Likelihood: 11.017433863553544\n",
      "ELBO Loss: 1818.411045036317\n",
      "training:  78%|███████▊  | 389/500 [02:32<00:44,  2.51it/s]Encodings MP Likelihood: 24.938638249510795\n",
      "ELBO Loss: 1831.228189763533\n",
      "training:  78%|███████▊  | 390/500 [02:33<00:44,  2.48it/s]Encodings MP Likelihood: 18.654177873004976\n",
      "ELBO Loss: 1823.7355929077983\n",
      "training:  78%|███████▊  | 391/500 [02:33<00:40,  2.67it/s]Encodings MP Likelihood: 19.57334800634934\n",
      "ELBO Loss: 1827.0146826804953\n",
      "training:  78%|███████▊  | 392/500 [02:33<00:37,  2.88it/s]Encodings MP Likelihood: 20.38927518835968\n",
      "ELBO Loss: 1825.3962322053283\n",
      "training:  79%|███████▊  | 393/500 [02:33<00:34,  3.06it/s]Encodings MP Likelihood: 23.612267724752787\n",
      "ELBO Loss: 1830.020996858877\n",
      "training:  79%|███████▉  | 394/500 [02:34<00:33,  3.19it/s]Encodings MP Likelihood: 12.566315507831446\n",
      "ELBO Loss: 1818.5948052387573\n",
      "training:  79%|███████▉  | 395/500 [02:34<00:31,  3.30it/s]Encodings MP Likelihood: 19.515711571105452\n",
      "ELBO Loss: 1825.6113966685373\n",
      "training:  79%|███████▉  | 396/500 [02:34<00:32,  3.19it/s]Encodings MP Likelihood: 14.319852746603388\n",
      "ELBO Loss: 1818.740686364426\n",
      "training:  79%|███████▉  | 397/500 [02:35<00:31,  3.30it/s]Encodings MP Likelihood: 32.56082164894013\n",
      "ELBO Loss: 1837.1412761256033\n",
      "training:  80%|███████▉  | 398/500 [02:35<00:30,  3.38it/s]Encodings MP Likelihood: 9.79735466266191\n",
      "ELBO Loss: 1815.1944029847205\n",
      "training:  80%|███████▉  | 399/500 [02:35<00:29,  3.44it/s]Encodings MP Likelihood: 13.234140876378657\n",
      "ELBO Loss: 1817.1449259335016\n",
      "computing elbo\n",
      "training:  80%|████████  | 400/500 [02:36<00:33,  3.00it/s]Encodings MP Likelihood: 18.169105196937586\n",
      "ELBO Loss: 1822.2293568613045\n",
      "training:  80%|████████  | 401/500 [02:36<00:33,  3.00it/s]Encodings MP Likelihood: 14.710820430369646\n",
      "ELBO Loss: 1817.7882379801779\n",
      "training:  80%|████████  | 402/500 [02:36<00:31,  3.14it/s]Encodings MP Likelihood: 7.6344628837579585\n",
      "ELBO Loss: 1811.7885061808513\n",
      "training:  81%|████████  | 403/500 [02:37<00:29,  3.24it/s]Encodings MP Likelihood: 11.449310077111456\n",
      "ELBO Loss: 1815.6466105705058\n",
      "training:  81%|████████  | 404/500 [02:37<00:29,  3.31it/s]Encodings MP Likelihood: 11.672031203770509\n",
      "ELBO Loss: 1814.9110370808532\n",
      "training:  81%|████████  | 405/500 [02:37<00:30,  3.13it/s]Encodings MP Likelihood: 9.563371622727752\n",
      "ELBO Loss: 1810.7532404953613\n",
      "training:  81%|████████  | 406/500 [02:38<00:32,  2.88it/s]Encodings MP Likelihood: 30.534344875883825\n",
      "ELBO Loss: 1832.3875194786465\n",
      "training:  81%|████████▏ | 407/500 [02:38<00:33,  2.74it/s]Encodings MP Likelihood: 14.902536736470134\n",
      "ELBO Loss: 1815.2607713548218\n",
      "training:  82%|████████▏ | 408/500 [02:38<00:34,  2.64it/s]Encodings MP Likelihood: 11.145460544408838\n",
      "ELBO Loss: 1813.2289053946222\n",
      "training:  82%|████████▏ | 409/500 [02:39<00:35,  2.58it/s]Encodings MP Likelihood: 10.169998244785779\n",
      "ELBO Loss: 1811.3230677946565\n",
      "training:  82%|████████▏ | 410/500 [02:39<00:35,  2.51it/s]Encodings MP Likelihood: 27.095010074255843\n",
      "ELBO Loss: 1829.2156411825074\n",
      "training:  82%|████████▏ | 411/500 [02:40<00:36,  2.46it/s]Encodings MP Likelihood: 16.735673933122577\n",
      "ELBO Loss: 1818.9154514131094\n",
      "training:  82%|████████▏ | 412/500 [02:40<00:35,  2.45it/s]Encodings MP Likelihood: 12.225671807917493\n",
      "ELBO Loss: 1812.379819591672\n",
      "training:  83%|████████▎ | 413/500 [02:40<00:35,  2.42it/s]Encodings MP Likelihood: 13.523205952228814\n",
      "ELBO Loss: 1814.0416627776044\n",
      "training:  83%|████████▎ | 414/500 [02:41<00:35,  2.40it/s]Encodings MP Likelihood: 24.15629582774182\n",
      "ELBO Loss: 1823.4781817455105\n",
      "training:  83%|████████▎ | 415/500 [02:41<00:35,  2.40it/s]Encodings MP Likelihood: 15.527411713382435\n",
      "ELBO Loss: 1816.8237332333028\n",
      "training:  83%|████████▎ | 416/500 [02:42<00:34,  2.43it/s]Encodings MP Likelihood: 25.171431670813657\n",
      "ELBO Loss: 1826.0863827714657\n",
      "training:  83%|████████▎ | 417/500 [02:42<00:33,  2.47it/s]Encodings MP Likelihood: 18.733009188046317\n",
      "ELBO Loss: 1817.482634371139\n",
      "training:  84%|████████▎ | 418/500 [02:43<00:32,  2.49it/s]Encodings MP Likelihood: 15.314793898458838\n",
      "ELBO Loss: 1814.983426273646\n",
      "training:  84%|████████▍ | 419/500 [02:43<00:32,  2.51it/s]Encodings MP Likelihood: 14.889884972374105\n",
      "ELBO Loss: 1813.7729955357274\n",
      "training:  84%|████████▍ | 420/500 [02:43<00:31,  2.53it/s]Encodings MP Likelihood: 16.39279882669555\n",
      "ELBO Loss: 1816.4671826029976\n",
      "training:  84%|████████▍ | 421/500 [02:44<00:31,  2.54it/s]Encodings MP Likelihood: 20.07543882618915\n",
      "ELBO Loss: 1819.8294830275117\n",
      "training:  84%|████████▍ | 422/500 [02:44<00:31,  2.47it/s]Encodings MP Likelihood: 33.57687820338602\n",
      "ELBO Loss: 1833.4655402598096\n",
      "training:  85%|████████▍ | 423/500 [02:45<00:31,  2.47it/s]Encodings MP Likelihood: 14.22344345921781\n",
      "ELBO Loss: 1811.3661416404095\n",
      "training:  85%|████████▍ | 424/500 [02:45<00:30,  2.50it/s]Encodings MP Likelihood: 8.377803636009297\n",
      "ELBO Loss: 1806.885516265819\n",
      "training:  85%|████████▌ | 425/500 [02:45<00:29,  2.52it/s]Encodings MP Likelihood: 10.500016654840175\n",
      "ELBO Loss: 1808.0017376319904\n",
      "training:  85%|████████▌ | 426/500 [02:46<00:29,  2.47it/s]Encodings MP Likelihood: 20.15989046806715\n",
      "ELBO Loss: 1817.8189234121296\n",
      "training:  85%|████████▌ | 427/500 [02:46<00:29,  2.50it/s]Encodings MP Likelihood: 10.971960646900506\n",
      "ELBO Loss: 1810.535490057266\n",
      "training:  86%|████████▌ | 428/500 [02:47<00:29,  2.43it/s]Encodings MP Likelihood: 15.114291951190655\n",
      "ELBO Loss: 1812.5388610379366\n",
      "training:  86%|████████▌ | 429/500 [02:47<00:28,  2.47it/s]Encodings MP Likelihood: 12.68860549129953\n",
      "ELBO Loss: 1809.0763371229448\n",
      "training:  86%|████████▌ | 430/500 [02:47<00:28,  2.45it/s]Encodings MP Likelihood: 14.816204821699916\n",
      "ELBO Loss: 1813.79062190225\n",
      "training:  86%|████████▌ | 431/500 [02:48<00:27,  2.48it/s]Encodings MP Likelihood: 14.953394665098843\n",
      "ELBO Loss: 1811.934645853232\n",
      "training:  86%|████████▋ | 432/500 [02:48<00:27,  2.50it/s]Encodings MP Likelihood: 14.162783871272806\n",
      "ELBO Loss: 1810.2094876720766\n",
      "training:  87%|████████▋ | 433/500 [02:49<00:26,  2.52it/s]Encodings MP Likelihood: 9.214725823222565\n",
      "ELBO Loss: 1805.6072389208182\n",
      "training:  87%|████████▋ | 434/500 [02:49<00:26,  2.46it/s]Encodings MP Likelihood: 12.123663483669729\n",
      "ELBO Loss: 1808.8854143574601\n",
      "training:  87%|████████▋ | 435/500 [02:49<00:26,  2.49it/s]Encodings MP Likelihood: 13.249749596186888\n",
      "ELBO Loss: 1809.8234140410414\n",
      "training:  87%|████████▋ | 436/500 [02:50<00:25,  2.50it/s]Encodings MP Likelihood: 10.70108542327262\n",
      "ELBO Loss: 1806.400547838853\n",
      "training:  87%|████████▋ | 437/500 [02:50<00:25,  2.49it/s]Encodings MP Likelihood: 11.242987067822842\n",
      "ELBO Loss: 1806.132104073223\n",
      "training:  88%|████████▊ | 438/500 [02:51<00:24,  2.50it/s]Encodings MP Likelihood: 11.94845900176241\n",
      "ELBO Loss: 1807.1377469276215\n",
      "training:  88%|████████▊ | 439/500 [02:51<00:22,  2.74it/s]Encodings MP Likelihood: 11.097498371446559\n",
      "ELBO Loss: 1806.5020159523565\n",
      "training:  88%|████████▊ | 440/500 [02:51<00:20,  2.94it/s]Encodings MP Likelihood: 8.791867330386255\n",
      "ELBO Loss: 1803.785417123257\n",
      "training:  88%|████████▊ | 441/500 [02:51<00:19,  3.04it/s]Encodings MP Likelihood: 13.01879681408781\n",
      "ELBO Loss: 1808.0650783481012\n",
      "training:  88%|████████▊ | 442/500 [02:52<00:18,  3.18it/s]Encodings MP Likelihood: 25.713675300238442\n",
      "ELBO Loss: 1821.2916091689349\n",
      "training:  89%|████████▊ | 443/500 [02:52<00:17,  3.28it/s]Encodings MP Likelihood: 11.452481771495785\n",
      "ELBO Loss: 1805.216249791887\n",
      "training:  89%|████████▉ | 444/500 [02:52<00:17,  3.19it/s]Encodings MP Likelihood: 18.291375197409288\n",
      "ELBO Loss: 1812.8726806525312\n",
      "training:  89%|████████▉ | 445/500 [02:53<00:16,  3.29it/s]Encodings MP Likelihood: 33.236341447194256\n",
      "ELBO Loss: 1827.714662765638\n",
      "training:  89%|████████▉ | 446/500 [02:53<00:16,  3.23it/s]Encodings MP Likelihood: 20.742210797227646\n",
      "ELBO Loss: 1815.3538594411739\n",
      "training:  89%|████████▉ | 447/500 [02:53<00:17,  3.00it/s]Encodings MP Likelihood: 14.416552414732017\n",
      "ELBO Loss: 1808.1549028093564\n",
      "training:  90%|████████▉ | 448/500 [02:54<00:18,  2.88it/s]Encodings MP Likelihood: 8.5904475370879\n",
      "ELBO Loss: 1802.3403156427144\n",
      "training:  90%|████████▉ | 449/500 [02:54<00:16,  3.05it/s]Encodings MP Likelihood: 16.606017549390067\n",
      "ELBO Loss: 1810.179456150625\n",
      "training:  90%|█████████ | 450/500 [02:54<00:15,  3.19it/s]Encodings MP Likelihood: 13.493609086373732\n",
      "ELBO Loss: 1806.8407592868894\n",
      "training:  90%|█████████ | 451/500 [02:55<00:14,  3.29it/s]Encodings MP Likelihood: 10.420680825206295\n",
      "ELBO Loss: 1803.6393028442546\n",
      "training:  90%|█████████ | 452/500 [02:55<00:14,  3.31it/s]Encodings MP Likelihood: 12.960168934349802\n",
      "ELBO Loss: 1805.2199743501963\n",
      "training:  91%|█████████ | 453/500 [02:55<00:14,  3.34it/s]Encodings MP Likelihood: 6.602116072397661\n",
      "ELBO Loss: 1799.7577843399442\n",
      "training:  91%|█████████ | 454/500 [02:55<00:13,  3.38it/s]Encodings MP Likelihood: 35.65364840623372\n",
      "ELBO Loss: 1827.307482058536\n",
      "training:  91%|█████████ | 455/500 [02:56<00:13,  3.42it/s]Encodings MP Likelihood: 7.834252138615595\n",
      "ELBO Loss: 1799.525840228618\n",
      "training:  91%|█████████ | 456/500 [02:56<00:12,  3.44it/s]Encodings MP Likelihood: 15.566266949852215\n",
      "ELBO Loss: 1809.056126748901\n",
      "training:  91%|█████████▏| 457/500 [02:56<00:12,  3.44it/s]Encodings MP Likelihood: 8.227633202759108\n",
      "ELBO Loss: 1799.5406235332155\n",
      "training:  92%|█████████▏| 458/500 [02:57<00:12,  3.46it/s]Encodings MP Likelihood: 26.07403772495785\n",
      "ELBO Loss: 1818.132769306669\n",
      "training:  92%|█████████▏| 459/500 [02:57<00:11,  3.47it/s]Encodings MP Likelihood: 10.053968097214586\n",
      "ELBO Loss: 1801.0444901649857\n",
      "training:  92%|█████████▏| 460/500 [02:57<00:11,  3.47it/s]Encodings MP Likelihood: 7.395607356356111\n",
      "ELBO Loss: 1798.4719415722911\n",
      "training:  92%|█████████▏| 461/500 [02:57<00:11,  3.47it/s]Encodings MP Likelihood: 16.34211807160286\n",
      "ELBO Loss: 1808.3964854048181\n",
      "training:  92%|█████████▏| 462/500 [02:58<00:10,  3.47it/s]Encodings MP Likelihood: 10.950558338823145\n",
      "ELBO Loss: 1801.6764462554236\n",
      "training:  93%|█████████▎| 463/500 [02:58<00:10,  3.48it/s]Encodings MP Likelihood: 10.854452906372874\n",
      "ELBO Loss: 1801.8484309132282\n",
      "training:  93%|█████████▎| 464/500 [02:58<00:10,  3.49it/s]Encodings MP Likelihood: 24.961181911181434\n",
      "ELBO Loss: 1814.7799424022846\n",
      "training:  93%|█████████▎| 465/500 [02:59<00:10,  3.48it/s]Encodings MP Likelihood: 6.429232818862205\n",
      "ELBO Loss: 1796.420519209632\n",
      "training:  93%|█████████▎| 466/500 [02:59<00:09,  3.48it/s]Encodings MP Likelihood: 9.655669033569405\n",
      "ELBO Loss: 1800.0522341929732\n",
      "training:  93%|█████████▎| 467/500 [02:59<00:09,  3.48it/s]Encodings MP Likelihood: 11.793552987560593\n",
      "ELBO Loss: 1800.4623774179324\n",
      "training:  94%|█████████▎| 468/500 [02:59<00:09,  3.47it/s]Encodings MP Likelihood: 8.859251852187745\n",
      "ELBO Loss: 1797.1320280605498\n",
      "training:  94%|█████████▍| 469/500 [03:00<00:08,  3.48it/s]Encodings MP Likelihood: 10.35837447825079\n",
      "ELBO Loss: 1799.319407273738\n",
      "training:  94%|█████████▍| 470/500 [03:00<00:08,  3.43it/s]Encodings MP Likelihood: 9.219969053135753\n",
      "ELBO Loss: 1796.4926168426741\n",
      "training:  94%|█████████▍| 471/500 [03:00<00:08,  3.45it/s]Encodings MP Likelihood: 14.94227283753392\n",
      "ELBO Loss: 1803.9816994272953\n",
      "training:  94%|█████████▍| 472/500 [03:01<00:08,  3.47it/s]Encodings MP Likelihood: 17.654808472431277\n",
      "ELBO Loss: 1806.7324029796753\n",
      "training:  95%|█████████▍| 473/500 [03:01<00:07,  3.48it/s]Encodings MP Likelihood: 11.529353239801619\n",
      "ELBO Loss: 1798.1364057304258\n",
      "training:  95%|█████████▍| 474/500 [03:01<00:07,  3.48it/s]Encodings MP Likelihood: 12.306809777300318\n",
      "ELBO Loss: 1800.1531147680298\n",
      "training:  95%|█████████▌| 475/500 [03:01<00:07,  3.48it/s]Encodings MP Likelihood: 7.517849388609319\n",
      "ELBO Loss: 1796.4982906121613\n",
      "training:  95%|█████████▌| 476/500 [03:02<00:06,  3.47it/s]Encodings MP Likelihood: 20.140345996242544\n",
      "ELBO Loss: 1807.5329748458253\n",
      "training:  95%|█████████▌| 477/500 [03:02<00:06,  3.47it/s]Encodings MP Likelihood: 7.42061394033321\n",
      "ELBO Loss: 1795.3415408364592\n",
      "training:  96%|█████████▌| 478/500 [03:02<00:06,  3.47it/s]Encodings MP Likelihood: 6.790991161482194\n",
      "ELBO Loss: 1793.7077183683866\n",
      "training:  96%|█████████▌| 479/500 [03:03<00:06,  3.15it/s]Encodings MP Likelihood: 7.131250494350674\n",
      "ELBO Loss: 1794.6759522610707\n",
      "training:  96%|█████████▌| 480/500 [03:03<00:06,  2.95it/s]Encodings MP Likelihood: 9.534192619534107\n",
      "ELBO Loss: 1796.4088023190245\n",
      "training:  96%|█████████▌| 481/500 [03:03<00:06,  2.82it/s]Encodings MP Likelihood: 8.35573290711489\n",
      "ELBO Loss: 1794.8396739393472\n",
      "training:  96%|█████████▋| 482/500 [03:04<00:06,  2.74it/s]Encodings MP Likelihood: 16.539638570649547\n",
      "ELBO Loss: 1804.7409490784123\n",
      "training:  97%|█████████▋| 483/500 [03:04<00:06,  2.68it/s]Encodings MP Likelihood: 9.352730933935721\n",
      "ELBO Loss: 1796.808125926472\n",
      "training:  97%|█████████▋| 484/500 [03:05<00:06,  2.65it/s]Encodings MP Likelihood: 11.432440218118236\n",
      "ELBO Loss: 1798.9249598319886\n",
      "training:  97%|█████████▋| 485/500 [03:05<00:05,  2.62it/s]Encodings MP Likelihood: 6.393359254695133\n",
      "ELBO Loss: 1792.402260726886\n",
      "training:  97%|█████████▋| 486/500 [03:05<00:05,  2.61it/s]Encodings MP Likelihood: 15.969019551162901\n",
      "ELBO Loss: 1802.6673558963525\n",
      "training:  97%|█████████▋| 487/500 [03:06<00:04,  2.82it/s]Encodings MP Likelihood: 12.657040285932197\n",
      "ELBO Loss: 1798.7542232838011\n",
      "training:  98%|█████████▊| 488/500 [03:06<00:04,  2.98it/s]Encodings MP Likelihood: 13.66429012809889\n",
      "ELBO Loss: 1798.565098368857\n",
      "training:  98%|█████████▊| 489/500 [03:06<00:03,  3.11it/s]Encodings MP Likelihood: 8.869625316027548\n",
      "ELBO Loss: 1794.292980013145\n",
      "training:  98%|█████████▊| 490/500 [03:07<00:03,  3.23it/s]Encodings MP Likelihood: 15.156947797327073\n",
      "ELBO Loss: 1799.8323823771345\n",
      "training:  98%|█████████▊| 491/500 [03:07<00:02,  3.12it/s]Encodings MP Likelihood: 22.113576269191707\n",
      "ELBO Loss: 1807.9152765711465\n",
      "training:  98%|█████████▊| 492/500 [03:07<00:02,  3.26it/s]Encodings MP Likelihood: 7.575729047541419\n",
      "ELBO Loss: 1790.7630357672892\n",
      "training:  99%|█████████▊| 493/500 [03:07<00:02,  3.37it/s]Encodings MP Likelihood: 7.445469398384534\n",
      "ELBO Loss: 1792.4002660676283\n",
      "training:  99%|█████████▉| 494/500 [03:08<00:01,  3.45it/s]Encodings MP Likelihood: 7.860331884183673\n",
      "ELBO Loss: 1792.1952739229923\n",
      "training:  99%|█████████▉| 495/500 [03:08<00:01,  3.44it/s]Encodings MP Likelihood: 24.743305345943323\n",
      "ELBO Loss: 1808.8796596800016\n",
      "training:  99%|█████████▉| 496/500 [03:08<00:01,  3.49it/s]Encodings MP Likelihood: 8.360794887069371\n",
      "ELBO Loss: 1793.7986085842385\n",
      "training:  99%|█████████▉| 497/500 [03:09<00:00,  3.54it/s]Encodings MP Likelihood: 18.364725785627055\n",
      "ELBO Loss: 1803.3415747522395\n",
      "training: 100%|█████████▉| 498/500 [03:09<00:00,  3.21it/s]Encodings MP Likelihood: 10.149769026365039\n",
      "ELBO Loss: 1793.4151225174223\n",
      "training: 100%|█████████▉| 499/500 [03:09<00:00,  2.99it/s]Encodings MP Likelihood: 8.665524384644081\n",
      "ELBO Loss: 1791.6008147095108\n",
      "computing elbo\n",
      "training: 100%|██████████| 500/500 [03:10<00:00,  2.63it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=n_epochs,\n",
    "              lr=lr\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Loss Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dashboard(trainer, treevae.encoder_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Posterior and MV imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance is 3.152920012749111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "full_posterior = trainer.create_posterior(trainer.model, cas_dataset, trainer.clades,\n",
    "                                indices=np.arange(len(cas_dataset))\n",
    "                                         )\n",
    "error = mean_squared_error(full_posterior.get_latent(), leaves_z)\n",
    "print(\"the distance is {}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Missing Value imputation By Posterior Predictive sampling***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_l = np.mean(np.sum(nb_glm.X, axis=1))\n",
    "\n",
    "# CascVI impitations\n",
    "imputed = {}\n",
    "imputed_z = {}\n",
    "imputed_gt = {}\n",
    "\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        imputed[n.name], imputed_z[n.name] = full_posterior.imputation_internal(n,\n",
    "                                                            give_mean=False,\n",
    "                                                            library_size=empirical_l\n",
    "                                                           )\n",
    "        imputed_gt[n.name] = nb_glm.X[n.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed_X = [x for x in imputed.values()]\n",
    "imputed_X = np.array(imputed_X).reshape(-1, cas_dataset.X.shape[1])\n",
    "#plot_histograms(imputed_X, \"Histogram of CasscVI imputed gene expression data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CascVI Baseline 1 (MP Oracle)***"
   ]
  },
  {
   "source": [
    "regenerate data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma, nbinom\n",
    "\n",
    "data_mu = []\n",
    "data_X = []\n",
    "idx = 0\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if n.is_leaf():\n",
    "        mu_z = np.clip(a=np.exp(nb_glm.W @ leaves_z[idx] + nb_glm.beta),\n",
    "                        a_min=0,\n",
    "                        a_max=1e8\n",
    "                        )\n",
    "        r, p = convert_params_NB(mu=mu_z, alpha=alpha)\n",
    "        \n",
    "        data_mu.append(mu_z)\n",
    "\n",
    "        sample = np.array([nbinom.rvs(n=r, p=p) for i in range(200)])\n",
    "        data_X.append(np.mean(sample, axis=0))\n",
    "        idx += 1\n",
    "data_X = np.array(data_X)\n",
    "data_mu = np.array(data_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-284)\n",
      "SpearmanrResult(correlation=0.8446119491245421, pvalue=4.780025075565974e-273)\n",
      "SpearmanrResult(correlation=0.8592567662095804, pvalue=8.583617783566959e-293)\n",
      "SpearmanrResult(correlation=0.848581129864151, pvalue=3.432762949808551e-278)\n",
      "SpearmanrResult(correlation=0.8765995318729166, pvalue=2.747e-319)\n",
      "SpearmanrResult(correlation=0.8805105504177826, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8930101018011612, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.876683641191424, pvalue=1.9988e-319)\n",
      "SpearmanrResult(correlation=0.8673982331915169, pvalue=9.188519504884423e-305)\n",
      "SpearmanrResult(correlation=0.8481854047229391, pvalue=1.13521500210057e-277)\n",
      "SpearmanrResult(correlation=0.8463511513270635, pvalue=2.7765526484805353e-275)\n",
      "SpearmanrResult(correlation=0.856394121424926, pvalue=9.221330820046107e-289)\n",
      "SpearmanrResult(correlation=0.8912788703505311, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8930749685766158, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8624463320415937, pvalue=2.1667053605576797e-297)\n",
      "SpearmanrResult(correlation=0.8864327695304771, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8792497051075061, pvalue=1e-323)\n",
      "SpearmanrResult(correlation=0.8609390994455498, pvalue=3.3327598989778173e-295)\n",
      "SpearmanrResult(correlation=0.861377684450991, pvalue=7.746041738187317e-296)\n",
      "SpearmanrResult(correlation=0.8544000476712235, pvalue=5.265151534378711e-286)\n",
      "SpearmanrResult(correlation=0.8931721906975083, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.9075112748715118, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8671646227464012, pvalue=2.0782931008067396e-304)\n",
      "SpearmanrResult(correlation=0.8727906715009135, pvalue=3.87534852455e-313)\n",
      "SpearmanrResult(correlation=0.8836625586726503, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8811649864621075, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8823847910530278, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8815648155789427, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8692173544869486, pvalue=1.5126854228647456e-307)\n",
      "SpearmanrResult(correlation=0.8944854792088551, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8807174915522827, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8688710938637265, pvalue=5.161602800762422e-307)\n",
      "SpearmanrResult(correlation=0.8450187502400737, pvalue=1.4418409826632611e-273)\n",
      "SpearmanrResult(correlation=0.8387233388447396, pvalue=1.1228782960029201e-265)\n",
      "SpearmanrResult(correlation=0.8663320078816933, pvalue=3.763443838688868e-303)\n",
      "SpearmanrResult(correlation=0.880373986621262, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8673500196993479, pvalue=1.0875669623222882e-304)\n",
      "SpearmanrResult(correlation=0.8753442757403546, pvalue=3.074527e-317)\n",
      "SpearmanrResult(correlation=0.8661727029769658, pvalue=6.535668404011321e-303)\n",
      "SpearmanrResult(correlation=0.8513091290933017, pvalue=8.201147328647599e-282)\n",
      "SpearmanrResult(correlation=0.8427846749480954, pvalue=9.98016843417381e-271)\n",
      "SpearmanrResult(correlation=0.8432468081698439, pvalue=2.6018171018338773e-271)\n",
      "SpearmanrResult(correlation=0.8549933196466343, pvalue=8.046247612999232e-287)\n",
      "SpearmanrResult(correlation=0.8764474659648386, pvalue=4.8782e-319)\n",
      "SpearmanrResult(correlation=0.8607617975387178, pvalue=6.0031151087103895e-295)\n",
      "SpearmanrResult(correlation=0.8730797805391598, pvalue=1.34441923503e-313)\n",
      "SpearmanrResult(correlation=0.8697044215779755, pvalue=2.6752757824814734e-308)\n",
      "SpearmanrResult(correlation=0.8857068258398312, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8661936526095828, pvalue=6.078339291754393e-303)\n",
      "SpearmanrResult(correlation=0.8745238157070271, pvalue=6.53193084e-316)\n",
      "SpearmanrResult(correlation=0.8818656076869371, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8674022914033824, pvalue=9.059035851488582e-305)\n",
      "SpearmanrResult(correlation=0.8828716462871967, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8950641919941497, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.9075464784122758, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.9110533309701141, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8669292965311043, pvalue=4.721612753262834e-304)\n",
      "SpearmanrResult(correlation=0.8925712090075104, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.9013305911438837, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8768207978594647, pvalue=1.1895e-319)\n",
      "SpearmanrResult(correlation=0.890842537551812, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8766047368162697, pvalue=2.69345e-319)\n",
      "SpearmanrResult(correlation=0.8778947211994358, pvalue=1.996e-321)\n",
      "SpearmanrResult(correlation=0.8844283982725569, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.884321619725152, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8864493689349745, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8811233414519167, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8723874435296713, pvalue=1.6892570462e-312)\n",
      "SpearmanrResult(correlation=0.8820996617190551, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8930201718365193, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8769177409496768, pvalue=8.239e-320)\n",
      "SpearmanrResult(correlation=0.8875471596532253, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8880540547096759, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8906886267421434, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.869473035062952, pvalue=6.097796370030345e-308)\n",
      "SpearmanrResult(correlation=0.8712759130282635, pvalue=9.5279331356196e-311)\n",
      "SpearmanrResult(correlation=0.8896847544670888, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8809609945708071, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8694602419793133, pvalue=6.381687106881166e-308)\n",
      "SpearmanrResult(correlation=0.8736255869741479, pvalue=1.8090230944e-314)\n",
      "SpearmanrResult(correlation=0.8798755818587073, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8766761882853986, pvalue=2.0559e-319)\n",
      "SpearmanrResult(correlation=0.8445958841353735, pvalue=5.0113530822616445e-273)\n",
      "SpearmanrResult(correlation=0.8629995513847665, pvalue=3.361567084309919e-298)\n",
      "SpearmanrResult(correlation=0.87597587902415, pvalue=2.88146e-318)\n",
      "SpearmanrResult(correlation=0.8823928251370062, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8592527782678656, pvalue=8.696570006071592e-293)\n",
      "SpearmanrResult(correlation=0.8626667950574264, pvalue=1.0321124410322448e-297)\n",
      "SpearmanrResult(correlation=0.8674682163303962, pvalue=7.193287383208395e-305)\n",
      "SpearmanrResult(correlation=0.9176215147585107, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.9111073322544235, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.90368848354519, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.9049792793218656, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.9099848849984867, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.9066957370887014, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.900670572292133, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8885274005032993, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8830064252405266, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8874410432440902, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.891578641771077, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8933050206421248, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8761859042988953, pvalue=1.307594e-318)\n",
      "SpearmanrResult(correlation=0.8760494005105144, pvalue=2.18557e-318)\n",
      "SpearmanrResult(correlation=0.8790901899822166, pvalue=2e-323)\n",
      "SpearmanrResult(correlation=0.8732989484132178, pvalue=6.0149923507e-314)\n",
      "SpearmanrResult(correlation=0.8674279933578308, pvalue=8.280211354551152e-305)\n",
      "SpearmanrResult(correlation=0.8858179623651273, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8789187395185645, pvalue=4e-323)\n",
      "SpearmanrResult(correlation=0.876217747459493, pvalue=1.15983e-318)\n",
      "SpearmanrResult(correlation=0.8663916702219928, pvalue=3.060077980895471e-303)\n",
      "SpearmanrResult(correlation=0.8811581546780032, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8755072278248976, pvalue=1.6712877e-317)\n",
      "SpearmanrResult(correlation=0.8749044055182051, pvalue=1.58680556e-316)\n",
      "SpearmanrResult(correlation=0.8728752827880261, pvalue=2.843598742e-313)\n",
      "SpearmanrResult(correlation=0.8544296815229172, pvalue=4.794541091818843e-286)\n",
      "SpearmanrResult(correlation=0.8706961075256167, pvalue=7.69248706844966e-310)\n",
      "SpearmanrResult(correlation=0.8618119054319358, pvalue=1.8176596811182255e-296)\n",
      "SpearmanrResult(correlation=0.8651104540636891, pvalue=2.5456006390474606e-301)\n",
      "SpearmanrResult(correlation=0.8612855426405708, pvalue=1.052928157799361e-295)\n",
      "SpearmanrResult(correlation=0.8604568293698064, pvalue=1.6487254873396052e-294)\n",
      "SpearmanrResult(correlation=0.8933703061564078, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8784960860450239, pvalue=2e-322)\n",
      "SpearmanrResult(correlation=0.8682806396700702, pvalue=4.151792988259957e-306)\n",
      "SpearmanrResult(correlation=0.9082561556721305, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.9053616962911079, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8785333381101165, pvalue=1.8e-322)\n",
      "SpearmanrResult(correlation=0.8786365406431573, pvalue=1.2e-322)\n",
      "SpearmanrResult(correlation=0.8795413447124072, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8705582296128018, pvalue=1.26218211211373e-309)\n",
      "SpearmanrResult(correlation=0.8820100902758857, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8863428904948795, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8517904101937952, pvalue=1.850840483616965e-282)\n",
      "SpearmanrResult(correlation=0.8698908015641154, pvalue=1.376134125599903e-308)\n",
      "SpearmanrResult(correlation=0.8781556787201807, pvalue=7.3e-322)\n",
      "SpearmanrResult(correlation=0.88221929656051, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8919854409607111, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8648394111930086, pvalue=6.448367226422681e-301)\n",
      "SpearmanrResult(correlation=0.8762805164368214, pvalue=9.15563e-319)\n",
      "SpearmanrResult(correlation=0.8647654999575559, pvalue=8.305625307806853e-301)\n",
      "SpearmanrResult(correlation=0.8655172994713377, pvalue=6.283915699804419e-302)\n",
      "SpearmanrResult(correlation=0.8801916470331589, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8969024903110164, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8845931962129717, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8758102066104071, pvalue=5.36845e-318)\n",
      "SpearmanrResult(correlation=0.8902116771492764, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8786108423603556, pvalue=1.3e-322)\n",
      "SpearmanrResult(correlation=0.8865636635284775, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8662469339040362, pvalue=5.053984299542765e-303)\n",
      "SpearmanrResult(correlation=0.8698714430725816, pvalue=1.474580141863516e-308)\n",
      "SpearmanrResult(correlation=0.873502221857645, pvalue=2.8489514765e-314)\n",
      "SpearmanrResult(correlation=0.8801332268945796, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8722773108293094, pvalue=2.523195742987e-312)\n",
      "SpearmanrResult(correlation=0.8703894206290779, pvalue=2.31252107472107e-309)\n",
      "SpearmanrResult(correlation=0.8722462104092154, pvalue=2.825723231686e-312)\n",
      "SpearmanrResult(correlation=0.8813963239427007, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8948469258279137, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8828544897337015, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8902772047895323, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8863618074904361, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8855237978876014, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8932143540932806, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8858033601767523, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8877675695526052, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8756548173956511, pvalue=9.61523e-318)\n",
      "SpearmanrResult(correlation=0.886278809828783, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8757148594649197, pvalue=7.67713e-318)\n",
      "SpearmanrResult(correlation=0.856257550234656, pvalue=1.4286243432538788e-288)\n",
      "SpearmanrResult(correlation=0.8887175082800634, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8850872502478787, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8719304785956923, pvalue=8.90559267796e-312)\n",
      "SpearmanrResult(correlation=0.8758214491181775, pvalue=5.14663e-318)\n",
      "SpearmanrResult(correlation=0.8839141124827047, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8834118828785448, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8748454671502547, pvalue=1.97614974e-316)\n",
      "SpearmanrResult(correlation=0.8402291924476717, pvalue=1.5631162862957137e-267)\n",
      "SpearmanrResult(correlation=0.8632782248353662, pvalue=1.3108411370423247e-298)\n",
      "SpearmanrResult(correlation=0.8868881780245208, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8755967015582216, pvalue=1.195463e-317)\n",
      "SpearmanrResult(correlation=0.8856643080705356, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8685880056692554, pvalue=1.4042483259083114e-306)\n",
      "SpearmanrResult(correlation=0.8666840499302465, pvalue=1.1085947322645472e-303)\n",
      "SpearmanrResult(correlation=0.8747321783857649, pvalue=3.012024e-316)\n",
      "SpearmanrResult(correlation=0.8789723849684092, pvalue=4e-323)\n",
      "SpearmanrResult(correlation=0.879752834490283, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8877388462000075, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8686281658739201, pvalue=1.2185482791375683e-306)\n",
      "SpearmanrResult(correlation=0.8700060711856319, pvalue=9.117617240750573e-309)\n",
      "SpearmanrResult(correlation=0.8820106722766082, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8844551017221933, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8767809961064076, pvalue=1.383e-319)\n",
      "SpearmanrResult(correlation=0.8890765236950193, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8693806614172033, pvalue=8.468833073372152e-308)\n",
      "SpearmanrResult(correlation=0.879110044774415, pvalue=2e-323)\n",
      "SpearmanrResult(correlation=0.8807739784291726, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8793039929975012, pvalue=1e-323)\n",
      "SpearmanrResult(correlation=0.8855234060229185, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8792881934686342, pvalue=1e-323)\n",
      "SpearmanrResult(correlation=0.8822424494135863, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8670025090007344, pvalue=3.658379706629757e-304)\n",
      "SpearmanrResult(correlation=0.8750786134358433, pvalue=8.2902595e-317)\n",
      "SpearmanrResult(correlation=0.8765249937281745, pvalue=3.6403e-319)\n",
      "SpearmanrResult(correlation=0.8870185914189866, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8782036615226159, pvalue=6.13e-322)\n",
      "SpearmanrResult(correlation=0.8755601139761628, pvalue=1.371052e-317)\n",
      "SpearmanrResult(correlation=0.8810505570703878, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.875650397369341, pvalue=9.77585e-318)\n",
      "SpearmanrResult(correlation=0.8653191315207828, pvalue=1.2428292165249602e-301)\n",
      "SpearmanrResult(correlation=0.87662034603652, pvalue=2.5391e-319)\n",
      "SpearmanrResult(correlation=0.8821363853778432, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.886576862941411, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8834591130066323, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8809062203228682, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8734253634695831, pvalue=3.7797626247e-314)\n",
      "SpearmanrResult(correlation=0.8779920730401473, pvalue=1.383e-321)\n",
      "SpearmanrResult(correlation=0.8786765005137155, pvalue=1e-322)\n",
      "SpearmanrResult(correlation=0.8773655243634163, pvalue=1.505e-320)\n",
      "SpearmanrResult(correlation=0.8765696752865406, pvalue=3.07506e-319)\n",
      "SpearmanrResult(correlation=0.8766992656350051, pvalue=1.88407e-319)\n",
      "SpearmanrResult(correlation=0.8915134491863729, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8831136959007437, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8694823304795577, pvalue=5.899458716958726e-308)\n",
      "SpearmanrResult(correlation=0.8643903800545455, pvalue=2.994042726033776e-300)\n",
      "SpearmanrResult(correlation=0.8779705282260929, pvalue=1.5e-321)\n",
      "SpearmanrResult(correlation=0.8782295679004517, pvalue=5.53e-322)\n",
      "SpearmanrResult(correlation=0.8859103238593473, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8757515785883585, pvalue=6.6894e-318)\n",
      "SpearmanrResult(correlation=0.8727842931637932, pvalue=3.96681247605e-313)\n",
      "SpearmanrResult(correlation=0.879551323449223, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8807775734983703, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8586449641224976, pvalue=6.348224483984424e-292)\n",
      "SpearmanrResult(correlation=0.8475196411768942, pvalue=8.426123200623365e-277)\n",
      "SpearmanrResult(correlation=0.8709780704573022, pvalue=2.78935209959487e-310)\n",
      "SpearmanrResult(correlation=0.8802305144033532, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8680556262588832, pvalue=9.165075785326017e-306)\n",
      "SpearmanrResult(correlation=0.8850196594507769, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8841901558925146, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8725137055260017, pvalue=1.06591054101e-312)\n",
      "SpearmanrResult(correlation=0.8709136753561224, pvalue=3.51731540880275e-310)\n",
      "SpearmanrResult(correlation=0.8912466091278274, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8859927117361662, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8663257663909095, pvalue=3.845765238316892e-303)\n",
      "SpearmanrResult(correlation=0.8672149150531108, pvalue=1.7436301527946165e-304)\n",
      "SpearmanrResult(correlation=0.8838723166731659, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8917476354229575, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8862151740693016, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8733051614450628, pvalue=5.879271987e-314)\n",
      "SpearmanrResult(correlation=0.87776253326002, pvalue=3.32e-321)\n",
      "SpearmanrResult(correlation=0.8615313967173035, pvalue=4.6393915153542835e-296)\n",
      "SpearmanrResult(correlation=0.8641545536218738, pvalue=6.691154377531524e-300)\n",
      "SpearmanrResult(correlation=0.872411309411359, pvalue=1.548506635527e-312)\n",
      "SpearmanrResult(correlation=0.8743776580565307, pvalue=1.123315083e-315)\n",
      "SpearmanrResult(correlation=0.8597556087619465, pvalue=1.6675769790043167e-293)\n",
      "SpearmanrResult(correlation=0.8923620622728652, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8831338784478433, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.876872314915512, pvalue=9.7865e-320)\n",
      "SpearmanrResult(correlation=0.8837996646806956, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.898849841099177, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8825598086656943, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8924583033023298, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8675011564290802, pvalue=6.410086911815521e-305)\n",
      "SpearmanrResult(correlation=0.8722552691071267, pvalue=2.734050651836e-312)\n",
      "SpearmanrResult(correlation=0.8818332185797725, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8822405475721139, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8817248899292381, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8888277169606517, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8788495755010581, pvalue=5e-323)\n",
      "SpearmanrResult(correlation=0.8883726913291864, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8647021725275421, pvalue=1.0315793807437435e-300)\n",
      "SpearmanrResult(correlation=0.8981485649132517, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8893362224253522, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8777646904115668, pvalue=3.28e-321)\n",
      "SpearmanrResult(correlation=0.8727031832120803, pvalue=5.33609225605e-313)\n",
      "SpearmanrResult(correlation=0.8803910476878294, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8788306039015281, pvalue=6e-323)\n",
      "SpearmanrResult(correlation=0.8789303341769132, pvalue=4e-323)\n",
      "SpearmanrResult(correlation=0.874813852937907, pvalue=2.2228814e-316)\n",
      "SpearmanrResult(correlation=0.883210769569183, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.890131081522732, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8877994002679629, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8828813681014002, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8869222530779516, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8778653671411871, pvalue=2.233e-321)\n",
      "SpearmanrResult(correlation=0.8922710423113692, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8698109365252129, pvalue=1.82990512763773e-308)\n",
      "SpearmanrResult(correlation=0.8704440615421982, pvalue=1.901116855225513e-309)\n",
      "SpearmanrResult(correlation=0.8738040364980078, pvalue=9.37054619e-315)\n",
      "SpearmanrResult(correlation=0.8728788600558188, pvalue=2.806610317e-313)\n",
      "SpearmanrResult(correlation=0.8687134997300525, pvalue=9.01327781022419e-307)\n",
      "SpearmanrResult(correlation=0.8806420818427035, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8767018059860218, pvalue=1.866e-319)\n",
      "SpearmanrResult(correlation=0.8780002720336108, pvalue=1.344e-321)\n",
      "SpearmanrResult(correlation=0.8845721104026079, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8860331189279081, pvalue=0.0)\n",
      "SpearmanrResult(correlation=0.8714606587491611, pvalue=4.887085022678e-311)\n",
      "SpearmanrResult(correlation=0.8737175992665518, pvalue=1.288831798e-314)\n",
      "SpearmanrResult(correlation=0.8708620841241931, pvalue=4.23502644958646e-310)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_X)):\n",
    "    print(stats.spearmanr(data_X[i], leaves_X[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "\n",
    "# CascVI impitations\n",
    "imputed_cascvi_1 = {}\n",
    "imputed_cascvi_1_z ={}\n",
    "\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        _, imputed_cascvi_1_z[n.name] = full_posterior.imputation_internal(n,\n",
    "                                                                    give_mean=False,\n",
    "                                                                    library_size=empirical_l,\n",
    "                                                                    known_latent=leaves_z\n",
    "        )\n",
    "        \n",
    "        mu_z = np.clip(a=np.exp(nb_glm.W @ imputed_cascvi_1_z[n.name].cpu().numpy() + nb_glm.beta),\n",
    "                        a_min=0,\n",
    "                        a_max=1e8\n",
    "                        )\n",
    "        \n",
    "        if treevae.reconstruction_loss == 'nb':\n",
    "            r, p = convert_params_NB(mu=mu_z, alpha=alpha)\n",
    "            sample = nbinom.rvs(n=r, p=p)\n",
    "        else:\n",
    "            sample = np.random.poisson(mu_z)\n",
    "        imputed_cascvi_1[n.name] = np.clip(a=sample,\n",
    "                                           a_min=0,\n",
    "                                           a_max=1e8\n",
    "                                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_cascvi_X = np.array([x for x in imputed_cascvi_1.values()]).reshape(-1, nb_glm.X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "py.float64'>\n",
      "gene 668: corr = 0.16504919191649806 <class 'numpy.float64'>\n",
      "gene 669: corr = 0.1862394990256288 <class 'numpy.float64'>\n",
      "gene 670: corr = 0.14828725657772526 <class 'numpy.float64'>\n",
      "gene 671: corr = -0.012145626057038545 <class 'numpy.float64'>\n",
      "gene 672: corr = 0.23802278440787386 <class 'numpy.float64'>\n",
      "gene 673: corr = 0.112226375416395 <class 'numpy.float64'>\n",
      "gene 674: corr = 0.05648985506895834 <class 'numpy.float64'>\n",
      "gene 675: corr = -0.052579379058836376 <class 'numpy.float64'>\n",
      "gene 676: corr = 0.6503357616642556 <class 'numpy.float64'>\n",
      "gene 677: corr = -0.02461601904035586 <class 'numpy.float64'>\n",
      "gene 678: corr = 0.11947083621809618 <class 'numpy.float64'>\n",
      "gene 679: corr = 0.2928756647891632 <class 'numpy.float64'>\n",
      "gene 680: corr = 0.28994853811166516 <class 'numpy.float64'>\n",
      "gene 681: corr = 0.1843373134796058 <class 'numpy.float64'>\n",
      "gene 682: corr = 0.1386315979391962 <class 'numpy.float64'>\n",
      "gene 683: corr = 0.23052081872698005 <class 'numpy.float64'>\n",
      "gene 684: corr = -0.014198782961460444 <class 'numpy.float64'>\n",
      "gene 685: corr = 0.22821605102887177 <class 'numpy.float64'>\n",
      "gene 686: corr = 0.500393630797011 <class 'numpy.float64'>\n",
      "gene 687: corr = 0.10460361341004268 <class 'numpy.float64'>\n",
      "gene 688: corr = 0.6487795830411986 <class 'numpy.float64'>\n",
      "gene 689: corr = 0.16564393915503584 <class 'numpy.float64'>\n",
      "gene 690: corr = 0.07791875810793963 <class 'numpy.float64'>\n",
      "gene 691: corr = 0.04471881005283882 <class 'numpy.float64'>\n",
      "gene 692: corr = 0.140913376926277 <class 'numpy.float64'>\n",
      "gene 693: corr = 0.5433940557123113 <class 'numpy.float64'>\n",
      "gene 694: corr = 0.18189233090739923 <class 'numpy.float64'>\n",
      "gene 695: corr = -0.03373046103840106 <class 'numpy.float64'>\n",
      "gene 696: corr = 0.2266145071739022 <class 'numpy.float64'>\n",
      "gene 697: corr = 0.08024910461013084 <class 'numpy.float64'>\n",
      "gene 698: corr = 0.5933179157270959 <class 'numpy.float64'>\n",
      "gene 699: corr = 0.22994424223559168 <class 'numpy.float64'>\n",
      "gene 700: corr = 0.05060577191009991 <class 'numpy.float64'>\n",
      "gene 701: corr = 0.702952325254857 <class 'numpy.float64'>\n",
      "gene 702: corr = 0.3383446614339764 <class 'numpy.float64'>\n",
      "gene 703: corr = 0.7474508939875979 <class 'numpy.float64'>\n",
      "gene 704: corr = 0.17268052437757764 <class 'numpy.float64'>\n",
      "gene 705: corr = 0.055533635262189546 <class 'numpy.float64'>\n",
      "gene 706: corr = 0.2665874532072991 <class 'numpy.float64'>\n",
      "gene 707: corr = 0.10162322822230087 <class 'numpy.float64'>\n",
      "gene 708: corr = 0.4027819155016479 <class 'numpy.float64'>\n",
      "gene 709: corr = 0.7830243130495741 <class 'numpy.float64'>\n",
      "gene 710: corr = 0.23430105264855203 <class 'numpy.float64'>\n",
      "gene 711: corr = 0.020053039630636354 <class 'numpy.float64'>\n",
      "gene 712: corr = 0.6378135421742454 <class 'numpy.float64'>\n",
      "gene 713: corr = 0.2983209725855543 <class 'numpy.float64'>\n",
      "gene 714: corr = 0.20659998654820763 <class 'numpy.float64'>\n",
      "gene 715: corr = 0.5199753117834821 <class 'numpy.float64'>\n",
      "gene 716: corr = 0.7015586341091109 <class 'numpy.float64'>\n",
      "gene 717: corr = 0.6029878107250665 <class 'numpy.float64'>\n",
      "gene 718: corr = -0.011451215811497927 <class 'numpy.float64'>\n",
      "gene 719: corr = 0.12298356278655159 <class 'numpy.float64'>\n",
      "gene 720: corr = 0.037749773181498684 <class 'numpy.float64'>\n",
      "gene 721: corr = 0.5819025306326551 <class 'numpy.float64'>\n",
      "gene 722: corr = 0.5647992997731206 <class 'numpy.float64'>\n",
      "gene 723: corr = 0.2222127371971479 <class 'numpy.float64'>\n",
      "gene 724: corr = 0.06486996809665126 <class 'numpy.float64'>\n",
      "gene 725: corr = -0.004955277209697158 <class 'numpy.float64'>\n",
      "gene 726: corr = 0.37603025660799605 <class 'numpy.float64'>\n",
      "gene 727: corr = 0.07862686117181614 <class 'numpy.float64'>\n",
      "gene 728: corr = 0.18472508048179587 <class 'numpy.float64'>\n",
      "gene 729: corr = 0.44508433950533427 <class 'numpy.float64'>\n",
      "gene 730: corr = 0.24586678874772244 <class 'numpy.float64'>\n",
      "gene 731: corr = 0.2207058136715857 <class 'numpy.float64'>\n",
      "gene 732: corr = 0.4436305725347407 <class 'numpy.float64'>\n",
      "gene 733: corr = 0.06147667582608614 <class 'numpy.float64'>\n",
      "gene 734: corr = 0.018698800988775206 <class 'numpy.float64'>\n",
      "gene 735: corr = 0.08886111654944985 <class 'numpy.float64'>\n",
      "gene 736: corr = 0.29687200385085 <class 'numpy.float64'>\n",
      "gene 737: corr = 0.7066321064407928 <class 'numpy.float64'>\n",
      "gene 738: corr = 0.527999449775843 <class 'numpy.float64'>\n",
      "gene 739: corr = 0.2733762596618704 <class 'numpy.float64'>\n",
      "gene 740: corr = 0.5834250934379523 <class 'numpy.float64'>\n",
      "gene 741: corr = 0.2837332066779895 <class 'numpy.float64'>\n",
      "gene 742: corr = 0.6271806269497862 <class 'numpy.float64'>\n",
      "gene 743: corr = 0.44596502132067584 <class 'numpy.float64'>\n",
      "gene 744: corr = 0.29349492963674306 <class 'numpy.float64'>\n",
      "gene 745: corr = 0.19106743672302884 <class 'numpy.float64'>\n",
      "gene 746: corr = 0.08178067387739789 <class 'numpy.float64'>\n",
      "gene 747: corr = 0.23432382879985786 <class 'numpy.float64'>\n",
      "gene 748: corr = -0.02242524530198974 <class 'numpy.float64'>\n",
      "gene 749: corr = 0.02436326645245741 <class 'numpy.float64'>\n",
      "gene 750: corr = 0.6634280461512368 <class 'numpy.float64'>\n",
      "gene 751: corr = 0.3186033981360579 <class 'numpy.float64'>\n",
      "gene 752: corr = 0.7710172837382381 <class 'numpy.float64'>\n",
      "gene 753: corr = 0.28566226213262674 <class 'numpy.float64'>\n",
      "gene 754: corr = 0.15331867882020955 <class 'numpy.float64'>\n",
      "gene 755: corr = 0.0875313547720045 <class 'numpy.float64'>\n",
      "gene 756: corr = 0.21116451102471398 <class 'numpy.float64'>\n",
      "gene 757: corr = 0.16751918148368922 <class 'numpy.float64'>\n",
      "gene 758: corr = 0.7242172638167405 <class 'numpy.float64'>\n",
      "gene 759: corr = 0.052178724591348306 <class 'numpy.float64'>\n",
      "gene 760: corr = 0.25707298261260786 <class 'numpy.float64'>\n",
      "gene 761: corr = 0.16376612458734627 <class 'numpy.float64'>\n",
      "gene 762: corr = 0.5427839189772115 <class 'numpy.float64'>\n",
      "gene 763: corr = 0.06983182837300608 <class 'numpy.float64'>\n",
      "gene 764: corr = 0.3270730634474068 <class 'numpy.float64'>\n",
      "gene 765: corr = 0.050706642278085315 <class 'numpy.float64'>\n",
      "gene 766: corr = 0.1390418361703385 <class 'numpy.float64'>\n",
      "gene 767: corr = 0.2645518956528041 <class 'numpy.float64'>\n",
      "gene 768: corr = 0.4877529840203096 <class 'numpy.float64'>\n",
      "gene 769: corr = 0.7405218748657421 <class 'numpy.float64'>\n",
      "gene 770: corr = 0.7855125699221398 <class 'numpy.float64'>\n",
      "gene 771: corr = 0.47743775094325963 <class 'numpy.float64'>\n",
      "gene 772: corr = 0.17915385370815357 <class 'numpy.float64'>\n",
      "gene 773: corr = 0.12285670674142866 <class 'numpy.float64'>\n",
      "gene 774: corr = 0.2288737744779347 <class 'numpy.float64'>\n",
      "gene 775: corr = 0.6986295360952905 <class 'numpy.float64'>\n",
      "gene 776: corr = 0.7083178888989208 <class 'numpy.float64'>\n",
      "gene 777: corr = 0.07942634876598326 <class 'numpy.float64'>\n",
      "gene 778: corr = 0.23044543738124348 <class 'numpy.float64'>\n",
      "gene 779: corr = 0.38707060635890483 <class 'numpy.float64'>\n",
      "gene 780: corr = 0.08412600268977703 <class 'numpy.float64'>\n",
      "gene 781: corr = 0.03140893937788991 <class 'numpy.float64'>\n",
      "gene 782: corr = 0.584780972284458 <class 'numpy.float64'>\n",
      "gene 783: corr = 0.32393823054839194 <class 'numpy.float64'>\n",
      "gene 784: corr = 0.09047486117026272 <class 'numpy.float64'>\n",
      "gene 785: corr = 0.5022969713698079 <class 'numpy.float64'>\n",
      "gene 786: corr = 0.22361496899746447 <class 'numpy.float64'>\n",
      "gene 787: corr = 0.23897672965012984 <class 'numpy.float64'>\n",
      "gene 788: corr = 0.75164461248563 <class 'numpy.float64'>\n",
      "gene 789: corr = 0.6683233558486459 <class 'numpy.float64'>\n",
      "gene 790: corr = 0.20030710168070892 <class 'numpy.float64'>\n",
      "gene 791: corr = -6.457938435849794e-05 <class 'numpy.float64'>\n",
      "gene 792: corr = 0.4955757252213667 <class 'numpy.float64'>\n",
      "gene 793: corr = 0.6698005002234183 <class 'numpy.float64'>\n",
      "gene 794: corr = 0.012330384551076289 <class 'numpy.float64'>\n",
      "gene 795: corr = 0.6377636057964479 <class 'numpy.float64'>\n",
      "gene 796: corr = 0.42349295955274197 <class 'numpy.float64'>\n",
      "gene 797: corr = 0.7350941228942685 <class 'numpy.float64'>\n",
      "gene 798: corr = 0.45737635742440713 <class 'numpy.float64'>\n",
      "gene 799: corr = 0.5346482417604588 <class 'numpy.float64'>\n",
      "gene 800: corr = 0.40918253480175076 <class 'numpy.float64'>\n",
      "gene 801: corr = 0.18317687842294123 <class 'numpy.float64'>\n",
      "gene 802: corr = 0.3980702549276772 <class 'numpy.float64'>\n",
      "gene 803: corr = 0.2658488890926296 <class 'numpy.float64'>\n",
      "gene 804: corr = 0.4259102156330227 <class 'numpy.float64'>\n",
      "gene 805: corr = 0.169629917338766 <class 'numpy.float64'>\n",
      "gene 806: corr = 0.48617237898526544 <class 'numpy.float64'>\n",
      "gene 807: corr = 0.1738216239207379 <class 'numpy.float64'>\n",
      "gene 808: corr = 0.4816226115497894 <class 'numpy.float64'>\n",
      "gene 809: corr = 0.3901172016709271 <class 'numpy.float64'>\n",
      "gene 810: corr = 0.48762363629149685 <class 'numpy.float64'>\n",
      "gene 811: corr = 0.40084978436379026 <class 'numpy.float64'>\n",
      "gene 812: corr = 0.3826768289432905 <class 'numpy.float64'>\n",
      "gene 813: corr = 0.11455877440099815 <class 'numpy.float64'>\n",
      "gene 814: corr = 0.28091736954749674 <class 'numpy.float64'>\n",
      "gene 815: corr = 0.1705141241547628 <class 'numpy.float64'>\n",
      "gene 816: corr = 0.6794264202241742 <class 'numpy.float64'>\n",
      "gene 817: corr = 0.7327987470820002 <class 'numpy.float64'>\n",
      "gene 818: corr = 0.004900707866781001 <class 'numpy.float64'>\n",
      "gene 819: corr = 0.28428645788836115 <class 'numpy.float64'>\n",
      "gene 820: corr = 0.8294729832073903 <class 'numpy.float64'>\n",
      "gene 821: corr = 0.19266027370361108 <class 'numpy.float64'>\n",
      "gene 822: corr = 0.14561116974523844 <class 'numpy.float64'>\n",
      "gene 823: corr = 0.017401916991858404 <class 'numpy.float64'>\n",
      "gene 824: corr = 0.29703594481859463 <class 'numpy.float64'>\n",
      "gene 825: corr = 0.05400106416605579 <class 'numpy.float64'>\n",
      "gene 826: corr = 0.4493689532448846 <class 'numpy.float64'>\n",
      "gene 827: corr = 0.09212880631906682 <class 'numpy.float64'>\n",
      "gene 828: corr = 0.289026480618405 <class 'numpy.float64'>\n",
      "gene 829: corr = 0.724725762295074 <class 'numpy.float64'>\n",
      "gene 830: corr = 0.10627209572052604 <class 'numpy.float64'>\n",
      "gene 831: corr = 0.24662488551408338 <class 'numpy.float64'>\n",
      "gene 832: corr = 0.3048268231726958 <class 'numpy.float64'>\n",
      "gene 833: corr = 0.6354965170785183 <class 'numpy.float64'>\n",
      "gene 834: corr = 0.11534104255358979 <class 'numpy.float64'>\n",
      "gene 835: corr = 0.09369853279058056 <class 'numpy.float64'>\n",
      "gene 836: corr = 0.7398165596426934 <class 'numpy.float64'>\n",
      "gene 837: corr = 0.3661747164158752 <class 'numpy.float64'>\n",
      "gene 838: corr = 0.30268077833600227 <class 'numpy.float64'>\n",
      "gene 839: corr = 0.28279813355567424 <class 'numpy.float64'>\n",
      "gene 840: corr = 0.7360565023465178 <class 'numpy.float64'>\n",
      "gene 841: corr = 0.4537212684078556 <class 'numpy.float64'>\n",
      "gene 842: corr = 0.19619124205447563 <class 'numpy.float64'>\n",
      "gene 843: corr = 0.49303923276416983 <class 'numpy.float64'>\n",
      "gene 844: corr = 0.187706038426051 <class 'numpy.float64'>\n",
      "gene 845: corr = 0.12228399197909477 <class 'numpy.float64'>\n",
      "gene 846: corr = 0.4731750464485096 <class 'numpy.float64'>\n",
      "gene 847: corr = 0.1332267255525192 <class 'numpy.float64'>\n",
      "gene 848: corr = 0.5556915676204272 <class 'numpy.float64'>\n",
      "gene 849: corr = 0.455704631859799 <class 'numpy.float64'>\n",
      "gene 850: corr = 0.8641795056228285 <class 'numpy.float64'>\n",
      "gene 851: corr = 0.08513682919409556 <class 'numpy.float64'>\n",
      "gene 852: corr = -0.027268051182404725 <class 'numpy.float64'>\n",
      "gene 853: corr = 0.24189113482425173 <class 'numpy.float64'>\n",
      "gene 854: corr = 0.2962064275892497 <class 'numpy.float64'>\n",
      "gene 855: corr = 0.7011524929410601 <class 'numpy.float64'>\n",
      "gene 856: corr = -0.015160466939208367 <class 'numpy.float64'>\n",
      "gene 857: corr = 0.20182473532891193 <class 'numpy.float64'>\n",
      "gene 858: corr = -0.0020040080160320644 <class 'numpy.float64'>\n",
      "gene 859: corr = 0.06176738347383829 <class 'numpy.float64'>\n",
      "gene 860: corr = 0.2399463945743598 <class 'numpy.float64'>\n",
      "gene 861: corr = 0.3558445423921473 <class 'numpy.float64'>\n",
      "gene 862: corr = 0.36547608144229005 <class 'numpy.float64'>\n",
      "gene 863: corr = 0.5694844452638559 <class 'numpy.float64'>\n",
      "gene 864: corr = 0.5593179148236624 <class 'numpy.float64'>\n",
      "gene 865: corr = 0.3255403346094118 <class 'numpy.float64'>\n",
      "gene 866: corr = 0.3714957495083719 <class 'numpy.float64'>\n",
      "gene 867: corr = 0.34105933363800345 <class 'numpy.float64'>\n",
      "gene 868: corr = 0.1416505093005894 <class 'numpy.float64'>\n",
      "gene 869: corr = 0.5596398916274544 <class 'numpy.float64'>\n",
      "gene 870: corr = 0.07514512183892111 <class 'numpy.float64'>\n",
      "gene 871: corr = 0.15761444944380712 <class 'numpy.float64'>\n",
      "gene 872: corr = 0.16810649494211033 <class 'numpy.float64'>\n",
      "gene 873: corr = 0.45441585976450827 <class 'numpy.float64'>\n",
      "gene 874: corr = 0.2908832976074357 <class 'numpy.float64'>\n",
      "gene 875: corr = -0.013132206736985237 <class 'numpy.float64'>\n",
      "gene 876: corr = 0.516235506705728 <class 'numpy.float64'>\n",
      "gene 877: corr = 0.07798834001304714 <class 'numpy.float64'>\n",
      "gene 878: corr = 0.0887571944898748 <class 'numpy.float64'>\n",
      "gene 879: corr = 0.2298038858297061 <class 'numpy.float64'>\n",
      "gene 880: corr = 0.5419732046100046 <class 'numpy.float64'>\n",
      "gene 881: corr = 0.6515952998239795 <class 'numpy.float64'>\n",
      "gene 882: corr = 0.5567153093576834 <class 'numpy.float64'>\n",
      "gene 883: corr = 0.21513007568231393 <class 'numpy.float64'>\n",
      "gene 884: corr = 0.4182118358812959 <class 'numpy.float64'>\n",
      "gene 885: corr = 0.1300935660880362 <class 'numpy.float64'>\n",
      "gene 886: corr = 0.0891945870226535 <class 'numpy.float64'>\n",
      "gene 887: corr = 0.1425866451927728 <class 'numpy.float64'>\n",
      "gene 888: corr = 0.689751865549076 <class 'numpy.float64'>\n",
      "gene 889: corr = 0.07152572333744261 <class 'numpy.float64'>\n",
      "gene 890: corr = 0.6800205044945591 <class 'numpy.float64'>\n",
      "gene 891: corr = 0.707570485390791 <class 'numpy.float64'>\n",
      "gene 892: corr = 0.3438730751173262 <class 'numpy.float64'>\n",
      "gene 893: corr = 0.18659239989555182 <class 'numpy.float64'>\n",
      "gene 894: corr = 0.8767627812048236 <class 'numpy.float64'>\n",
      "gene 895: corr = 0.42916646463601354 <class 'numpy.float64'>\n",
      "gene 896: corr = 0.6648066688409354 <class 'numpy.float64'>\n",
      "gene 897: corr = 0.11985013515370278 <class 'numpy.float64'>\n",
      "gene 898: corr = 0.3973067744767397 <class 'numpy.float64'>\n",
      "gene 899: corr = 0.4708273423016794 <class 'numpy.float64'>\n",
      "gene 900: corr = 0.36694530042577556 <class 'numpy.float64'>\n",
      "gene 901: corr = 0.20994081832491948 <class 'numpy.float64'>\n",
      "gene 902: corr = 0.5259825074422252 <class 'numpy.float64'>\n",
      "gene 903: corr = 0.41509053241012517 <class 'numpy.float64'>\n",
      "gene 904: corr = 0.6184662673782999 <class 'numpy.float64'>\n",
      "gene 905: corr = 0.17916163272116484 <class 'numpy.float64'>\n",
      "gene 907: corr = 0.4385623040625363 <class 'numpy.float64'>\n",
      "gene 908: corr = 0.3171343354649522 <class 'numpy.float64'>\n",
      "gene 909: corr = 0.6208473503318827 <class 'numpy.float64'>\n",
      "gene 910: corr = 0.28188038185999575 <class 'numpy.float64'>\n",
      "gene 911: corr = 0.25217835455050364 <class 'numpy.float64'>\n",
      "gene 912: corr = 0.1509162815121686 <class 'numpy.float64'>\n",
      "gene 913: corr = 0.4669658312448526 <class 'numpy.float64'>\n",
      "gene 914: corr = 0.07834630155825867 <class 'numpy.float64'>\n",
      "gene 915: corr = 0.5373387478916261 <class 'numpy.float64'>\n",
      "gene 916: corr = 0.059600192020465036 <class 'numpy.float64'>\n",
      "gene 917: corr = 0.15376672375882106 <class 'numpy.float64'>\n",
      "gene 918: corr = 0.10100772008913297 <class 'numpy.float64'>\n",
      "gene 919: corr = 0.312172214513191 <class 'numpy.float64'>\n",
      "gene 921: corr = 0.8157019213551796 <class 'numpy.float64'>\n",
      "gene 922: corr = 0.03703420491655947 <class 'numpy.float64'>\n",
      "gene 923: corr = -0.006369168362239028 <class 'numpy.float64'>\n",
      "gene 924: corr = 0.4657765896761533 <class 'numpy.float64'>\n",
      "gene 925: corr = 0.743557779588031 <class 'numpy.float64'>\n",
      "gene 926: corr = 0.7199389165712146 <class 'numpy.float64'>\n",
      "gene 927: corr = 0.7263836275620169 <class 'numpy.float64'>\n",
      "gene 928: corr = 0.30788534419038865 <class 'numpy.float64'>\n",
      "gene 929: corr = 0.1282907041344173 <class 'numpy.float64'>\n",
      "gene 930: corr = 0.18724900830296357 <class 'numpy.float64'>\n",
      "gene 931: corr = 0.5988660098033587 <class 'numpy.float64'>\n",
      "gene 932: corr = 0.3767275648566399 <class 'numpy.float64'>\n",
      "gene 933: corr = 0.7032870059924816 <class 'numpy.float64'>\n",
      "gene 934: corr = 0.7535671796014795 <class 'numpy.float64'>\n",
      "gene 935: corr = 0.2628979888395406 <class 'numpy.float64'>\n",
      "gene 936: corr = 0.03971084840205198 <class 'numpy.float64'>\n",
      "gene 937: corr = 0.18977179503324446 <class 'numpy.float64'>\n",
      "gene 938: corr = 0.7612315763728762 <class 'numpy.float64'>\n",
      "gene 939: corr = 0.015123410221549434 <class 'numpy.float64'>\n",
      "gene 940: corr = 0.44566054586063963 <class 'numpy.float64'>\n",
      "gene 941: corr = 0.09915796381208172 <class 'numpy.float64'>\n",
      "gene 942: corr = 0.4202889481242823 <class 'numpy.float64'>\n",
      "gene 943: corr = 0.31665919327166986 <class 'numpy.float64'>\n",
      "gene 944: corr = 0.34109039203214936 <class 'numpy.float64'>\n",
      "gene 945: corr = 0.7149378358099474 <class 'numpy.float64'>\n",
      "gene 946: corr = 0.6810332481077886 <class 'numpy.float64'>\n",
      "gene 947: corr = 0.27378078774746706 <class 'numpy.float64'>\n",
      "gene 948: corr = 0.3052697184469673 <class 'numpy.float64'>\n",
      "gene 949: corr = 0.5619601972939491 <class 'numpy.float64'>\n",
      "gene 950: corr = 0.12089924781120263 <class 'numpy.float64'>\n",
      "gene 951: corr = 0.053536660215369535 <class 'numpy.float64'>\n",
      "gene 952: corr = 0.2765248887478986 <class 'numpy.float64'>\n",
      "gene 953: corr = 0.4687328221509586 <class 'numpy.float64'>\n",
      "gene 954: corr = 0.22598476996173494 <class 'numpy.float64'>\n",
      "gene 955: corr = 0.7409730055364653 <class 'numpy.float64'>\n",
      "gene 956: corr = 0.6651126590029677 <class 'numpy.float64'>\n",
      "gene 957: corr = 0.4003189590619863 <class 'numpy.float64'>\n",
      "gene 958: corr = -0.04053397574739101 <class 'numpy.float64'>\n",
      "gene 959: corr = 0.749625331658175 <class 'numpy.float64'>\n",
      "gene 960: corr = 0.14633632042601233 <class 'numpy.float64'>\n",
      "gene 961: corr = 0.39724519707453937 <class 'numpy.float64'>\n",
      "gene 962: corr = 0.2569005782301721 <class 'numpy.float64'>\n",
      "gene 963: corr = 0.2852182943751805 <class 'numpy.float64'>\n",
      "gene 964: corr = 0.42944695008411643 <class 'numpy.float64'>\n",
      "gene 965: corr = 0.14858120454551016 <class 'numpy.float64'>\n",
      "gene 966: corr = 0.2478812837682835 <class 'numpy.float64'>\n",
      "gene 967: corr = 0.46242146597586553 <class 'numpy.float64'>\n",
      "gene 968: corr = 0.4391596869646659 <class 'numpy.float64'>\n",
      "gene 969: corr = 0.20735001640437128 <class 'numpy.float64'>\n",
      "gene 970: corr = 0.8222679335541405 <class 'numpy.float64'>\n",
      "gene 971: corr = 0.7654434050667507 <class 'numpy.float64'>\n",
      "gene 972: corr = 0.33502993303068035 <class 'numpy.float64'>\n",
      "gene 973: corr = 0.7437893943561772 <class 'numpy.float64'>\n",
      "gene 974: corr = 0.11361183833679936 <class 'numpy.float64'>\n",
      "gene 975: corr = 0.0944671422450129 <class 'numpy.float64'>\n",
      "gene 976: corr = 0.40637892234590334 <class 'numpy.float64'>\n",
      "gene 977: corr = 0.026789499698449012 <class 'numpy.float64'>\n",
      "gene 978: corr = 0.3185094376145266 <class 'numpy.float64'>\n",
      "gene 979: corr = 0.31513529040440785 <class 'numpy.float64'>\n",
      "gene 980: corr = 0.26178379535117646 <class 'numpy.float64'>\n",
      "gene 981: corr = 0.2693849426570062 <class 'numpy.float64'>\n",
      "gene 982: corr = 0.5244674700498099 <class 'numpy.float64'>\n",
      "gene 983: corr = 0.43766841879354784 <class 'numpy.float64'>\n",
      "gene 984: corr = 0.047996428626771614 <class 'numpy.float64'>\n",
      "gene 985: corr = 0.8404355217184049 <class 'numpy.float64'>\n",
      "gene 986: corr = 0.17106190275756827 <class 'numpy.float64'>\n",
      "gene 987: corr = 0.2036197693258433 <class 'numpy.float64'>\n",
      "gene 988: corr = 0.16094442259354608 <class 'numpy.float64'>\n",
      "gene 989: corr = -0.0597234061040721 <class 'numpy.float64'>\n",
      "gene 990: corr = 0.4007368617481681 <class 'numpy.float64'>\n",
      "gene 991: corr = 0.05885336167644321 <class 'numpy.float64'>\n",
      "gene 992: corr = 0.2507412371477669 <class 'numpy.float64'>\n",
      "gene 993: corr = 0.6089874770148204 <class 'numpy.float64'>\n",
      "gene 994: corr = 0.0027039326326945322 <class 'numpy.float64'>\n",
      "gene 995: corr = 0.09613062211709039 <class 'numpy.float64'>\n",
      "gene 996: corr = 0.46012367911095947 <class 'numpy.float64'>\n",
      "gene 997: corr = 0.154101228598574 <class 'numpy.float64'>\n",
      "gene 998: corr = 0.7901834996471645 <class 'numpy.float64'>\n",
      "gene 999: corr = 0.24002600085333003 <class 'numpy.float64'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.34484965984329646"
      ]
     },
     "metadata": {},
     "execution_count": 236
    }
   ],
   "source": [
    "mean = 0\n",
    "genes_to_inspect2 = []\n",
    "for i in range(internal_X.shape[1]):\n",
    "    corr = stats.spearmanr(internal_X[:, i], internal_cascvi_X[:, i])\n",
    "    if math.isnan(corr[0]):\n",
    "        continue\n",
    "    if corr[0] < 0.05:\n",
    "        genes_to_inspect2.append(i)\n",
    "    mean += corr[0]\n",
    "    print('gene {}: corr = {}'.format(i, corr[0]), type(corr[0]))\n",
    "mean /= internal_X.shape[1]\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "e 658: corr = 0.3505221035022903 <class 'numpy.float64'>\n",
      "gene 659: corr = 0.691084144071372 <class 'numpy.float64'>\n",
      "gene 660: corr = 0.12619034113242364 <class 'numpy.float64'>\n",
      "gene 661: corr = -0.0038877590580275296 <class 'numpy.float64'>\n",
      "gene 663: corr = 0.8915656506027362 <class 'numpy.float64'>\n",
      "gene 664: corr = -0.019370240575750926 <class 'numpy.float64'>\n",
      "gene 665: corr = 0.6049517713981974 <class 'numpy.float64'>\n",
      "gene 666: corr = 0.2063003634957107 <class 'numpy.float64'>\n",
      "gene 667: corr = 0.20668441464232765 <class 'numpy.float64'>\n",
      "gene 668: corr = 0.16946652896658537 <class 'numpy.float64'>\n",
      "gene 669: corr = 0.32108171651050893 <class 'numpy.float64'>\n",
      "gene 670: corr = 0.1427071911603086 <class 'numpy.float64'>\n",
      "gene 672: corr = 0.2692698310027577 <class 'numpy.float64'>\n",
      "gene 673: corr = 0.284923625632443 <class 'numpy.float64'>\n",
      "gene 674: corr = 0.1275140587654431 <class 'numpy.float64'>\n",
      "gene 675: corr = 0.048294649492359065 <class 'numpy.float64'>\n",
      "gene 676: corr = 0.7094092401925495 <class 'numpy.float64'>\n",
      "gene 677: corr = -0.011522259100445053 <class 'numpy.float64'>\n",
      "gene 678: corr = 0.21506406172208403 <class 'numpy.float64'>\n",
      "gene 679: corr = 0.4251894864890557 <class 'numpy.float64'>\n",
      "gene 680: corr = 0.34803675461933403 <class 'numpy.float64'>\n",
      "gene 681: corr = 0.30559939305622763 <class 'numpy.float64'>\n",
      "gene 682: corr = 0.2705080754575501 <class 'numpy.float64'>\n",
      "gene 683: corr = 0.29188001585799006 <class 'numpy.float64'>\n",
      "gene 685: corr = 0.3489844103811127 <class 'numpy.float64'>\n",
      "gene 686: corr = 0.6104026217533717 <class 'numpy.float64'>\n",
      "gene 687: corr = 0.27891286845452445 <class 'numpy.float64'>\n",
      "gene 688: corr = 0.6909715599764374 <class 'numpy.float64'>\n",
      "gene 689: corr = 0.24566535104647236 <class 'numpy.float64'>\n",
      "gene 690: corr = 0.051770762144510436 <class 'numpy.float64'>\n",
      "gene 691: corr = 0.037845660528845276 <class 'numpy.float64'>\n",
      "gene 692: corr = 0.1583477554198686 <class 'numpy.float64'>\n",
      "gene 693: corr = 0.6434978487280028 <class 'numpy.float64'>\n",
      "gene 694: corr = 0.27303428314750483 <class 'numpy.float64'>\n",
      "gene 696: corr = 0.29600918256521713 <class 'numpy.float64'>\n",
      "gene 697: corr = 0.22180719985424804 <class 'numpy.float64'>\n",
      "gene 698: corr = 0.7120004769813238 <class 'numpy.float64'>\n",
      "gene 699: corr = 0.31986836266054464 <class 'numpy.float64'>\n",
      "gene 700: corr = 0.04262371229129369 <class 'numpy.float64'>\n",
      "gene 701: corr = 0.7359273259048912 <class 'numpy.float64'>\n",
      "gene 702: corr = 0.4348300982666741 <class 'numpy.float64'>\n",
      "gene 703: corr = 0.7954770653496669 <class 'numpy.float64'>\n",
      "gene 704: corr = 0.2538814243017481 <class 'numpy.float64'>\n",
      "gene 705: corr = 0.05693584635834766 <class 'numpy.float64'>\n",
      "gene 706: corr = 0.2729673727405639 <class 'numpy.float64'>\n",
      "gene 707: corr = 0.11999832497468627 <class 'numpy.float64'>\n",
      "gene 708: corr = 0.4895215650934329 <class 'numpy.float64'>\n",
      "gene 709: corr = 0.7996431196803347 <class 'numpy.float64'>\n",
      "gene 710: corr = 0.3536681769143511 <class 'numpy.float64'>\n",
      "gene 711: corr = 0.10303617411054972 <class 'numpy.float64'>\n",
      "gene 712: corr = 0.6352076452764038 <class 'numpy.float64'>\n",
      "gene 713: corr = 0.470243866287557 <class 'numpy.float64'>\n",
      "gene 714: corr = 0.3472643904008432 <class 'numpy.float64'>\n",
      "gene 715: corr = 0.5815381681550439 <class 'numpy.float64'>\n",
      "gene 716: corr = 0.7538771276579123 <class 'numpy.float64'>\n",
      "gene 717: corr = 0.6917890202647657 <class 'numpy.float64'>\n",
      "gene 719: corr = 0.1823750129663299 <class 'numpy.float64'>\n",
      "gene 720: corr = 0.14956172659744685 <class 'numpy.float64'>\n",
      "gene 721: corr = 0.70159848846511 <class 'numpy.float64'>\n",
      "gene 722: corr = 0.7038421710653732 <class 'numpy.float64'>\n",
      "gene 723: corr = 0.35040646115683216 <class 'numpy.float64'>\n",
      "gene 724: corr = -0.016237161877834323 <class 'numpy.float64'>\n",
      "gene 725: corr = 0.043737426851848275 <class 'numpy.float64'>\n",
      "gene 726: corr = 0.5544595692697941 <class 'numpy.float64'>\n",
      "gene 727: corr = 0.1379138480116951 <class 'numpy.float64'>\n",
      "gene 728: corr = 0.315717460146049 <class 'numpy.float64'>\n",
      "gene 729: corr = 0.6014120596655456 <class 'numpy.float64'>\n",
      "gene 730: corr = 0.304573683600493 <class 'numpy.float64'>\n",
      "gene 731: corr = 0.20976553540811513 <class 'numpy.float64'>\n",
      "gene 732: corr = 0.5329232486112156 <class 'numpy.float64'>\n",
      "gene 733: corr = 0.09388216085317659 <class 'numpy.float64'>\n",
      "gene 734: corr = -0.027838704141742998 <class 'numpy.float64'>\n",
      "gene 735: corr = 0.22603988594965962 <class 'numpy.float64'>\n",
      "gene 736: corr = 0.3927428342158805 <class 'numpy.float64'>\n",
      "gene 737: corr = 0.7935314597880881 <class 'numpy.float64'>\n",
      "gene 738: corr = 0.586552055540698 <class 'numpy.float64'>\n",
      "gene 739: corr = 0.31601887521281546 <class 'numpy.float64'>\n",
      "gene 740: corr = 0.6794787010163524 <class 'numpy.float64'>\n",
      "gene 741: corr = 0.4984947281446174 <class 'numpy.float64'>\n",
      "gene 742: corr = 0.6912932819110963 <class 'numpy.float64'>\n",
      "gene 743: corr = 0.5253771069403966 <class 'numpy.float64'>\n",
      "gene 744: corr = 0.45658938630861917 <class 'numpy.float64'>\n",
      "gene 745: corr = 0.22003927425150685 <class 'numpy.float64'>\n",
      "gene 746: corr = 0.11309256084179997 <class 'numpy.float64'>\n",
      "gene 747: corr = 0.28403251871921087 <class 'numpy.float64'>\n",
      "gene 749: corr = 0.15691032233132104 <class 'numpy.float64'>\n",
      "gene 750: corr = 0.7648970780394684 <class 'numpy.float64'>\n",
      "gene 751: corr = 0.3672181967869046 <class 'numpy.float64'>\n",
      "gene 752: corr = 0.7947139268491251 <class 'numpy.float64'>\n",
      "gene 753: corr = 0.4542790134058353 <class 'numpy.float64'>\n",
      "gene 754: corr = 0.1330484650585659 <class 'numpy.float64'>\n",
      "gene 755: corr = 0.20757430084956724 <class 'numpy.float64'>\n",
      "gene 756: corr = 0.29657129905123003 <class 'numpy.float64'>\n",
      "gene 757: corr = 0.23992570129334367 <class 'numpy.float64'>\n",
      "gene 758: corr = 0.7663249653291501 <class 'numpy.float64'>\n",
      "gene 759: corr = 0.16333655209025677 <class 'numpy.float64'>\n",
      "gene 760: corr = 0.3991192774059034 <class 'numpy.float64'>\n",
      "gene 761: corr = 0.1838804013266442 <class 'numpy.float64'>\n",
      "gene 762: corr = 0.611774783323007 <class 'numpy.float64'>\n",
      "gene 763: corr = 0.1154708915280692 <class 'numpy.float64'>\n",
      "gene 764: corr = 0.3969137303069432 <class 'numpy.float64'>\n",
      "gene 765: corr = 0.07578493605245307 <class 'numpy.float64'>\n",
      "gene 766: corr = 0.25153836560168835 <class 'numpy.float64'>\n",
      "gene 767: corr = 0.46307486239004064 <class 'numpy.float64'>\n",
      "gene 768: corr = 0.5739202979970625 <class 'numpy.float64'>\n",
      "gene 769: corr = 0.7879813905605637 <class 'numpy.float64'>\n",
      "gene 770: corr = 0.8401912181344541 <class 'numpy.float64'>\n",
      "gene 771: corr = 0.5850447887043178 <class 'numpy.float64'>\n",
      "gene 772: corr = 0.29378626958178544 <class 'numpy.float64'>\n",
      "gene 773: corr = 0.038983095064172496 <class 'numpy.float64'>\n",
      "gene 774: corr = 0.28776499443714804 <class 'numpy.float64'>\n",
      "gene 775: corr = 0.724309835794945 <class 'numpy.float64'>\n",
      "gene 776: corr = 0.7871648555342793 <class 'numpy.float64'>\n",
      "gene 777: corr = 0.18158468904774563 <class 'numpy.float64'>\n",
      "gene 778: corr = 0.20852323794779795 <class 'numpy.float64'>\n",
      "gene 779: corr = 0.45682044794258814 <class 'numpy.float64'>\n",
      "gene 780: corr = 0.07625937499453952 <class 'numpy.float64'>\n",
      "gene 781: corr = 0.08219838985528931 <class 'numpy.float64'>\n",
      "gene 782: corr = 0.6869831461048878 <class 'numpy.float64'>\n",
      "gene 783: corr = 0.4047195488209506 <class 'numpy.float64'>\n",
      "gene 784: corr = 0.12395931554826906 <class 'numpy.float64'>\n",
      "gene 785: corr = 0.5978406554063653 <class 'numpy.float64'>\n",
      "gene 786: corr = 0.34501759581898483 <class 'numpy.float64'>\n",
      "gene 787: corr = 0.34614912552151317 <class 'numpy.float64'>\n",
      "gene 788: corr = 0.8232174280570134 <class 'numpy.float64'>\n",
      "gene 789: corr = 0.7451826615418098 <class 'numpy.float64'>\n",
      "gene 790: corr = 0.30945903808508485 <class 'numpy.float64'>\n",
      "gene 791: corr = 0.12702749931124213 <class 'numpy.float64'>\n",
      "gene 792: corr = 0.6118824532390982 <class 'numpy.float64'>\n",
      "gene 793: corr = 0.7044112619498353 <class 'numpy.float64'>\n",
      "gene 794: corr = 0.07511502169307459 <class 'numpy.float64'>\n",
      "gene 795: corr = 0.6845506010296184 <class 'numpy.float64'>\n",
      "gene 796: corr = 0.5524503532596476 <class 'numpy.float64'>\n",
      "gene 797: corr = 0.8127515401865574 <class 'numpy.float64'>\n",
      "gene 798: corr = 0.5769009704902871 <class 'numpy.float64'>\n",
      "gene 799: corr = 0.547851673519848 <class 'numpy.float64'>\n",
      "gene 800: corr = 0.43698334728927357 <class 'numpy.float64'>\n",
      "gene 801: corr = 0.2667320504339476 <class 'numpy.float64'>\n",
      "gene 802: corr = 0.5401506230616235 <class 'numpy.float64'>\n",
      "gene 803: corr = 0.2951020773857758 <class 'numpy.float64'>\n",
      "gene 804: corr = 0.5063534078000836 <class 'numpy.float64'>\n",
      "gene 805: corr = 0.28348150458038535 <class 'numpy.float64'>\n",
      "gene 806: corr = 0.5843993027576259 <class 'numpy.float64'>\n",
      "gene 807: corr = 0.13301791816815112 <class 'numpy.float64'>\n",
      "gene 808: corr = 0.5688400909785063 <class 'numpy.float64'>\n",
      "gene 809: corr = 0.5315717951938301 <class 'numpy.float64'>\n",
      "gene 810: corr = 0.6706755910481782 <class 'numpy.float64'>\n",
      "gene 811: corr = 0.562684700857604 <class 'numpy.float64'>\n",
      "gene 812: corr = 0.36849246337908825 <class 'numpy.float64'>\n",
      "gene 813: corr = 0.17616345944603876 <class 'numpy.float64'>\n",
      "gene 814: corr = 0.2677548687515294 <class 'numpy.float64'>\n",
      "gene 815: corr = 0.03613760806556897 <class 'numpy.float64'>\n",
      "gene 816: corr = 0.7404993627291251 <class 'numpy.float64'>\n",
      "gene 817: corr = 0.7933679300975924 <class 'numpy.float64'>\n",
      "gene 818: corr = 0.1444749454725733 <class 'numpy.float64'>\n",
      "gene 819: corr = 0.32185121785970133 <class 'numpy.float64'>\n",
      "gene 820: corr = 0.8346638007728565 <class 'numpy.float64'>\n",
      "gene 821: corr = 0.24885619633495623 <class 'numpy.float64'>\n",
      "gene 822: corr = 0.2187164247776325 <class 'numpy.float64'>\n",
      "gene 823: corr = 0.1568384876215251 <class 'numpy.float64'>\n",
      "gene 824: corr = 0.31206665572275955 <class 'numpy.float64'>\n",
      "gene 825: corr = 0.11562745826000377 <class 'numpy.float64'>\n",
      "gene 826: corr = 0.5029020339852958 <class 'numpy.float64'>\n",
      "gene 827: corr = 0.19453756695505714 <class 'numpy.float64'>\n",
      "gene 828: corr = 0.43559971754582294 <class 'numpy.float64'>\n",
      "gene 829: corr = 0.7840351514609696 <class 'numpy.float64'>\n",
      "gene 830: corr = 0.1394847287001073 <class 'numpy.float64'>\n",
      "gene 831: corr = 0.3271205091250248 <class 'numpy.float64'>\n",
      "gene 832: corr = 0.3985319949312009 <class 'numpy.float64'>\n",
      "gene 833: corr = 0.7356902034256243 <class 'numpy.float64'>\n",
      "gene 834: corr = 0.2655912611974898 <class 'numpy.float64'>\n",
      "gene 835: corr = 0.06031170742737901 <class 'numpy.float64'>\n",
      "gene 836: corr = 0.7924138006605589 <class 'numpy.float64'>\n",
      "gene 837: corr = 0.46824942907488265 <class 'numpy.float64'>\n",
      "gene 838: corr = 0.4609241580859282 <class 'numpy.float64'>\n",
      "gene 839: corr = 0.36240726945783064 <class 'numpy.float64'>\n",
      "gene 840: corr = 0.7892515006053938 <class 'numpy.float64'>\n",
      "gene 841: corr = 0.54567804668533 <class 'numpy.float64'>\n",
      "gene 842: corr = 0.300915039469263 <class 'numpy.float64'>\n",
      "gene 843: corr = 0.5825689912547969 <class 'numpy.float64'>\n",
      "gene 844: corr = 0.2245321418069576 <class 'numpy.float64'>\n",
      "gene 845: corr = 0.11508486296823275 <class 'numpy.float64'>\n",
      "gene 846: corr = 0.5576591153338641 <class 'numpy.float64'>\n",
      "gene 847: corr = 0.11825389768165456 <class 'numpy.float64'>\n",
      "gene 848: corr = 0.6502097018942233 <class 'numpy.float64'>\n",
      "gene 849: corr = 0.5825393622359192 <class 'numpy.float64'>\n",
      "gene 850: corr = 0.8451850712485341 <class 'numpy.float64'>\n",
      "gene 851: corr = 0.15597705366593428 <class 'numpy.float64'>\n",
      "gene 853: corr = 0.2949791225363127 <class 'numpy.float64'>\n",
      "gene 854: corr = 0.38245951435503245 <class 'numpy.float64'>\n",
      "gene 855: corr = 0.7735832263801186 <class 'numpy.float64'>\n",
      "gene 856: corr = -0.035504231147376775 <class 'numpy.float64'>\n",
      "gene 857: corr = 0.25516119396988646 <class 'numpy.float64'>\n",
      "gene 859: corr = 0.0589881245728083 <class 'numpy.float64'>\n",
      "gene 860: corr = 0.3750463939355912 <class 'numpy.float64'>\n",
      "gene 861: corr = 0.5067148574143412 <class 'numpy.float64'>\n",
      "gene 862: corr = 0.44000637393245756 <class 'numpy.float64'>\n",
      "gene 863: corr = 0.6848755649425412 <class 'numpy.float64'>\n",
      "gene 864: corr = 0.6209898456643979 <class 'numpy.float64'>\n",
      "gene 865: corr = 0.41304945121191533 <class 'numpy.float64'>\n",
      "gene 866: corr = 0.30235275335764444 <class 'numpy.float64'>\n",
      "gene 867: corr = 0.3909589644705225 <class 'numpy.float64'>\n",
      "gene 868: corr = 0.3290411686668246 <class 'numpy.float64'>\n",
      "gene 869: corr = 0.6485629299529337 <class 'numpy.float64'>\n",
      "gene 870: corr = 0.06810593381957729 <class 'numpy.float64'>\n",
      "gene 871: corr = 0.18133034863905476 <class 'numpy.float64'>\n",
      "gene 872: corr = -0.01666639758227429 <class 'numpy.float64'>\n",
      "gene 873: corr = 0.5893211809549074 <class 'numpy.float64'>\n",
      "gene 874: corr = 0.32028797091444705 <class 'numpy.float64'>\n",
      "gene 876: corr = 0.6564720286937056 <class 'numpy.float64'>\n",
      "gene 877: corr = 0.1916268798725786 <class 'numpy.float64'>\n",
      "gene 878: corr = 0.18185073220867476 <class 'numpy.float64'>\n",
      "gene 879: corr = 0.3213035015869263 <class 'numpy.float64'>\n",
      "gene 880: corr = 0.6356861619179139 <class 'numpy.float64'>\n",
      "gene 881: corr = 0.6723302619437745 <class 'numpy.float64'>\n",
      "gene 882: corr = 0.6527549650088559 <class 'numpy.float64'>\n",
      "gene 883: corr = 0.3917735763123346 <class 'numpy.float64'>\n",
      "gene 884: corr = 0.5706278967868336 <class 'numpy.float64'>\n",
      "gene 885: corr = -0.018195208289046236 <class 'numpy.float64'>\n",
      "gene 886: corr = 0.22778557912132338 <class 'numpy.float64'>\n",
      "gene 887: corr = 0.17792987735554938 <class 'numpy.float64'>\n",
      "gene 888: corr = 0.7115239998013048 <class 'numpy.float64'>\n",
      "gene 889: corr = -0.02964700812488845 <class 'numpy.float64'>\n",
      "gene 890: corr = 0.7480558028041152 <class 'numpy.float64'>\n",
      "gene 891: corr = 0.7521004714367389 <class 'numpy.float64'>\n",
      "gene 892: corr = 0.45291215457847234 <class 'numpy.float64'>\n",
      "gene 893: corr = 0.31420169982030755 <class 'numpy.float64'>\n",
      "gene 894: corr = 0.8683014622554405 <class 'numpy.float64'>\n",
      "gene 895: corr = 0.5961591094124435 <class 'numpy.float64'>\n",
      "gene 896: corr = 0.7231907878984033 <class 'numpy.float64'>\n",
      "gene 897: corr = -0.010270058719742101 <class 'numpy.float64'>\n",
      "gene 898: corr = 0.419136649041375 <class 'numpy.float64'>\n",
      "gene 899: corr = 0.5707025395229668 <class 'numpy.float64'>\n",
      "gene 900: corr = 0.4956343550983828 <class 'numpy.float64'>\n",
      "gene 901: corr = 0.3808823510611383 <class 'numpy.float64'>\n",
      "gene 902: corr = 0.5949451233821818 <class 'numpy.float64'>\n",
      "gene 903: corr = 0.5070590094967542 <class 'numpy.float64'>\n",
      "gene 904: corr = 0.6940182284153212 <class 'numpy.float64'>\n",
      "gene 905: corr = -0.01962760621128097 <class 'numpy.float64'>\n",
      "gene 907: corr = 0.5835237951410889 <class 'numpy.float64'>\n",
      "gene 908: corr = 0.4265167692697922 <class 'numpy.float64'>\n",
      "gene 909: corr = 0.7219625041437225 <class 'numpy.float64'>\n",
      "gene 910: corr = 0.3991641058575601 <class 'numpy.float64'>\n",
      "gene 911: corr = 0.42761043735501414 <class 'numpy.float64'>\n",
      "gene 912: corr = 0.31120394941730384 <class 'numpy.float64'>\n",
      "gene 913: corr = 0.5685456464863785 <class 'numpy.float64'>\n",
      "gene 914: corr = 0.14529893443541075 <class 'numpy.float64'>\n",
      "gene 915: corr = 0.6770789043461145 <class 'numpy.float64'>\n",
      "gene 916: corr = -0.010269290998083552 <class 'numpy.float64'>\n",
      "gene 917: corr = 0.31792022589248625 <class 'numpy.float64'>\n",
      "gene 918: corr = 0.26084016698729057 <class 'numpy.float64'>\n",
      "gene 919: corr = 0.3679716483796422 <class 'numpy.float64'>\n",
      "gene 921: corr = 0.8037133991391662 <class 'numpy.float64'>\n",
      "gene 922: corr = 0.11029542431719372 <class 'numpy.float64'>\n",
      "gene 923: corr = -0.0028369393655811883 <class 'numpy.float64'>\n",
      "gene 924: corr = 0.5972093953987306 <class 'numpy.float64'>\n",
      "gene 925: corr = 0.7861992465994007 <class 'numpy.float64'>\n",
      "gene 926: corr = 0.7865900981952044 <class 'numpy.float64'>\n",
      "gene 927: corr = 0.7649031560930128 <class 'numpy.float64'>\n",
      "gene 928: corr = 0.3878648854426792 <class 'numpy.float64'>\n",
      "gene 929: corr = 0.09332660565019256 <class 'numpy.float64'>\n",
      "gene 930: corr = 0.3509795063736442 <class 'numpy.float64'>\n",
      "gene 931: corr = 0.6646792511133 <class 'numpy.float64'>\n",
      "gene 932: corr = 0.45162982499197396 <class 'numpy.float64'>\n",
      "gene 933: corr = 0.7542399990198563 <class 'numpy.float64'>\n",
      "gene 934: corr = 0.794601005117815 <class 'numpy.float64'>\n",
      "gene 935: corr = 0.3530005505732199 <class 'numpy.float64'>\n",
      "gene 936: corr = 0.13027385773158703 <class 'numpy.float64'>\n",
      "gene 937: corr = 0.3589327503514229 <class 'numpy.float64'>\n",
      "gene 938: corr = 0.8137129328657128 <class 'numpy.float64'>\n",
      "gene 939: corr = 0.08930212161980931 <class 'numpy.float64'>\n",
      "gene 940: corr = 0.5734356113290451 <class 'numpy.float64'>\n",
      "gene 941: corr = 0.16070185448515115 <class 'numpy.float64'>\n",
      "gene 942: corr = 0.5340612013023374 <class 'numpy.float64'>\n",
      "gene 943: corr = 0.3477097837207389 <class 'numpy.float64'>\n",
      "gene 944: corr = 0.42847286714548755 <class 'numpy.float64'>\n",
      "gene 945: corr = 0.7557483756135775 <class 'numpy.float64'>\n",
      "gene 946: corr = 0.7588588593817841 <class 'numpy.float64'>\n",
      "gene 947: corr = 0.30830001366744425 <class 'numpy.float64'>\n",
      "gene 948: corr = 0.3632450486293944 <class 'numpy.float64'>\n",
      "gene 949: corr = 0.6560334250847515 <class 'numpy.float64'>\n",
      "gene 950: corr = 0.17772064558240236 <class 'numpy.float64'>\n",
      "gene 951: corr = 0.2418914382690133 <class 'numpy.float64'>\n",
      "gene 952: corr = 0.3756691925940659 <class 'numpy.float64'>\n",
      "gene 953: corr = 0.5310315537561483 <class 'numpy.float64'>\n",
      "gene 954: corr = 0.34699065705539206 <class 'numpy.float64'>\n",
      "gene 955: corr = 0.7779003426171265 <class 'numpy.float64'>\n",
      "gene 956: corr = 0.6986870339172713 <class 'numpy.float64'>\n",
      "gene 957: corr = 0.5280547857780824 <class 'numpy.float64'>\n",
      "gene 958: corr = -0.015723132918207743 <class 'numpy.float64'>\n",
      "gene 959: corr = 0.7676019546318853 <class 'numpy.float64'>\n",
      "gene 960: corr = 0.2723295297239141 <class 'numpy.float64'>\n",
      "gene 961: corr = 0.5267626458057496 <class 'numpy.float64'>\n",
      "gene 962: corr = 0.3473328091471808 <class 'numpy.float64'>\n",
      "gene 963: corr = 0.3422988257745479 <class 'numpy.float64'>\n",
      "gene 964: corr = 0.5349358429047353 <class 'numpy.float64'>\n",
      "gene 965: corr = 0.20978905879081927 <class 'numpy.float64'>\n",
      "gene 966: corr = 0.3954420071820784 <class 'numpy.float64'>\n",
      "gene 967: corr = 0.615251557649659 <class 'numpy.float64'>\n",
      "gene 968: corr = 0.5435911178584717 <class 'numpy.float64'>\n",
      "gene 969: corr = 0.3609949355169427 <class 'numpy.float64'>\n",
      "gene 970: corr = 0.8330716906842199 <class 'numpy.float64'>\n",
      "gene 971: corr = 0.772461279269827 <class 'numpy.float64'>\n",
      "gene 972: corr = 0.42778829333379187 <class 'numpy.float64'>\n",
      "gene 973: corr = 0.7848952734503885 <class 'numpy.float64'>\n",
      "gene 974: corr = 0.062417732404851364 <class 'numpy.float64'>\n",
      "gene 975: corr = 0.01000251137953461 <class 'numpy.float64'>\n",
      "gene 976: corr = 0.4412311174100221 <class 'numpy.float64'>\n",
      "gene 977: corr = 0.20443679529864175 <class 'numpy.float64'>\n",
      "gene 978: corr = 0.4296302691408761 <class 'numpy.float64'>\n",
      "gene 979: corr = 0.48484429124886885 <class 'numpy.float64'>\n",
      "gene 980: corr = 0.3727312058841071 <class 'numpy.float64'>\n",
      "gene 981: corr = 0.38532229171979426 <class 'numpy.float64'>\n",
      "gene 982: corr = 0.6219784068932963 <class 'numpy.float64'>\n",
      "gene 983: corr = 0.5928780170745485 <class 'numpy.float64'>\n",
      "gene 984: corr = 0.11484554960781745 <class 'numpy.float64'>\n",
      "gene 985: corr = 0.8753193861227838 <class 'numpy.float64'>\n",
      "gene 986: corr = 0.07776502269765026 <class 'numpy.float64'>\n",
      "gene 987: corr = 0.19504409620251553 <class 'numpy.float64'>\n",
      "gene 988: corr = 0.2343523996841234 <class 'numpy.float64'>\n",
      "gene 989: corr = 0.022966153687666403 <class 'numpy.float64'>\n",
      "gene 990: corr = 0.6079830868552781 <class 'numpy.float64'>\n",
      "gene 991: corr = 0.08826172787993045 <class 'numpy.float64'>\n",
      "gene 992: corr = 0.3626543480763052 <class 'numpy.float64'>\n",
      "gene 993: corr = 0.6888086758748917 <class 'numpy.float64'>\n",
      "gene 994: corr = 0.18434415037883362 <class 'numpy.float64'>\n",
      "gene 995: corr = -0.011144550351208446 <class 'numpy.float64'>\n",
      "gene 996: corr = 0.5906728432128514 <class 'numpy.float64'>\n",
      "gene 997: corr = 0.3621147015391428 <class 'numpy.float64'>\n",
      "gene 998: corr = 0.8185925235157917 <class 'numpy.float64'>\n",
      "gene 999: corr = 0.36102939574539916 <class 'numpy.float64'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.41429399710496534"
      ]
     },
     "metadata": {},
     "execution_count": 232
    }
   ],
   "source": [
    "mean = 0\n",
    "for i in range(internal_X.shape[1]):\n",
    "    corr = stats.spearmanr(internal_X[:, i], internal_avg_X[:, i])\n",
    "    if math.isnan(corr[0]):\n",
    "        continue\n",
    "    mean += corr[0]\n",
    "    print('gene {}: corr = {}'.format(i, corr[0]), type(corr[0]))\n",
    "mean /= internal_X.shape[1]\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CascVI Baseline 2 (Reconstruction of Averaged latent space)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_cascvi_2, imputed_cascvi_2_z = avg_baseline_z(tree=tree,\n",
    "                                   model=treevae,\n",
    "                                   posterior=full_posterior,\n",
    "                                   weighted=False,\n",
    "                                   n_samples_z=1,\n",
    "                                   library_size=empirical_l,\n",
    "                                   gaussian=False,\n",
    "                                   use_cuda=False,\n",
    "                                   known_latent=True,\n",
    "                                   latent=np.array([leaves_z]),\n",
    "                                   give_cov=False\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_cascvi_2 = {}\n",
    "\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        mu_z = np.clip(a=np.exp(nb_glm.W @ imputed_cascvi_2_z[n.name][0] + nb_glm.beta),\n",
    "                        a_min=0,\n",
    "                        a_max=1e8\n",
    "                        )\n",
    "        \n",
    "        if treevae.reconstruction_loss == 'nb':\n",
    "            r, p = convert_params_NB(mu=mu_z, alpha=alpha)\n",
    "            sample = nbinom.rvs(n=r, p=1-p)\n",
    "        else:\n",
    "            sample = np.random.poisson(mu_z)\n",
    "        imputed_cascvi_2[n.name] = np.clip(a=sample,\n",
    "                                           a_min=0,\n",
    "                                           a_max=1e8\n",
    "                                           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1: Unweighted Average of gene expression in Clade\n",
    "\n",
    "The simple idea here is to impute the value of an internal node, with the (un)weighted average of the gene expression values of the leaves, taking the query internal node as the root of the subtree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted = False\n",
    "imputed_avg = avg_weighted_baseline(tree, weighted, nb_glm.X, rounding=True)\n",
    "\n",
    "#get internal nodes\n",
    "avg_X = np.array([x for x in imputed_avg.values()]).reshape(-1, nb_glm.X.shape[1])\n",
    "internal_avg_X, _, _ = get_internal(avg_X, nb_glm.mu, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2: (Un)weighted Average of decoded latent vectors, with scVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same averaging of the subtrees leaves in **Baseline 1**, only this time, the gene expression data is recovered with scVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anndata\n",
    "gene_dataset = GeneExpressionDataset()\n",
    "gene_dataset.populate_from_data(leaves_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "n_epochs = 500\n",
    "use_batches = False\n",
    "\n",
    "vae = VAE(gene_dataset.nb_genes,\n",
    "                  n_batch=cas_dataset.n_batches * use_batches,\n",
    "                  n_hidden=64,\n",
    "                  n_layers=1,\n",
    "                  reconstruction_loss='nb',\n",
    "                  n_latent=nb_glm.latent,\n",
    "                  ldvae=ldvae\n",
    "              )\n",
    "\n",
    "if freeze:\n",
    "    new_weight = torch.from_numpy(nb_glm.W).float()\n",
    "    new_bias = torch.from_numpy(nb_glm.beta).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        vae.decoder.factor_regressor.fc_layers[0][0].weight = torch.nn.Parameter(new_weight)\n",
    "        vae.decoder.factor_regressor.fc_layers[0][0].bias = torch.nn.Parameter(new_bias)\n",
    "        \n",
    "    for param in vae.decoder.factor_regressor.fc_layers[0][0].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance between the Poisson and the NB means is 11221.932083575548\n"
     ]
    }
   ],
   "source": [
    "px_scale, px_r, px_rate, px_dropout = vae.decoder.forward(vae.dispersion,\n",
    "                                        torch.from_numpy(leaves_z).float(),\n",
    "                                        torch.from_numpy(np.array([np.log(10000)])).float(),\n",
    "                                        None\n",
    "                                        )\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "if ldvae:\n",
    "    foo = np.clip(a=np.exp(px_r.detach().numpy()),\n",
    "            a_min=0,\n",
    "            a_max=5000\n",
    "    )\n",
    "    mse = mean_squared_error(mu, foo)\n",
    "else:\n",
    "    mse = mean_squared_error(mu, px_rate.detach().numpy())\n",
    "\n",
    "print(\"the distance between the Poisson and the NB means is {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training: 100%|██████████| 500/500 [00:06<00:00, 72.53it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer_scvi = UnsupervisedTrainer(model=vae,\n",
    "                              gene_dataset=gene_dataset,\n",
    "                              train_size=1.0,\n",
    "                              use_cuda=use_cuda,\n",
    "                              frequency=10,\n",
    "                              n_epochs_kl_warmup=2000\n",
    "                              )\n",
    "\n",
    "# train scVI\n",
    "trainer_scvi.train(n_epochs=n_epochs, lr=1e-3) \n",
    "                                        \n",
    "elbo_train_scvi = trainer_scvi.history[\"elbo_train_set\"]\n",
    "x = np.linspace(0, 100, (len(elbo_train_scvi)))\n",
    "plt.plot(np.log(elbo_train_scvi), \n",
    "         label=\"train\", color='blue',\n",
    "         linestyle=':',\n",
    "         linewidth=3\n",
    "        )\n",
    "        \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.legend()\n",
    "plt.title(\"Train history scVI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance is 3.889812574646592\n"
     ]
    }
   ],
   "source": [
    "scvi_posterior = trainer_scvi.create_posterior(model=vae,\n",
    "                                               gene_dataset=gene_dataset \n",
    "                                                )\n",
    "\n",
    "error = mean_squared_error(scvi_posterior.get_latent()[0], leaves_z)\n",
    "print(\"the distance is {}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***scVI Baseline 2 (Decoded Average Latent space)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_size = np.mean(np.sum(nb_glm.X, axis=1))\n",
    "scvi_latent = np.array([scvi_posterior.get_latent(give_mean=False)[0] for i in range(10)])\n",
    "\n",
    "imputed_scvi_2, imputed_scvi_2_z = scvi_baseline_z(tree,\n",
    "                                        posterior=scvi_posterior,\n",
    "                                        model=vae,\n",
    "                                        weighted=False,\n",
    "                                        n_samples_z=1,\n",
    "                                        library_size=library_size,\n",
    "                                        use_cuda=False\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Likelihood Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100, 5), (100, 5))"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "cascvi_latent = full_posterior.get_latent()\n",
    "scvi_latent = scvi_posterior.get_latent()[0]\n",
    "\n",
    "scvi_latent.shape, cascvi_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood of scVI encodings:  -14685.11046910444\n"
     ]
    }
   ],
   "source": [
    "treevae.initialize_visit()\n",
    "treevae.initialize_messages(scvi_latent, cas_dataset.barcodes, scvi_latent.shape[1])\n",
    "treevae.perform_message_passing((treevae.tree & treevae.root), scvi_latent.shape[1], False)\n",
    "mp_lik_scvi = treevae.aggregate_messages_into_leaves_likelihood(d, add_prior=True)\n",
    "print(\"Likelihood of scVI encodings: \", mp_lik_scvi.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood of cascVI encodings:  -69.8083984094612\n"
     ]
    }
   ],
   "source": [
    "treevae.initialize_visit()\n",
    "treevae.initialize_messages(cascvi_latent, cas_dataset.barcodes, cascvi_latent.shape[1])\n",
    "treevae.perform_message_passing((treevae.tree & treevae.root), cascvi_latent.shape[1], False)\n",
    "mp_lik_cascvi = treevae.aggregate_messages_into_leaves_likelihood(d, add_prior=True)\n",
    "print(\"Likelihood of cascVI encodings: \", mp_lik_cascvi.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood of observations:  -203.46344429379195\n"
     ]
    }
   ],
   "source": [
    "treevae.initialize_visit()\n",
    "treevae.initialize_messages(leaves_z, cas_dataset.barcodes, cascvi_latent.shape[1])\n",
    "treevae.perform_message_passing((treevae.tree & treevae.root), cascvi_latent.shape[1], False)\n",
    "mp_lik_cascvi = treevae.aggregate_messages_into_leaves_likelihood(d, add_prior=True)\n",
    "print(\"Likelihood of observations: \", mp_lik_cascvi.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood Ratio: tensor(14481.6470, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Likelihood ratio\n",
    "lambda_ = (mp_lik_cascvi - mp_lik_scvi)\n",
    "print(\"Likelihood Ratio:\", lambda_)"
   ]
  },
  {
   "source": [
    "# 6. Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CPM Normalization (for sample-sample correlation)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get imputations into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100, 100), (100, 100), (100, 100), (100, 100), (100, 100), (100, 100))"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "internal_scvi_X_2 = np.array([x for x in imputed_scvi_2.values()]).reshape(-1, nb_glm.X.shape[1])\n",
    "internal_cascvi_X = np.array([x for x in imputed_cascvi_1.values()]).reshape(-1, nb_glm.X.shape[1])\n",
    "internal_cascvi_X_2 = np.array([x for x in imputed_cascvi_2.values()]).reshape(-1, nb_glm.X.shape[1])\n",
    "\n",
    "internal_cascvi_X_2.shape, internal_cascvi_X.shape, internal_scvi_X_2.shape, imputed_X.shape, internal_avg_X.shape, internal_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "internal_scvi_X_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "norm_internal_X = sc.pp.normalize_total(AnnData(internal_X), target_sum=1e4, inplace=False)['X'] \n",
    "norm_scvi_X_2 = sc.pp.normalize_total(AnnData(internal_scvi_X_2), target_sum=1e4, inplace=False)['X']\n",
    "norm_avg_X = sc.pp.normalize_total(AnnData(internal_avg_X), target_sum=1e4, inplace=False)['X']\n",
    "norm_imputed_X = sc.pp.normalize_total(AnnData(imputed_X), target_sum=1e4, inplace=False)['X']\n",
    "norm_cascvi_X = sc.pp.normalize_total(AnnData(internal_cascvi_X), target_sum=1e4, inplace=False)['X']\n",
    "norm_cascvi_X_2 = sc.pp.normalize_total(AnnData(internal_cascvi_X_2), target_sum=1e4, inplace=False)['X']\n",
    "\n",
    "norm_internal_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Sample-Sample Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1. Sample-Sample correlation (Without Normalization)***\n",
    "\n",
    "We will use Scipy to compute a nonparametric rank correlation between the imputed and the groundtruth profiles. The correlation is based on the Spearman Correlation Coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {'groundtruth': internal_X.T, 'cascVI': imputed_X.T, 'scVI': internal_scvi_X_2.T,\n",
    "        'Average': internal_avg_X.T , 'Avg Oracle': internal_cascvi_X_2.T,\n",
    "        'MP Oracle': internal_cascvi_X.T\n",
    "        }\n",
    "        \n",
    "df1 = correlations(data, 'None', True)\n",
    "#df1.head(5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2. Sample-Sample correlation (With ScanPy Normalization)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'groundtruth': norm_internal_X.T, 'cascVI': norm_imputed_X.T, 'scVI': norm_scvi_X_2.T, \n",
    "        'Average': norm_avg_X.T , 'Avg Oracle': norm_cascvi_X_2.T,\n",
    "        'MP Oracle': norm_cascvi_X.T\n",
    "        }\n",
    "\n",
    "df2 = correlations(data, 'None', True)\n",
    "#df2.head(5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## II. Gene-Gene Correlations"
   ]
  },
  {
   "source": [
    "***2. Gene-Gene correlation (With Normalization)***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:4264: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(SpearmanRConstantInputWarning())\n/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "data = {'groundtruth': internal_X, 'cascVI': imputed_X, 'scVI': internal_scvi_X_2,\n",
    "        'Average': internal_avg_X , 'Avg Oracle': internal_cascvi_X_2,\n",
    "        'MP Oracle': internal_cascvi_X\n",
    "        }\n",
    "\n",
    "df3 = correlations(data, 'None', True)\n",
    "#df3.head(5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2. Gene-Gene correlation (With Normalization)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:4264: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(SpearmanRConstantInputWarning())\n/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "data = {'groundtruth': norm_internal_X, 'cascVI': norm_imputed_X, 'scVI': norm_scvi_X_2, \n",
    "        'Average': norm_avg_X , 'Avg Oracle': norm_cascvi_X_2,\n",
    "        'MP Oracle': norm_cascvi_X\n",
    "        }\n",
    "\n",
    "df4 = correlations(data, 'None', True)\n",
    "#df4.head(5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***3. Gene-Gene correlation (With Rank Normalization)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:4264: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(SpearmanRConstantInputWarning())\n/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "#data = {'groundtruth': norm_internal_X, 'cascVI': norm_imputed_X, 'scVI': norm_scvi_X_2, \n",
    "#        'Average': norm_avg_X , 'cascVI + Avg': norm_cascvi_X_2,\n",
    "#        'MP Oracle': norm_cascvi_X\n",
    "#        }\n",
    "\n",
    "data = {'groundtruth': internal_X, 'cascVI': imputed_X, 'scVI': internal_scvi_X_2,\n",
    "        'Average': internal_avg_X , 'Avg Oracle': internal_cascvi_X_2,\n",
    "        'MP Oracle': internal_cascvi_X\n",
    "        }\n",
    "        \n",
    "df5 = correlations(data, 'rank', True)\n",
    "#df5.head(5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Table Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Method\", \"Spearman CC\", \"Pearson CC\", \"Kendall Tau\"]\n",
    "data = [df1, df2, df3, df4, df5]\n",
    "#data = [df2, df4]\n",
    "\n",
    "data \n",
    "tables = [[] for i in range(len(data))]\n",
    "\n",
    "#task = [\"Sample-Sample (None)\", \"Sample-Sample (CPM)\", \"Gene-Gene (None)\", \n",
    "           #\"Gene-Gene(CPM)\", \"Gene-Gene (Rank)\" ]\n",
    "\n",
    "for (df, t) in zip(data, tables):\n",
    "    for m in np.unique(df.Method):\n",
    "        sub_df = np.round(df[df['Method'] == m].mean(), decimals=3)\n",
    "        t.append([m, sub_df['Spearman CC'], sub_df['Pearson CC'], sub_df['Kendall Tau']])\n",
    "        \n",
    "# Create and style Data Frames\n",
    "df_table1 = pd.DataFrame(tables[0], columns=columns)\n",
    "df_table2 = pd.DataFrame(tables[1], columns=columns)\n",
    "df_table3 = pd.DataFrame(tables[2], columns=columns)\n",
    "df_table4 = pd.DataFrame(tables[3], columns=columns)\n",
    "df_table5 = pd.DataFrame(tables[4], columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " >>> Sample-Sample | No Normalization <<<\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Method  Spearman CC  Pearson CC  Kendall Tau\n",
       "0     Average        0.553       0.603        0.478\n",
       "1  Avg Oracle        0.437       0.465        0.375\n",
       "2   MP Oracle        0.439       0.501        0.376\n",
       "3      cascVI        0.357       0.401        0.299\n",
       "4        scVI        0.313       0.320        0.261"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendall Tau</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Average</td>\n      <td>0.553</td>\n      <td>0.603</td>\n      <td>0.478</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avg Oracle</td>\n      <td>0.437</td>\n      <td>0.465</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MP Oracle</td>\n      <td>0.439</td>\n      <td>0.501</td>\n      <td>0.376</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cascVI</td>\n      <td>0.357</td>\n      <td>0.401</td>\n      <td>0.299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scVI</td>\n      <td>0.313</td>\n      <td>0.320</td>\n      <td>0.261</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "print(\" >>> Sample-Sample | No Normalization <<<\")\n",
    "df_table1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> Sample-Sample | CPM Normalization <<<\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Method  Spearman CC  Pearson CC  Kendall Tau\n",
       "0     Average        0.553       0.603        0.478\n",
       "1  Avg Oracle        0.437       0.465        0.375\n",
       "2   MP Oracle        0.439       0.501        0.376\n",
       "3      cascVI        0.357       0.401        0.299\n",
       "4        scVI        0.313       0.320        0.261"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendall Tau</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Average</td>\n      <td>0.553</td>\n      <td>0.603</td>\n      <td>0.478</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avg Oracle</td>\n      <td>0.437</td>\n      <td>0.465</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MP Oracle</td>\n      <td>0.439</td>\n      <td>0.501</td>\n      <td>0.376</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cascVI</td>\n      <td>0.357</td>\n      <td>0.401</td>\n      <td>0.299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scVI</td>\n      <td>0.313</td>\n      <td>0.320</td>\n      <td>0.261</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "print(\">>> Sample-Sample | CPM Normalization <<<\")\n",
    "df_table2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> Gene-Gene | No Normalization <<<\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Method  Spearman CC  Pearson CC  Kendall Tau\n",
       "0     Average        0.194       0.213        0.159\n",
       "1  Avg Oracle        0.123       0.148        0.101\n",
       "2   MP Oracle        0.124       0.130        0.102\n",
       "3      cascVI        0.077       0.084        0.061\n",
       "4        scVI        0.081       0.099        0.065"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendall Tau</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Average</td>\n      <td>0.194</td>\n      <td>0.213</td>\n      <td>0.159</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avg Oracle</td>\n      <td>0.123</td>\n      <td>0.148</td>\n      <td>0.101</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MP Oracle</td>\n      <td>0.124</td>\n      <td>0.130</td>\n      <td>0.102</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cascVI</td>\n      <td>0.077</td>\n      <td>0.084</td>\n      <td>0.061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scVI</td>\n      <td>0.081</td>\n      <td>0.099</td>\n      <td>0.065</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "print(\">>> Gene-Gene | No Normalization <<<\")\n",
    "df_table3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> Gene-Gene | CPM Normalization <<<\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Method  Spearman CC  Pearson CC  Kendall Tau\n",
       "0     Average        0.189       0.222        0.146\n",
       "1  Avg Oracle        0.113       0.147        0.089\n",
       "2   MP Oracle        0.115       0.135        0.091\n",
       "3      cascVI        0.095       0.116        0.072\n",
       "4        scVI        0.087       0.115        0.066"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendall Tau</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Average</td>\n      <td>0.189</td>\n      <td>0.222</td>\n      <td>0.146</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avg Oracle</td>\n      <td>0.113</td>\n      <td>0.147</td>\n      <td>0.089</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MP Oracle</td>\n      <td>0.115</td>\n      <td>0.135</td>\n      <td>0.091</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cascVI</td>\n      <td>0.095</td>\n      <td>0.116</td>\n      <td>0.072</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scVI</td>\n      <td>0.087</td>\n      <td>0.115</td>\n      <td>0.066</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "print(\">>> Gene-Gene | CPM Normalization <<<\")\n",
    "df_table4.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> Gene-Gene | Rank Normalization <<<\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Method  Spearman CC  Pearson CC  Kendall Tau\n",
       "0     Average        0.194       0.194        0.159\n",
       "1  Avg Oracle        0.123       0.123        0.101\n",
       "2   MP Oracle        0.124       0.124        0.102\n",
       "3      cascVI        0.077       0.077        0.061\n",
       "4        scVI        0.081       0.081        0.065"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendall Tau</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Average</td>\n      <td>0.194</td>\n      <td>0.194</td>\n      <td>0.159</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avg Oracle</td>\n      <td>0.123</td>\n      <td>0.123</td>\n      <td>0.101</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MP Oracle</td>\n      <td>0.124</td>\n      <td>0.124</td>\n      <td>0.102</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cascVI</td>\n      <td>0.077</td>\n      <td>0.077</td>\n      <td>0.061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scVI</td>\n      <td>0.081</td>\n      <td>0.081</td>\n      <td>0.065</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "print(\">>> Gene-Gene | Rank Normalization <<<\")\n",
    "df_table5.head(10)"
   ]
  },
  {
   "source": [
    "# 8. Latent Space Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***cascVI***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge internal nodes and leaves\n",
    "#full_cascvi_latent = construct_latent(tree, cascvi_latent, imputed_z)\n",
    "\n",
    "\n",
    "#print(\"CascVI latent space\")\n",
    "#plot_common_ancestor(tree,\n",
    "#                     full_cascvi_latent,\n",
    "#                     embedding='umap',\n",
    "#                     give_labels=False\n",
    "#                             )"
   ]
  },
  {
   "source": [
    "***CascVI + avg***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_cascvi_latent_2 = construct_latent(tree, cascvi_latent, imputed_cascvi_2_z)\n",
    "\n",
    "#print(\"CascVI + averaging latent space\")\n",
    "#plot_common_ancestor(tree,\n",
    "#                     full_cascvi_latent_2,\n",
    "#                     embedding='umap',\n",
    "#                     give_labels=False\n",
    "#                             )"
   ]
  },
  {
   "source": [
    "***scVI***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge internal nodes and leaves\n",
    "#full_scvi_latent = construct_latent(tree, scvi_latent, imputed_scvi_2_z)\n",
    "\n",
    "#print(\"scVI latent space\")\n",
    "#plot_common_ancestor(tree,\n",
    " #                full_scvi_latent,\n",
    " #                embedding='umap',\n",
    " #                give_labels=False\n",
    " #                   )"
   ]
  },
  {
   "source": [
    "### k-NN purity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***LEAVES only***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Leaves Only\")\n",
    "#data = {'groundtruth': leaves_z, 'scVI': scvi_latent,\n",
    "#        'cascVI': cascvi_latent\n",
    "#        }\n",
    "#scores = knn_purity(max_neighbors=50,\n",
    "#                    data=data,\n",
    "#                    plot=True,\n",
    "#                    save_fig='/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/tmp'\n",
    "#                    )"
   ]
  },
  {
   "source": [
    "*** Internal nodes only***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Internal nodes Only\")\n",
    "#internal_z, internal_idx, internal_mu = get_internal(glm.z, glm.mu, tree)\n",
    "#internal_scvi_z, _, _ = get_internal(full_scvi_latent, glm.mu, tree)\n",
    "#internal_cascvi_z, _, _ = get_internal(full_cascvi_latent, glm.mu, tree)\n",
    "#internal_cascvi_z_2, _, _ = get_internal(full_cascvi_latent_2, glm.mu, tree)\n",
    "\n",
    "#data = {'groundtruth': internal_z, 'scVI + avg': internal_scvi_z,\n",
    "#        'cascVI': internal_cascvi_z, 'cascVI + avg': internal_cascvi_z_2\n",
    "#        }\n",
    "\n",
    "#scores = knn_purity(max_neighbors=50,\n",
    "#              data=data,\n",
    "#              plot=True,\n",
    "#              save_fig='/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/tmp/'\n",
    "#              )"
   ]
  },
  {
   "source": [
    "***Full tree***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Full tree\")\n",
    "#data = {'groundtruth': glm.z, 'scVI + avg': full_scvi_latent,\n",
    "#        'cascVI': full_cascvi_latent, 'cascVI + avg': full_cascvi_latent_2\n",
    "#        }\n",
    "#scores = knn_purity(max_neighbors=50,\n",
    "#              data=data,\n",
    "#              plot=True)"
   ]
  },
  {
   "source": [
    "***Stratified k-NN purity***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = {'groundtruth': glm.z, 'scVI + avg': full_scvi_latent,\n",
    "#        'cascVI': full_cascvi_latent, 'cascVI + avg': full_cascvi_latent_2\n",
    "#        }\n",
    "\n",
    "#for k in [2, 5, 10, 20, 35, 50]:\n",
    "#    print(\"For {} neighbors\".format(k))\n",
    "#    if k == 10:\n",
    "#        min_depth = 3\n",
    "#    elif k == 20:\n",
    "#        min_depth = 4\n",
    "#    elif k == 35:\n",
    "#        min_depth = 6\n",
    "#    elif k == 50:\n",
    "#        min_depth = 7\n",
    "#    else:\n",
    "#        min_depth = 2\n",
    "#    scores = knn_purity_stratified(n_neighbors=k,\n",
    "#                                   tree=tree,\n",
    "#                                   data=data,\n",
    "#                                   min_depth=min_depth,\n",
    "#                                   plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd08038a79804d646dd36b3762b0d60c87c86d89e40c61f6758cc1d2f18aca59864",
   "display_name": "Python 3.7  ('scvi-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "8038a79804d646dd36b3762b0d60c87c86d89e40c61f6758cc1d2f18aca59864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}