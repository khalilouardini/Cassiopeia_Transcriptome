{
 "cells": [
  {
   "source": [
    "# 0. Standard imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('WebAgg')\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import ete3 Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2247 nodes in the tree\n663 leaves in the tree\n"
     ]
    }
   ],
   "source": [
    "from ete3 import Tree\n",
    "\n",
    "tree_name = \"/data/yosef2/users/mattjones/projects/metastasis/JQ19/5k/trees/lg7/lg7_tree_hybrid_priors.alleleThresh.processed.txt\"\n",
    "tree = Tree(tree_name, 1)\n",
    "\n",
    "N = len([n for n in tree.traverse()])\n",
    "\n",
    "leaves = [n.name for n in tree.traverse('levelorder') if n.is_leaf()]\n",
    "\n",
    "print('{} nodes in the tree'.format(N))\n",
    "print('{} leaves in the tree'.format(len(leaves)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    |  |     |  |\n           |  |     |  |   /- /- /- /- /-M1.ACTGATGAGGTCGGAT-1\n           |  |     |  |  |\n           |  |     |  |--|   /- /- /-M1.GATCAGTTCTGTTGAG-1\n           |  |     |  |  |  |\n           |  |     |  |   \\-|-- /-RE.TCACAAGTCCCAACGG-1\n           |  |     |  |     |\n           |  |     |  |      \\- /-M2.CCCAATCCAGGTTTCA-1\n           |  |     |  |\n           |  |     |  |   /- /- /- /-M1.GACGTGCTCACCGGGT-1\n           |  |     |  |--|\n           |  |     |  |  |   /- /-M1.TTGCCGTGTTCGTGAT-1\n           |  |     |  |   \\-|\n           |  |     |  |      \\- /- /-RE.TCAATCTAGGGTTTCT-1\n           |  |     |  |\n           |  |     |  |-- /- /- /- /-LL.GATGAGGAGAGCAATT-1\n           |  |     |  |\n           |  |     |  |-- /- /- /-M2.GCATGCGGTCTCATCC-1\n           |  |     |  |\n           |  |     |  |   /- /- /- /-M2.TACTTGTTCCACTCCA-1\n           |  |     |  |--|\n           |  |     |  |  |         /- /- /-M1.CATTCGCAGCCTTGAT-1\n           |  |     |  |   \\- /- /-|\n           |  |     |  |            \\- /- /- /-M1.GAGCAGACAAACTGTC-1\n           |  |     |  |\n           |  |     |  |   /- /- /-LL.TTCTCCTTCCTTTCGG-1\n           |  |     |  |  |\n           |  |     |  |  |      /- /-M1.TAGCCGGAGGGCTCTC-1\n           |  |     |  |  |-- /-|\n           |  |     |  |  |      \\-M1.TATTACCTCAGTTGAC-1\n           |  |     |  |--|\n           |  |     |  |  |-- /- /- /-RE.AGGGAGTGTTCGGCAC-1\n           |  |     |  |  |\n           |  |     |  |  |-- /- /- /-RE.CAACCTCGTAAGGATT-1\n           |  |     |  |  |\n           |  |     |  |   \\- /- /- /-M2.GTGTGCGTCAGCACAT-1\n           |  |     |  |\n           |  |     |  |   /- /- /- /- /-M1.CCTTTCTCAGGGCATA-1\n           |  |     |  |--|\n           |  |     |  |   \\- /- /- /- /-M1.CAAGATCGTCGACTGC-1\n           |  |     |  |\n           |  |     |  |         /- /- /-RE.GTATTCTTCGGATGGA-1\n           |  |     |  |-- /- /-|\n           |  |     |  |         \\- /- /-M2.CCCATACTCAGCCTAA-1\n           |  |     |  |\n           |  |     |  |      /- /- /-LL.GCTGCAGAGAGTCGGT-1\n           |  |     |  |   /-|\n           |  |     |   \\-|   \\-LL.GAGTCCGGTCGACTGC-1\n           |  |     |     |\n           |  |     |      \\- /- /- /- /- /-LL.CTCTAATCAGCGATCC-1\n           |  |     |\n           |  |     |   /- /- /-RE.ATTTCTGGTTGAACTC-1\n           |  |     |--|\n           |  |     |   \\- /-RE.TTGGCAAAGGCTCTTA-1\n           |  |     |\n           |  |     |   /- /-RW.AAATGCCCACTGTGTA-1\n           |  |     |--|\n           |  |     |   \\- /-RW.TAGACCAAGTTCGCGC-1\n           |  |     |\n           |  |     |      /- /-RE.AGCGTCGAGCCCGAAA-1\n           |  |     |   /-|\n           |  |     |--|   \\- /-RE.ACCGTAAAGTCATGCT-1\n           |  |     |  |\n           |  |     |   \\- /- /-RE.CCTAGCTAGGATGGAA-1\n            \\-|     |\n              |     |         /- /- /-M1.CGGACGTAGATATACG-1\n              |     |      /-|\n              |     |     |   \\- /-M1.TCGTAGAAGACTAGAT-1\n              |     |-- /-|\n              |     |     |   /- /- /-RE.CGCCAAGAGTGGTCCC-1\n              |     |      \\-|\n              |     |         \\- /-RE.TCATTTGGTATGAAAC-1\n              |     |\n              |     |   /- /- /-M1.TGAGGGAAGCTGAAAT-1\n              |     |  |\n              |     |  |   /- /-M1.AAGACCTCAAGTAGTA-1\n              |     |  |  |\n              |     |  |--|-- /-M1.ATAGACCCAGCCTTGG-1\n              |     |  |  |\n              |     |--|   \\- /-M1.ATAAGAGCATGTCTCC-1\n              |     |  |\n              |     |  |      /- /-RW.CCAATCCAGCGATTCT-1\n              |     |  |     |\n              |     |  |     |-- /- /-RW.GTGAAGGTCTATCGCC-1\n              |     |  |   /-|\n              |     |  |  |  |-- /-RW.CCTCTGATCCTAGAAC-1\n              |     |   \\-|  |\n              |     |     |   \\-RW.CATGGCGAGGTGACCA-1\n              |     |     |\n              |     |      \\- /- /-M1.GCTGCTTCACTGTTAG-1\n              |     |\n              |     |      /- /- /- /-M2.GCTCCTAGTTATTCTC-1\n              |     |-- /-|\n              |     |     |   /- /- /-LL.GAGGTGAAGAACTGTA-1\n              |     |      \\-|\n              |     |        |   /- /-M2.GTAGGCCTCAGCCTAA-1\n              |     |         \\-|\n              |     |            \\-M2.CTCACACGTCAATGTC-1\n              |     |\n              |     |         /- /-RE.CCACGGATCGTAGGAG-1\n              |     |      /-|\n              |   /-|     |   \\-RE.TCACGAAGTAAACGCG-1\n              |  |  |-- /-|\n              |  |  |     |   /- /- /-RE.AGCGGTCAGTTCGATC-1\n              |  |  |      \\-|\n              |  |  |         \\- /-RE.AGGGAGTAGAAAGTGG-1\n              |  |  |\n              |  |  |   /- /- /-LL.CACATAGAGTACGACG-1\n              |  |  |  |\n              |  |  |  |-- /-M1.GGCAATTTCTTGCAAG-1\n              |  |  |  |\n              |  |  |--|   /- /- /-M1.CGTTCTGAGACTGTAA-1\n              |  |  |  |--|\n              |  |  |  |   \\-M1.CATTCGCGTCTTGCGG-1\n              |  |  |  |\n              |  |  |  |   /- /-M1.GGGCATCCAATGGAAT-1\n              |  |  |   \\-|\n              |  |  |      \\-RW.ATGAGGGTCAGTTAGC-1\n              |  |  |\n              |  |  |   /- /- /-RE.AGATCTGCACCGAAAG-1\n              |  |  |  |\n              |  |  |  |   /- /-RE.TTAGTTCTCGGATGTT-1\n              |  |  |  |--|\n              |  |  |  |   \\- /-RE.TGCTACCTCCCTCTTT-1\n              |  |  |  |\n              |  |  |  |      /- /- /-RE.GCAGCCACACGGACAA-1\n              |  |  |  |   /-|\n              |  |  |  |  |  |   /- /-M1.AGAGTGGCACTAAGTC-1\n              |  |  |  |--|   \\-|\n              |  |  |--|  |      \\- /-M1.AGTGGGAGTTGTTTGG-1\n              |  |  |  |  |\n              |  |  |  |   \\- /-RE.TCAGATGAGCTCCTTC-1\n              |  |  |  |\n              |  |  |  |   /- /- /-RE.TACTCATAGGCTAGCA-1\n              |  |  |  |--|\n              |  |  |  |   \\- /-M2.TACACGATCCACGTGG-1\n              |  |  |  |\n              |  |  |  |   /- /- /-M1.CGTTCTGCACTACAGT-1\n              |  |  |  |  |\n              |  |  |   \\-|-- /- /- /-M1.CACCTTGGTGGTACAG-1\n              |  |  |     |\n              |  |  |      \\- /- /- /-RE.CCATTCGCAGTGAGTG-1\n              |  |  |\n              |  |  |         /- /- /- /-RE.TTGCGTCCAGCTGTAT-1\n              |  |  |      /-|\n              |  |  |     |   \\- /- /-M1.GTACTCCCATTAGCCA-1\n              |  |  |     |\n              |  |  |     |      /- /- /-LL.GTCATTTTCTCTTATG-1\n              |  |  |     |-- /-|\n              |  |  |     |      \\- /- /-M2.TCACAAGGTGAGTGAC-1\n              |  |  |     |\n              |  |  |   /-|-- /- /-RE.GCAGTTATCGTCCGTT-1\n              |  |  |  |  |\n              |  |  |  |  |         /- /-RE.CTCCTAGAGTATGACA-1\n              |  |  |  |  |-- /- /-|\n              |  |  |  |  |         \\- /- /-M1.AGTAGTCCAGAGTGTG-1\n              |  |  |  |  |\n              |  |  |  |  |-- /- /- /- /- /- /-M1.CTGTTTAGTCACTGGC-1\n              |  |  |  |  |\n              |  |  |  |   \\- /-RE.CCTACACGTGAGTGAC-1\n              |  |  |  |\n              |  |  |  |      /- /-RE.CGAGCCACAGATGGGT-1\n              |  |  |  |     |\n              |  |  |  |     |-- /- /- /-RE.TTATGCTCAATAGAGT-1\n              |  |  |  |     |\n              |  |  |  |     |-- /- /- /-RE.AAACGGGAGAAGGTGA-1\n              |  |  |  |     |\n              |  |  |  |     |   /- /- /- /-M1.GGACGTCCATAAAGGT-1\n              |  |  |  |     |--|\n              |  |  |  |     |   \\- /- /- /- /-M1.CCTCTGAAGACAGAGA-1\n              |  |  |  |     |\n              |  |  |  |     |      /- /- /-M2.ACCAGTACAGACAGGT-1\n              |  |  |  |     |     |\n              |  |  |  |     |     |   /- /- /-M2.GGACAAGTCGTTTATC-1\n              |  |  |  |     |   /-|--|\n              |  |  |  |     |  |  |   \\- /-M2.ACGAGGACATCGGTTA-1\n              |  |  |  |     |  |  |\n              |  |  |  |     |  |  |      /- /- /-M2.TGCGGGTCAAGTTGTC-1\n              |  |  |  |   /-|--|   \\- /-|\n              |  |  |  |  |  |  |         \\- /-M2.GCATGTACATTCTCAT-1\n              |  |  |  |  |  |  |\n              |  |  |  |  |  |  |   /- /- /- /-M2.TCTCATATCTTGTACT-1\n              |  |  |--|  |  |   \\-|\n              |  |  |  |  |  |      \\- /- /- /- /-M1.TCAGCTCTCAACACAC-1\n              |  |  |  |  |  |\n              |  |  |  |  |  |   /- /- /-RE.TACACGATCTCCTATA-1\n              |  |  |  |  |  |--|\n              |  |  |  |  |  |   \\- /- /- /-M1.GCGCCAACAGGTTTCA-1\n              |  |  |  |  |  |\n              |  |  |  |  |  |         /- /- /-M1.TTCGGTCGTACGACCC-1\n              |  |  |  |  |  |-- /- /-|\n              |  |  |  |  |  |         \\- /- /-M1.CCCAATCGTCGCATAT-1\n              |  |  |  |  |  |\n              |  |  |  |  |  |-- /-RE.CGCCAAGGTAGCGTAG-1\n              |  |  |  |  |  |\n              |  |  |  |  |   \\-RE.GCATACATCGGCCGAT-1\n              |  |  |  |  |\n              |  |  |  |  |         /- /- /-RE.TTTGTCAGTTCGAATC-1\n              |  |  |  |  |        |\n              |  |  |  |  |        |   /- /- /-M2.TGAGCATTCTGATACG-1\n              |  |  |  |  |      /-|--|\n              |  |  |  |  |     |  |   \\- /- /-M1.ACCTTTATCTGATTCT-1\n              |  |  |  |  |     |  |\n              |  |  |  |  |     |   \\- /-RE.CACTCCATCTCAAACG-1\n              |  |  |  |  |     |\n              |  |  |  |  |     |-- /- /-RE.CAAGTTGCATTAGGCT-1\n              |  |  |  |  |     |\n              |  |  |  |  |     |-- /- /-RE.CAACCTCCATTAACCG-1\n              |  |  |  |  |     |\n              |  |  |  |  |     |-- /-RE.TGCACCTTCTTCGAGA-1\n              |  |  |  |  |     |\n              |  |  |  |  |     |   /- /- /- /- /-RE.ACTATCTAGGGATACC-1\n              |  |  |  |  |     |--|\n              |  |  |   \\-|     |  |   /- /-RE.TGGGCGTAGCGCCTCA-1\n              |  |  |     |     |   \\-|\n              |  |  |     |     |      \\- /- /-Liv.ACGATACAGATGTTAG-1\n              |  |  |     |     |\n              |  |  |     |     |      /- /-RE.TGGCGCAGTTCATGGT-1\n              |  |  |     |     |-- /-|\n              |  |  |     |     |      \\-RE.CTTACCGTCTTAGAGC-1\n              |  |  |     |     |\n              |  |  |     |     |-- /- /- /-RE.GGGAATGAGACTTTCG-1\n              |  |  |     |   /-|\n              |  |  |     |  |  |   /- /- /-RE.ACGAGCCAGAGTGACC-1\n              |  |  |     |  |  |  |\n              |  |  |     |  |  |  |         /- /-RE.TACGGATAGCCACCTG-1\n              |  |  |     |  |  |  |      /-|\n              |  |  |     |  |  |  |-- /-|   \\- /-RE.CAGTAACCATGGGAAC-1\n              |  |  |     |  |  |  |     |\n              |  |  |     |  |  |--|      \\-RE.CATTCGCCAATGGTCT-1\n              |  |  |     |  |  |  |\n              |  |  |     |  |  |  |-- /- /- /-M1.CACAGTAGTTAAGGGC-1\n              |  |  |     |  |  |  |\n              |  |  |     |  |  |  |   /- /- /- /-RE.GAGGTGAGTCGAGTTT-1\n              |  |  |     |--|  |  |  |\n              |  |  |     |  |  |   \\-|      /- /- /- /-RE.CTACGTCTCTTCGAGA-1\n              |  |  |     |  |  |     |     |\n              |  |  |     |  |  |      \\- /-|-- /- /- /-M2.CGTCAGGCAAAGTGCG-1\n              |  |  |     |  |  |           |\n              |  |  |     |  |  |            \\- /- /-RE.CCGGTAGCACGAGAGT-1\n              |  |  |     |  |  |\n              |  |  |     |  |  |   /- /- /- /-RE.GATCAGTAGACTAGAT-1\n              |  |  |     |  |  |--|\n              |  |  |     |  |  |   \\- /- /- /- /-RE.TAAGTGCCAGGCTGAA-1\n              |  |  |     |  |  |\n               \\-|  |     |  |   \\-RE.TACCTTACACAGACAG-1\n                 |  |     |  |\n                 |  |     |   \\- /- /- /- /- /-RE.AGCGGTCAGTACATGA-1\n                 |  |     |\n                 |  |      \\- /- /- /- /- /-M1.TTCTCCTGTAAGCACG-1\n                 |  |\n                 |  |   /- /- /- /- /-M1.AAACGGGCAGTGGGAT-1\n                 |  |  |\n                 |  |  |         /- /- /-RE.CGAACATAGACCTTTG-1\n                 |  |  |   /- /-|\n                 |  |  |  |     |   /- /- /-RE.TCGCGAGTCATAAAGG-1\n                 |  |  |  |      \\-|\n                 |  |  |  |         \\- /- /-RE.ACGAGGATCGCTTAGA-1\n                 |  |  |--|\n                 |  |  |  |-- /- /- /- /-M1.GCACATAGTCGACTAT-1\n                 |  |  |  |\n                 |  |--|  |      /- /- /- /-RE.AACACGTAGCTCCTTC-1\n                 |  |  |   \\- /-|\n                 |  |  |        |   /- /- /-RE.TGTATTCAGCGTAATA-1\n                 |  |  |         \\-|\n                 |  |  |            \\- /- /-RE.CATGGCGGTTCTGGTA-1\n                 |  |  |\n                 |  |  |         /- /- /-RE.TGCGTGGCAGCATACT-1\n                 |  |  |-- /- /-|\n                 |  |  |         \\- /-RE.ATAAGAGGTTGTCTTT-1\n                 |  |  |\n                 |  |  |      /- /- /-RE.CATTATCGTATCGCAT-1\n                 |  |   \\- /-|\n                 |  |         \\- /- /-M1.CTGTGCTCATTCGACA-1\n                 |  |\n                 |  |-- /- /- /-RE.GCTCTGTTCACCACCT-1\n                 |  |\n                 |  |      /- /- /-RE.AGTGTCAAGACACGAC-1\n                 |  |   /-|\n                 |  |  |   \\- /-RE.GGCGACTAGGCTACGA-1\n                 |  |--|\n                 |  |  |   /- /- /-RE.GTACGTAGTTGGACCC-1\n                 |  |   \\-|\n                 |  |      \\- /- /-RE.GCATGATTCACCGTAA-1\n                 |  |\n                 |  |   /- /- /-RE.CTCGGAGAGAAACCTA-1\n                 |  |--|\n                 |  |  |   /- /- /-LL.TAGTGGTAGCGAGAAA-1\n                 |  |   \\-|\n                 |  |     |   /- /- /-RE.GTCAAGTAGTGCCATT-1\n                 |  |      \\-|\n                 |  |         \\- /-RE.TGATTTCAGCTAACAA-1\n                 |  |\n                 |   \\- /- /- /- /-RE.TTCTCAATCTCTAGGA-1\n                 |\n                 |   /- /- /- /-RE.GAGGTGAGTTGCCTCT-1\n                 |  |\n                 |  |   /- /- /-RE.CTGCGGAAGTGACATA-1\n                 |  |  |\n                 |  |  |-- /-RE.CTGATAGAGACTTGAA-1\n                 |  |  |\n                 |  |  |      /-RE.TGGCTGGGTCTAACGT-1\n                 |  |  |   /-|\n                 |  |--|--|   \\-RE.TGCACCTAGTGTACCT-1\n                 |--|  |  |\n                 |  |  |   \\-RE.AAGGTTCCAATTGCTG-1\n                 |  |  |\n                 |  |  |      /- /- /-RE.CGTCAGGGTCATGCCG-1\n                 |  |  |     |\n                 |  |   \\- /-|-- /-RE.CTGAAACGTAAGTGGC-1\n                 |  |        |\n                 |  |         \\- /-RE.AAGACCTGTCGCGTGT-1\n                 |  |\n                 |   \\- /- /- /-RE.CAACCAATCATGGTCA-1\n                 |\n                 |      /- /- /-LL.GTTACAGGTAAACGCG-1\n                 |     |\n                 |   /-|-- /-M1.AGAGCTTTCATGTAGC-1\n                 |  |  |\n                 |  |  |      /- /- /-M1.AGGTCCGTCACATAGC-1\n                 |  |   \\- /-|\n                 |  |        |   /- /-M1.CATGGCGCACTGTTAG-1\n                 |  |         \\-|\n                 |  |            \\- /-M1.ATGAGGGAGTGGTAAT-1\n                 |  |\n                 |  |            /- /- /-RE.ACCTTTAAGCTAGGCA-1\n                 |  |         /-|\n                 |  |        |   \\-RE.ATTGGTGGTTGTACAC-1\n                 |  |      /-|\n                 |  |     |  |   /- /- /-M1.CCACGGAAGCACAGGT-1\n                 |  |     |   \\-|\n                 |  |     |      \\- /- /-RE.GGCTCGACATGTTCCC-1\n                 |  |   /-|\n                 |  |  |  |      /- /- /-RW.ACGATACTCCGCGCAA-1\n                 |  |  |  |   /-|\n                 |  |  |  |  |   \\-RE.CATTCGCCAAGCCCAC-1\n                 |  |  |  |  |\n                 |  |  |   \\-|-- /- /-RE.TCATTTGTCCGATATG-1\n                 |--|  |     |\n                 |  |  |     |   /- /- /-RE.TTAACTCTCATTGCCC-1\n                 |  |  |      \\-|\n                 |  |  |        |      /- /- /-RE.CAGTCCTGTCCGACGT-1\n                 |  |  |         \\- /-|\n                 |  |--|               \\- /-RE.GCGCGATAGGACGAAA-1\n                 |  |  |\n                 |  |  |      /- /- /-RE.GTGCGGTGTCGGCACT-1\n                 |  |  |-- /-|\n                 |  |  |      \\- /- /- /-RE.CTACACCTCTGTACGA-1\n                 |  |  |\n                 |  |  |      /- /- /-RE.CAGCGACTCAACGAAA-1\n                 |  |  |     |\n                 |  |  |   /-|      /- /-RE.GAATAAGAGATTACCC-1\n                 |  |  |  |  |   /-|\n                 |  |  |  |   \\-|   \\- /-RE.ACGGGCTTCCAGATCA-1\n                 |  |   \\-|     |\n                 |  |     |      \\- /-RE.TATCTCATCTTGTACT-1\n                 |  |     |\n                 |  |      \\- /- /- /- /-RE.GGAACTTAGCTCCTTC-1\n                 |  |\n                 |  |               /- /-M2.CATCGAATCATATCGG-1\n                 |   \\- /- /- /- /-|\n                 |                  \\-M2.GCTTCCACAGCTGCTG-1\n                 |\n                 |   /- /- /- /- /-RE.ATTGGTGCATTTGCTT-1\n                 |  |\n                 |  |      /- /- /-RE.CTCCTAGCAATCACAC-1\n                 |  |   /-|\n                 |  |  |   \\-RE.GTGGGTCAGCTGCAAG-1\n                 |  |  |\n                 |  |  |-- /- /-RE.CCAGCGAAGAAACGAG-1\n                 |  |  |\n                 |  |  |      /- /-RE.GAAACTCAGTAATCCC-1\n                 |  |  |     |\n                 |  |  |   /-|-- /-RE.TATCAGGAGAGTAATC-1\n                 |  |  |  |  |\n                 |  |  |  |  |      /- /- /-RE.TGAGCCGCATGGTTGT-1\n                 |  |  |--|   \\- /-|\n                 |  |--|  |         \\- /-RE.TATTACCCAAACCTAC-1\n                 |  |  |  |\n                 |  |  |  |   /- /-RE.GACCAATGTCCTCTTG-1\n                 |  |  |   \\-|\n                 |  |  |      \\- /- /-RE.TACCTATTCAATCACG-1\n                 |  |  |\n                 |  |  |   /- /- /-RE.GCTCCTACACTACAGT-1\n                 |  |  |--|\n                 |  |  |  |   /- /- /-RE.ACGAGCCAGTGAACGC-1\n                 |  |  |   \\-|\n                 |  |  |      \\- /-RE.TTCTACAGTACCTACA-1\n                 |  |  |\n                 |  |   \\- /- /-RE.GGGAATGTCAACACGT-1\n                  \\-|\n                    |      /- /- /-RE.ACGCCAGAGCTTATCG-1\n                    |     |\n                    |     |      /- /-RE.CCTAGCTCAAGAAAGG-1\n                    |     |     |\n                    |     |     |      /- /-RE.AGCTTGATCCCTTGTG-1\n                    |     |     |   /-|\n                    |     |   /-|--|   \\-RE.CATGACATCTCAACTT-1\n                    |   /-|  |  |  |\n                    |  |  |  |  |   \\-RE.GTGCATAAGAGTAATC-1\n                    |  |  |--|  |\n                    |  |  |  |   \\-RE.CACATTTAGACTTGAA-1\n                    |  |  |  |\n                    |  |  |   \\- /- /- /-RE.ACGTCAAAGTCCAGGA-1\n                    |  |  |\n                    |  |   \\- /- /- /- /-RE.CGTCTACAGAAACCAT-1\n                    |  |\n                    |  |         /- /- /-RE.ATGTGTGGTGTTCTTT-1\n                    |  |        |\n                    |  |        |   /- /- /-RE.TGGACGCCAGCGTCCA-1\n                    |  |        |--|\n                    |  |   /- /-|   \\- /-RE.AGCATACGTAAGTGGC-1\n                    |  |  |     |\n                    |  |  |     |-- /-RE.TTCCCAGAGGCATGGT-1\n                    |  |  |     |\n                    |  |  |      \\- /-RE.TGCCCATTCCACTCCA-1\n                    |  |  |\n                    |  |--|   /- /-RE.CCCATACCATGACATC-1\n                     \\-|  |  |\n                       |  |  |   /- /- /-RE.CACATAGTCCAAATGC-1\n                       |  |  |  |\n                       |  |  |  |-- /- /- /-RE.AGTTGGTAGAGGACGG-1\n                       |  |  |--|\n                       |   \\-|  |-- /- /- /-RE.CGAACATGTAGCTCCG-1\n                       |     |  |\n                       |     |  |   /- /-RE.CAGTAACTCCCATTAT-1\n                       |     |   \\-|\n                       |     |      \\- /-RE.GGGCACTAGATGAGAG-1\n                       |     |\n                       |     |   /- /- /-RE.TCACGAACACCGAAAG-1\n                       |      \\-|\n                       |         \\- /- /-RE.GTCACAACACATCTTT-1\n                       |\n                       |   /- /- /-RE.CAGCCGAAGTTGTAGA-1\n                       |--|\n                       |   \\- /- /- /-RE.TGGCCAGAGTGACATA-1\n                       |\n                       |      /- /- /-RE.CGGACACAGTCAATAG-1\n                       |     |\n                        \\- /-|-- /-RE.ACCCACTGTGGTAACG-1\n                             |\n                              \\- /- /-RE.CAACCTCCAAGTAATG-1\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  },
  {
   "source": [
    "### Gene expression data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                Barcodes\n",
       "0  LL.AAACCTGCAAGAAAGG-1\n",
       "1  LL.AAACCTGCATGAAGTA-1\n",
       "2  LL.AAACCTGGTACATGTC-1\n",
       "3  LL.AAACCTGTCAAGGTAA-1\n",
       "4  LL.AAACGGGGTCTTGATG-1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Barcodes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LL.AAACCTGCAAGAAAGG-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LL.AAACCTGCATGAAGTA-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LL.AAACCTGGTACATGTC-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LL.AAACCTGTCAAGGTAA-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LL.AAACGGGGTCTTGATG-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "barcodes = pd.read_csv(\"/data/yosef2/users/mattjones/projects/metastasis/JQ19/5k/RNA/ALL_Samples/GRCh38/barcodes.tsv\", names=['Barcodes'])\n",
    "\n",
    "barcodes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                id          Gene\n",
       "0  ENSG00000243485  RP11-34P13.3\n",
       "1  ENSG00000237613       FAM138A\n",
       "2  ENSG00000186092         OR4F5\n",
       "3  ENSG00000238009  RP11-34P13.7\n",
       "4  ENSG00000239945  RP11-34P13.8"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Gene</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ENSG00000243485</td>\n      <td>RP11-34P13.3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ENSG00000237613</td>\n      <td>FAM138A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ENSG00000186092</td>\n      <td>OR4F5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ENSG00000238009</td>\n      <td>RP11-34P13.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ENSG00000239945</td>\n      <td>RP11-34P13.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "genes = pd.read_csv(\"/data/yosef2/users/mattjones/projects/metastasis/JQ19/5k/RNA/ALL_Samples/GRCh38/genes.tsv\", sep='\\t', names=['id', 'Gene'])\n",
    "\n",
    "genes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Gene         C          Z           Pval            FDR\n",
       "0     TFF3  0.174633  42.425806   0.000000e+00   0.000000e+00\n",
       "1     TFF1  0.227374  41.599879   0.000000e+00   0.000000e+00\n",
       "2   MUC5AC  0.157811  37.940520   0.000000e+00   0.000000e+00\n",
       "3  CEACAM6  0.245428  32.255498  1.472918e-228  2.218583e-225\n",
       "4    MUC5B  0.084600  24.601674  6.060690e-134  7.303131e-131"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gene</th>\n      <th>C</th>\n      <th>Z</th>\n      <th>Pval</th>\n      <th>FDR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TFF3</td>\n      <td>0.174633</td>\n      <td>42.425806</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TFF1</td>\n      <td>0.227374</td>\n      <td>41.599879</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MUC5AC</td>\n      <td>0.157811</td>\n      <td>37.940520</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CEACAM6</td>\n      <td>0.245428</td>\n      <td>32.255498</td>\n      <td>1.472918e-228</td>\n      <td>2.218583e-225</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MUC5B</td>\n      <td>0.084600</td>\n      <td>24.601674</td>\n      <td>6.060690e-134</td>\n      <td>7.303131e-131</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "hotspot_genes = pd.read_csv(\"/data/yosef2/users/mattjones/projects/metastasis/hotspot_gene_sets/lg7_hotspot_genes.tsv\", sep='\\t')\n",
    "hotspot_genes.head(5)"
   ]
  },
  {
   "source": [
    "Gene expression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<33694x43423 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 90063434 stored elements in COOrdinate format>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from scipy.io import mmread\n",
    "\n",
    "X = mmread('/data/yosef2/users/mattjones/projects/metastasis/JQ19/5k/RNA/ALL_Samples/GRCh38/matrix.mtx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = barcodes['Barcodes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "43423"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "len(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "\"M2.TAGCCGGAGGGCTTCC-1\" in L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RE.TAAGCGTTCTAACTCT-1\n",
      "RE.CGGACACAGGAGCGTT-1\n",
      "RE.TGGTTCCCACCGAATT-1\n",
      "RE.GATCGATAGGGATGGG-1\n",
      "RE.CGTTGGGAGCACGCCT-1\n",
      "RE.GCATGCGCAGGAATCG-1\n",
      "RE.CTGTTTACACCCATGG-1\n",
      "RE.GCACATAGTACGCTGC-1\n",
      "RE.CGTAGGCCACGAGAGT-1\n",
      "RE.GTGCAGCAGGTTCCTA-1\n",
      "RE.CGTGTAATCGAATGCT-1\n",
      "RE.CCTCTGATCTGCGACG-1\n",
      "RE.CGTAGGCCAACACCCG-1\n",
      "RE.CGTGTAAAGATAGCAT-1\n",
      "RE.GTAGGCCAGCGTCAAG-1\n",
      "RE.CAGTAACTCCTGTAGA-1\n",
      "RE.CGATGTACACAGAGGT-1\n",
      "RE.ATCTACTCAGTCGTGC-1\n",
      "RE.GCTTCCATCCCACTTG-1\n",
      "RE.ATGGGAGAGTCATGCT-1\n",
      "RE.TTCCCAGAGGGTTTCT-1\n",
      "RE.ACTGAGTGTCATGCAT-1\n",
      "RE.AACACGTTCTCGATGA-1\n",
      "RE.CTACACCTCATAAAGG-1\n",
      "RE.CGGACGTAGCGAGAAA-1\n",
      "RE.CTTACCGTCCAAACTG-1\n",
      "RE.TGACTTTAGCACGCCT-1\n",
      "M1.TAGAGCTAGGCTAGCA-1\n",
      "RE.TGAGCCGGTACGAAAT-1\n",
      "RE.CGTAGCGGTCAGTGGA-1\n",
      "RE.GACTGCGGTTACGACT-1\n",
      "RE.GATCGATAGCCCAGCT-1\n",
      "RE.TCAGCTCCACATGTGT-1\n",
      "RE.CTTCTCTGTAGCACGA-1\n",
      "RE.TGACTAGTCCGAATGT-1\n",
      "RE.CTTTGCGAGCGTAATA-1\n",
      "RE.TGAAAGAAGTCTCGGC-1\n",
      "RE.ACTTGTTTCGTCACGG-1\n",
      "RE.GCCTCTATCTTGACGA-1\n",
      "RE.CACAGTAGTATCACCA-1\n",
      "RE.CGCCAAGAGTCCGGTC-1\n",
      "RE.ACGGGCTCAAGTTCTG-1\n",
      "M2.GAACCTATCCAATGGT-1\n",
      "RE.CAGCCGAGTTCGAATC-1\n",
      "RE.CAGCTAAGTCAGAATA-1\n",
      "RE.GTCAAGTTCTGAGGGA-1\n",
      "RE.ACTTACTAGCGGCTTC-1\n",
      "M2.TTGCCGTCAGACAAAT-1\n",
      "RW.CCAATCCAGCGATTCT-1\n",
      "RE.GACCAATGTCCTCTTG-1\n",
      "RE.ACGAGCCAGTGAACGC-1\n",
      "RE.GTTCGGGGTTTAAGCC-1\n",
      "RE.GGGAATGAGACTTTCG-1\n",
      "RE.TCGCGAGTCATAAAGG-1\n",
      "RE.TGGACGCCAGCGTCCA-1\n",
      "M1.GAGCAGACAAACTGTC-1\n",
      "M2.GGACAAGTCGTTTATC-1\n",
      "M1.TTCGGTCGTACGACCC-1\n",
      "M1.CCCAATCGTCGCATAT-1\n",
      "M2.CGTCAGGCAAAGTGCG-1\n"
     ]
    }
   ],
   "source": [
    "leaves_X = []\n",
    "for barcode in leaves:\n",
    "    foo = barcodes.index[barcodes['Barcodes'] == barcode].tolist()\n",
    "    if foo == []:\n",
    "        print(barcode)\n",
    "    #idx = barcodes.index[barcodes['Barcodes'] == barcode].tolist()[0]\n",
    "    x = np.squeeze(np.array(Y[:, idx]))\n",
    "    leaves_X.append(x)\n",
    "#leaves_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n in enumerate(tree.traverse('levelorder')):\n",
    "    n.add_features(index=i)\n",
    "    if not n.is_leaf():\n",
    "        n.name = str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_length = {}\n",
    "for node in tree.traverse('levelorder'):\n",
    "    if node.name == '0':\n",
    "        branch_length[node.name] = 0.0\n",
    "        continue\n",
    "    branch_length[node.name] = 1.0\n",
    "branch_length['prior_root'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for i, n in enumerate(tree.traverse()):\n",
    "#    print(i, n.name)\n",
    "\n",
    "#split_node = tree.search_nodes(name='2|2|2|2|2|0|2|2|2|0|2|2|0|2|0|2|2|2|0|2|2|2|2|0|0|0|0|0|0')[0]\n",
    "#sub_leaves = [n.name for n in split_node.get_leaves()]\n",
    "#tree.prune(sub_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "from anndata import AnnData\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from external.dataset.tree import TreeDataset, GeneExpressionDataset\n",
    "from external.dataset.poisson_glm import Poisson_GLM\n",
    "from external.dataset.anndataset import AnnDatasetFromAnnData\n",
    "\n",
    "# Models\n",
    "from models.vae import VAE\n",
    "import scanpy as sc\n",
    "from external.inference.tree_inference import TreeTrainer\n",
    "from inference.inference import UnsupervisedTrainer\n",
    "from scvi.inference import posterior\n",
    "from external.models.treevae import TreeVAE\n",
    "\n",
    "# Utils\n",
    "from external.utils.data_util import get_leaves, get_internal\n",
    "from external.utils.metrics import ks_pvalue, accuracy_imputation, correlations, knn_purity, knn_purity_stratified\n",
    "from external.utils.plots_util import plot_histograms, plot_scatter_mean, plot_ecdf_ks, plot_density\n",
    "from external.utils.plots_util import plot_losses, plot_elbo, plot_common_ancestor, plot_one_gene, training_dashboard\n",
    "from external.utils.baselines import avg_weighted_baseline, scvi_baseline, scvi_baseline_z, cascvi_baseline_z, avg_baseline_z, construct_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f60784b0430>"
      ]
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "source": [
    "import torch\n",
    "    \n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Simulated latent space***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_common_ancestor(tree,\n",
    "#                     glm.z,\n",
    "#                     embedding='umap',\n",
    "#                     give_labels=False\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fitting CascVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "# anndata + gene and celle filtering\n",
    "adata = AnnData(leaves_X)\n",
    "leaves = [n for n in tree.traverse('levelorder') if n.is_leaf()]\n",
    "adata.obs_names = [n.name for n in leaves]\n",
    "sc.pp.filter_genes(adata, min_counts=3)\n",
    "sc.pp.filter_cells(adata, min_counts=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create a TreeDataset object***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "go\n",
      "[2021-05-10 13:55:18,075] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-10 13:55:18,077] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-10 13:55:18,103] INFO - scvi.dataset.dataset | Merging datasets. Input objects are modified in place.\n",
      "[2021-05-10 13:55:18,104] INFO - scvi.dataset.dataset | Gene names and cell measurement names are assumed to have a non-null intersection between datasets.\n",
      "[2021-05-10 13:55:18,106] INFO - scvi.dataset.dataset | Keeping 1000 genes\n",
      "[2021-05-10 13:55:18,116] INFO - scvi.dataset.dataset | Computing the library size for the new data\n",
      "[2021-05-10 13:55:18,118] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-10 13:55:18,119] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n",
      "[2021-05-10 13:55:18,122] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-10 13:55:18,123] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n"
     ]
    }
   ],
   "source": [
    "# treeVAE\n",
    "import copy\n",
    "\n",
    "tree_bis = copy.deepcopy(tree)\n",
    "scvi_dataset = AnnDatasetFromAnnData(adata, filtering=False)\n",
    "scvi_dataset.initialize_cell_attribute('barcodes', adata.obs_names)\n",
    "cas_dataset = TreeDataset(scvi_dataset, tree=tree_bis, filtering=False)\n",
    "cas_dataset\n",
    "\n",
    "# No batches beacause of the message passing\n",
    "use_cuda = True\n",
    "use_MP = True\n",
    "ldvae = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initialize model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "treevae = TreeVAE(cas_dataset.nb_genes,\n",
    "              tree = cas_dataset.tree,\n",
    "              n_latent=glm.latent,\n",
    "              n_hidden=128,\n",
    "              n_layers=1,\n",
    "              reconstruction_loss='poisson',\n",
    "              prior_t = branch_length,\n",
    "              ldvae = ldvae,\n",
    "              use_MP=use_MP\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (px_decoder): FCLayers(\n",
       "    (fc_layers): Sequential(\n",
       "      (Layer 0): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=128, bias=True)\n",
       "        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): None\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (px_scale_decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=1000, bias=True)\n",
       "    (1): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 236
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "freeze = False\n",
    "if freeze:\n",
    "    new_weight = torch.from_numpy(glm.W).float()\n",
    "    new_bias = torch.from_numpy(glm.beta).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        treevae.decoder.factor_regressor.fc_layers[0][0].weight = torch.nn.Parameter(new_weight)\n",
    "        treevae.decoder.factor_regressor.fc_layers[0][0].bias = torch.nn.Parameter(new_bias)\n",
    "        \n",
    "    for param in treevae.decoder.factor_regressor.fc_layers[0][0].parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "treevae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert(treevae.decoder.factor_regressor.fc_layers[0][0].weight.numpy().all() == glm.W.T.all())\n",
    "#assert(treevae.decoder.factor_regressor.fc_layers[0][0].bias.numpy().all() == glm.beta.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Are we able to generate the gene expression data by decoding the simulated latent space?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance between the Poisson and the NB means is 44813.85865894124\n"
     ]
    }
   ],
   "source": [
    "px_scale, px_rate, raw_px_scale = treevae.decoder(treevae.dispersion,\n",
    "                                        torch.from_numpy(leaves_z).float(),\n",
    "                                        torch.from_numpy(np.array([np.log(10000)])).float()\n",
    "                                       )\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if ldvae:\n",
    "    foo = np.clip(a=np.exp(raw_px_scale.detach().cpu().numpy()),\n",
    "            a_min=0,\n",
    "            a_max=1e8\n",
    "    )\n",
    "    mse = mean_squared_error(mu, foo)\n",
    "else:\n",
    "    mse = mean_squared_error(mu, px_rate.detach().numpy())\n",
    "\n",
    "print(\"the distance between the Poisson and the NB means is {}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hyperparameters***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "lr = 1e-3\n",
    "lambda_ = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***trainer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_leaves:  [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112], [113], [114], [115], [116], [117], [118], [119], [120], [121], [122], [123], [124], [125], [126], [127], [128], [129], [130], [131], [132], [133], [134], [135], [136], [137], [138], [139], [140], [141], [142], [143], [144], [145], [146], [147], [148], [149], [150], [151], [152], [153], [154], [155], [156], [157], [158], [159], [160], [161], [162], [163], [164], [165], [166], [167], [168], [169], [170], [171], [172], [173], [174], [175], [176], [177], [178], [179], [180], [181], [182], [183], [184], [185], [186], [187], [188], [189], [190], [191], [192], [193], [194], [195], [196], [197], [198], [199], [200], [201], [202], [203], [204], [205], [206], [207], [208], [209], [210], [211], [212], [213], [214], [215], [216], [217], [218], [219], [220], [221], [222], [223], [224], [225], [226], [227], [228], [229], [230], [231], [232], [233], [234], [235], [236], [237], [238], [239], [240], [241], [242], [243], [244], [245], [246], [247], [248], [249], [250], [251], [252], [253], [254], [255], [256], [257], [258], [259], [260], [261], [262], [263], [264], [265], [266], [267], [268], [269], [270], [271], [272], [273], [274], [275], [276], [277], [278], [279], [280], [281], [282], [283], [284], [285], [286], [287], [288], [289], [290], [291], [292], [293], [294], [295], [296], [297], [298], [299], [300], [301], [302], [303], [304], [305], [306], [307], [308], [309], [310], [311], [312], [313], [314], [315], [316], [317], [318], [319], [320], [321], [322], [323], [324], [325], [326], [327], [328], [329], [330], [331], [332], [333], [334], [335], [336], [337], [338], [339], [340], [341], [342], [343], [344], [345], [346], [347], [348], [349], [350], [351], [352], [353], [354], [355], [356], [357], [358], [359], [360], [361], [362], [363], [364], [365], [366], [367], [368], [369], [370], [371], [372], [373], [374], [375], [376], [377], [378], [379], [380], [381], [382], [383], [384], [385], [386], [387], [388], [389], [390], [391], [392], [393], [394], [395], [396], [397], [398], [399], [400], [401], [402], [403], [404], [405], [406], [407], [408], [409], [410], [411], [412], [413], [414], [415], [416], [417], [418], [419], [420], [421], [422], [423], [424], [425], [426], [427], [428], [429], [430], [431], [432], [433], [434], [435], [436], [437], [438], [439], [440], [441], [442], [443], [444], [445], [446], [447], [448], [449], [450], [451], [452], [453], [454], [455], [456], [457], [458], [459], [460], [461], [462], [463], [464], [465], [466], [467], [468], [469], [470], [471], [472], [473], [474], [475], [476], [477], [478], [479], [480], [481], [482], [483], [484], [485], [486], [487], [488], [489], [490], [491], [492], [493], [494], [495], [496], [497], [498], [499]]\ntest_leaves:  []\nvalidation leaves:  []\n"
     ]
    }
   ],
   "source": [
    "freq = 100\n",
    "trainer = TreeTrainer(\n",
    "    model = treevae,\n",
    "    gene_dataset = cas_dataset,\n",
    "    lambda_ = lambda_,\n",
    "    train_size=1.0,\n",
    "    test_size=0,\n",
    "    use_cuda=use_cuda,\n",
    "    frequency=freq,\n",
    "    n_epochs_kl_warmup=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Start training***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0688256816\n",
      "training:  85%|████████▌ | 850/1000 [03:07<00:35,  4.24it/s]Encodings MP Likelihood: 1.0250695639118177\n",
      "ELBO Loss: 561.5198904665988\n",
      "training:  85%|████████▌ | 851/1000 [03:07<00:39,  3.78it/s]Encodings MP Likelihood: 0.8278356571127333\n",
      "ELBO Loss: 566.2978840524001\n",
      "training:  85%|████████▌ | 852/1000 [03:07<00:38,  3.86it/s]Encodings MP Likelihood: 1.0835691405472634\n",
      "ELBO Loss: 563.7063535346398\n",
      "training:  85%|████████▌ | 853/1000 [03:08<00:37,  3.94it/s]Encodings MP Likelihood: 1.1772286054600822\n",
      "ELBO Loss: 567.0721246901841\n",
      "training:  85%|████████▌ | 854/1000 [03:08<00:37,  3.93it/s]Encodings MP Likelihood: 1.9331837257358977\n",
      "ELBO Loss: 569.4242327883079\n",
      "training:  86%|████████▌ | 855/1000 [03:08<00:36,  4.00it/s]Encodings MP Likelihood: 1.0168637288368112\n",
      "ELBO Loss: 564.6312752131631\n",
      "training:  86%|████████▌ | 856/1000 [03:08<00:35,  4.07it/s]Encodings MP Likelihood: 1.6080092162429296\n",
      "ELBO Loss: 565.4173610547424\n",
      "training:  86%|████████▌ | 857/1000 [03:09<00:34,  4.11it/s]Encodings MP Likelihood: 1.1437275015850399\n",
      "ELBO Loss: 563.8907853643759\n",
      "training:  86%|████████▌ | 858/1000 [03:09<00:34,  4.13it/s]Encodings MP Likelihood: 0.9145850447754071\n",
      "ELBO Loss: 562.7601290673012\n",
      "training:  86%|████████▌ | 859/1000 [03:09<00:34,  4.14it/s]Encodings MP Likelihood: 0.6198931790823438\n",
      "ELBO Loss: 563.0294968311931\n",
      "training:  86%|████████▌ | 860/1000 [03:09<00:33,  4.14it/s]Encodings MP Likelihood: 1.83051688235874\n",
      "ELBO Loss: 564.8057087478483\n",
      "training:  86%|████████▌ | 861/1000 [03:10<00:33,  4.15it/s]Encodings MP Likelihood: 0.8245617139322745\n",
      "ELBO Loss: 563.9820539502043\n",
      "training:  86%|████████▌ | 862/1000 [03:10<00:33,  4.17it/s]Encodings MP Likelihood: 1.1018289095481857\n",
      "ELBO Loss: 565.3748283762218\n",
      "training:  86%|████████▋ | 863/1000 [03:10<00:32,  4.19it/s]Encodings MP Likelihood: 0.8697633807558033\n",
      "ELBO Loss: 563.4215588157865\n",
      "training:  86%|████████▋ | 864/1000 [03:10<00:33,  4.01it/s]Encodings MP Likelihood: 1.7346985082281141\n",
      "ELBO Loss: 571.7968510629021\n",
      "training:  86%|████████▋ | 865/1000 [03:11<00:35,  3.84it/s]Encodings MP Likelihood: 0.9516870860908659\n",
      "ELBO Loss: 568.3161592321817\n",
      "training:  87%|████████▋ | 866/1000 [03:11<00:35,  3.75it/s]Encodings MP Likelihood: 1.8935532481464021\n",
      "ELBO Loss: 565.7612037739107\n",
      "training:  87%|████████▋ | 867/1000 [03:11<00:36,  3.68it/s]Encodings MP Likelihood: 1.7495184187487336\n",
      "ELBO Loss: 568.3398434667793\n",
      "training:  87%|████████▋ | 868/1000 [03:11<00:36,  3.64it/s]Encodings MP Likelihood: 1.21038084194073\n",
      "ELBO Loss: 564.0557734508496\n",
      "training:  87%|████████▋ | 869/1000 [03:12<00:36,  3.63it/s]Encodings MP Likelihood: 1.4234331698643108\n",
      "ELBO Loss: 563.9978473385264\n",
      "training:  87%|████████▋ | 870/1000 [03:12<00:35,  3.62it/s]Encodings MP Likelihood: 3.8120007838995624\n",
      "ELBO Loss: 565.8961631384129\n",
      "training:  87%|████████▋ | 871/1000 [03:12<00:35,  3.61it/s]Encodings MP Likelihood: 1.8127450958308222\n",
      "ELBO Loss: 564.3072508966027\n",
      "training:  87%|████████▋ | 872/1000 [03:13<00:35,  3.61it/s]Encodings MP Likelihood: 0.6213875243466077\n",
      "ELBO Loss: 563.0597986418851\n",
      "training:  87%|████████▋ | 873/1000 [03:13<00:35,  3.56it/s]Encodings MP Likelihood: 0.6910661349618848\n",
      "ELBO Loss: 562.5761975070175\n",
      "training:  87%|████████▋ | 874/1000 [03:13<00:35,  3.52it/s]Encodings MP Likelihood: 3.019679616121849\n",
      "ELBO Loss: 567.9045568145717\n",
      "training:  88%|████████▊ | 875/1000 [03:13<00:31,  3.91it/s]Encodings MP Likelihood: 0.501085954277472\n",
      "ELBO Loss: 564.5244676517045\n",
      "training:  88%|████████▊ | 876/1000 [03:14<00:32,  3.76it/s]Encodings MP Likelihood: 1.3927762809082433\n",
      "ELBO Loss: 563.6195080784028\n",
      "training:  88%|████████▊ | 877/1000 [03:14<00:33,  3.70it/s]Encodings MP Likelihood: 0.643892859725493\n",
      "ELBO Loss: 564.5484060702274\n",
      "training:  88%|████████▊ | 878/1000 [03:14<00:30,  4.01it/s]Encodings MP Likelihood: 0.6899958171442216\n",
      "ELBO Loss: 564.7347610959454\n",
      "training:  88%|████████▊ | 879/1000 [03:14<00:28,  4.26it/s]Encodings MP Likelihood: 0.34153171409057814\n",
      "ELBO Loss: 560.4463229411305\n",
      "training:  88%|████████▊ | 880/1000 [03:15<00:26,  4.50it/s]Encodings MP Likelihood: 1.300122964566108\n",
      "ELBO Loss: 563.834025969273\n",
      "training:  88%|████████▊ | 881/1000 [03:15<00:25,  4.68it/s]Encodings MP Likelihood: 7.695702058042976\n",
      "ELBO Loss: 569.9621130862286\n",
      "training:  88%|████████▊ | 882/1000 [03:15<00:25,  4.68it/s]Encodings MP Likelihood: 1.1310782957413534\n",
      "ELBO Loss: 563.0931230597909\n",
      "training:  88%|████████▊ | 883/1000 [03:15<00:25,  4.67it/s]Encodings MP Likelihood: 1.863009727598034\n",
      "ELBO Loss: 561.6635838863984\n",
      "training:  88%|████████▊ | 884/1000 [03:15<00:24,  4.69it/s]Encodings MP Likelihood: 1.2745146032635857\n",
      "ELBO Loss: 562.1424215101746\n",
      "training:  88%|████████▊ | 885/1000 [03:16<00:24,  4.69it/s]Encodings MP Likelihood: 0.6381815723699262\n",
      "ELBO Loss: 563.3324294186244\n",
      "training:  89%|████████▊ | 886/1000 [03:16<00:24,  4.68it/s]Encodings MP Likelihood: 1.2138737994048234\n",
      "ELBO Loss: 565.5385265478557\n",
      "training:  89%|████████▊ | 887/1000 [03:16<00:24,  4.66it/s]Encodings MP Likelihood: 1.0602842041941574\n",
      "ELBO Loss: 561.7621726597962\n",
      "training:  89%|████████▉ | 888/1000 [03:16<00:23,  4.67it/s]Encodings MP Likelihood: 3.6728338631739095\n",
      "ELBO Loss: 563.3677428244697\n",
      "training:  89%|████████▉ | 889/1000 [03:16<00:23,  4.68it/s]Encodings MP Likelihood: 4.176132563630685\n",
      "ELBO Loss: 568.1016776536537\n",
      "training:  89%|████████▉ | 890/1000 [03:17<00:38,  2.89it/s]Encodings MP Likelihood: 5.083971312603254\n",
      "ELBO Loss: 571.7168983580799\n",
      "training:  89%|████████▉ | 891/1000 [03:17<00:34,  3.18it/s]Encodings MP Likelihood: 4.554874020378457\n",
      "ELBO Loss: 565.9453180911373\n",
      "training:  89%|████████▉ | 892/1000 [03:18<00:31,  3.46it/s]Encodings MP Likelihood: 1.4596632261050317\n",
      "ELBO Loss: 564.0566747695229\n",
      "training:  89%|████████▉ | 893/1000 [03:18<00:28,  3.74it/s]Encodings MP Likelihood: 0.3611188111820806\n",
      "ELBO Loss: 562.7913198789325\n",
      "training:  89%|████████▉ | 894/1000 [03:18<00:27,  3.91it/s]Encodings MP Likelihood: 0.6739077057057367\n",
      "ELBO Loss: 564.0188023131475\n",
      "training:  90%|████████▉ | 895/1000 [03:18<00:25,  4.19it/s]Encodings MP Likelihood: 1.0664122211807774\n",
      "ELBO Loss: 560.6344476027377\n",
      "training:  90%|████████▉ | 896/1000 [03:18<00:23,  4.39it/s]Encodings MP Likelihood: 1.083634426351485\n",
      "ELBO Loss: 566.7069435798012\n",
      "training:  90%|████████▉ | 897/1000 [03:19<00:22,  4.64it/s]Encodings MP Likelihood: 0.7369269664804549\n",
      "ELBO Loss: 562.8791041988318\n",
      "training:  90%|████████▉ | 898/1000 [03:19<00:21,  4.80it/s]Encodings MP Likelihood: 2.9079247903745515\n",
      "ELBO Loss: 564.3434742826823\n",
      "training:  90%|████████▉ | 899/1000 [03:19<00:20,  4.92it/s]Encodings MP Likelihood: 1.4003645103940583\n",
      "ELBO Loss: 564.3865634079656\n",
      "computing elbo\n",
      "training:  90%|█████████ | 900/1000 [03:19<00:22,  4.43it/s]Encodings MP Likelihood: 0.8119793706957613\n",
      "ELBO Loss: 561.5547468654614\n",
      "training:  90%|█████████ | 901/1000 [03:19<00:21,  4.59it/s]Encodings MP Likelihood: 4.837699124224163\n",
      "ELBO Loss: 566.6205721795126\n",
      "training:  90%|█████████ | 902/1000 [03:20<00:20,  4.73it/s]Encodings MP Likelihood: 1.6632942452940613\n",
      "ELBO Loss: 562.9515855982478\n",
      "training:  90%|█████████ | 903/1000 [03:20<00:20,  4.63it/s]Encodings MP Likelihood: 3.055102651343021\n",
      "ELBO Loss: 567.0386235139064\n",
      "training:  90%|█████████ | 904/1000 [03:20<00:20,  4.74it/s]Encodings MP Likelihood: 1.5816416654676841\n",
      "ELBO Loss: 563.84267573286\n",
      "training:  90%|█████████ | 905/1000 [03:20<00:19,  4.84it/s]Encodings MP Likelihood: 1.8622682042109084\n",
      "ELBO Loss: 564.0773011462039\n",
      "training:  91%|█████████ | 906/1000 [03:20<00:19,  4.93it/s]Encodings MP Likelihood: 0.6981281798596413\n",
      "ELBO Loss: 563.2477781622185\n",
      "training:  91%|█████████ | 907/1000 [03:21<00:18,  4.96it/s]Encodings MP Likelihood: 0.7457252471713659\n",
      "ELBO Loss: 560.3451076459032\n",
      "training:  91%|█████████ | 908/1000 [03:21<00:18,  4.87it/s]Encodings MP Likelihood: 5.033159845960573\n",
      "ELBO Loss: 569.4690804122713\n",
      "training:  91%|█████████ | 909/1000 [03:21<00:18,  4.82it/s]Encodings MP Likelihood: 2.969149503428633\n",
      "ELBO Loss: 563.0373303120274\n",
      "training:  91%|█████████ | 910/1000 [03:21<00:18,  4.92it/s]Encodings MP Likelihood: 3.075158719818843\n",
      "ELBO Loss: 565.9659302995806\n",
      "training:  91%|█████████ | 911/1000 [03:21<00:17,  4.98it/s]Encodings MP Likelihood: 0.6142187921508473\n",
      "ELBO Loss: 564.7638627608133\n",
      "training:  91%|█████████ | 912/1000 [03:22<00:17,  5.02it/s]Encodings MP Likelihood: 1.0013233622247766\n",
      "ELBO Loss: 561.8051080466959\n",
      "training:  91%|█████████▏| 913/1000 [03:22<00:18,  4.68it/s]Encodings MP Likelihood: 2.513579076881241\n",
      "ELBO Loss: 562.057332345945\n",
      "training:  91%|█████████▏| 914/1000 [03:22<00:17,  4.86it/s]Encodings MP Likelihood: 1.4173482851260546\n",
      "ELBO Loss: 566.7189870123129\n",
      "training:  92%|█████████▏| 915/1000 [03:22<00:17,  4.97it/s]Encodings MP Likelihood: 0.48270750190081524\n",
      "ELBO Loss: 559.3500785345525\n",
      "training:  92%|█████████▏| 916/1000 [03:22<00:16,  5.04it/s]Encodings MP Likelihood: 1.7459987841521662\n",
      "ELBO Loss: 562.8176069436628\n",
      "training:  92%|█████████▏| 917/1000 [03:23<00:16,  5.03it/s]Encodings MP Likelihood: 1.302032208679271\n",
      "ELBO Loss: 563.4385504588405\n",
      "training:  92%|█████████▏| 918/1000 [03:23<00:16,  5.05it/s]Encodings MP Likelihood: 1.0202486300662224\n",
      "ELBO Loss: 560.6142423904881\n",
      "training:  92%|█████████▏| 919/1000 [03:23<00:15,  5.07it/s]Encodings MP Likelihood: 1.511069988778993\n",
      "ELBO Loss: 565.1331147466133\n",
      "training:  92%|█████████▏| 920/1000 [03:23<00:15,  5.08it/s]Encodings MP Likelihood: 2.0672256703512026\n",
      "ELBO Loss: 561.0184281582151\n",
      "training:  92%|█████████▏| 921/1000 [03:23<00:15,  4.98it/s]Encodings MP Likelihood: 0.5747965548595054\n",
      "ELBO Loss: 562.3737574214451\n",
      "training:  92%|█████████▏| 922/1000 [03:24<00:15,  5.02it/s]Encodings MP Likelihood: 1.4200514263690658\n",
      "ELBO Loss: 563.1311821922733\n",
      "training:  92%|█████████▏| 923/1000 [03:24<00:15,  5.07it/s]Encodings MP Likelihood: 0.6328827540389119\n",
      "ELBO Loss: 563.5644805965982\n",
      "training:  92%|█████████▏| 924/1000 [03:24<00:14,  5.10it/s]Encodings MP Likelihood: 2.1586918273357623\n",
      "ELBO Loss: 571.5426607596742\n",
      "training:  92%|█████████▎| 925/1000 [03:24<00:14,  5.11it/s]Encodings MP Likelihood: 1.2244136415886855\n",
      "ELBO Loss: 562.3521763102187\n",
      "training:  93%|█████████▎| 926/1000 [03:24<00:14,  5.15it/s]Encodings MP Likelihood: 1.7248268537286153\n",
      "ELBO Loss: 561.5744582020112\n",
      "training:  93%|█████████▎| 927/1000 [03:25<00:14,  5.17it/s]Encodings MP Likelihood: 1.405175494196278\n",
      "ELBO Loss: 559.9183136733767\n",
      "training:  93%|█████████▎| 928/1000 [03:25<00:13,  5.19it/s]Encodings MP Likelihood: 1.6288435003624786\n",
      "ELBO Loss: 567.6012928691997\n",
      "training:  93%|█████████▎| 929/1000 [03:25<00:13,  5.22it/s]Encodings MP Likelihood: 0.7944373756655646\n",
      "ELBO Loss: 559.5422654560336\n",
      "training:  93%|█████████▎| 930/1000 [03:25<00:13,  5.23it/s]Encodings MP Likelihood: 0.46284534220674645\n",
      "ELBO Loss: 562.1983257554726\n",
      "training:  93%|█████████▎| 931/1000 [03:25<00:13,  5.24it/s]Encodings MP Likelihood: 4.521961857840843\n",
      "ELBO Loss: 565.2206254864362\n",
      "training:  93%|█████████▎| 932/1000 [03:26<00:12,  5.24it/s]Encodings MP Likelihood: 1.0657759804494642\n",
      "ELBO Loss: 563.0895014172488\n",
      "training:  93%|█████████▎| 933/1000 [03:26<00:12,  5.18it/s]Encodings MP Likelihood: 1.0015591388072302\n",
      "ELBO Loss: 559.1499545784517\n",
      "training:  93%|█████████▎| 934/1000 [03:26<00:12,  5.15it/s]Encodings MP Likelihood: 2.181389709306132\n",
      "ELBO Loss: 560.9274158739624\n",
      "training:  94%|█████████▎| 935/1000 [03:26<00:12,  5.15it/s]Encodings MP Likelihood: 1.9122815667005466\n",
      "ELBO Loss: 563.5449859252134\n",
      "training:  94%|█████████▎| 936/1000 [03:26<00:12,  5.15it/s]Encodings MP Likelihood: 0.5733196375228373\n",
      "ELBO Loss: 560.2017505824019\n",
      "training:  94%|█████████▎| 937/1000 [03:27<00:12,  5.14it/s]Encodings MP Likelihood: 0.9287540309743182\n",
      "ELBO Loss: 562.2018134781558\n",
      "training:  94%|█████████▍| 938/1000 [03:27<00:12,  5.14it/s]Encodings MP Likelihood: 1.088644365300637\n",
      "ELBO Loss: 566.277182924892\n",
      "training:  94%|█████████▍| 939/1000 [03:27<00:11,  5.11it/s]Encodings MP Likelihood: 1.195500354726253\n",
      "ELBO Loss: 564.2529445948744\n",
      "training:  94%|█████████▍| 940/1000 [03:27<00:12,  4.65it/s]Encodings MP Likelihood: 3.126524491141528\n",
      "ELBO Loss: 564.3877679491653\n",
      "training:  94%|█████████▍| 941/1000 [03:27<00:12,  4.71it/s]Encodings MP Likelihood: 1.118763914728112\n",
      "ELBO Loss: 562.9865654493169\n",
      "training:  94%|█████████▍| 942/1000 [03:28<00:12,  4.79it/s]Encodings MP Likelihood: 0.5520977834259478\n",
      "ELBO Loss: 559.285664016156\n",
      "training:  94%|█████████▍| 943/1000 [03:28<00:11,  4.87it/s]Encodings MP Likelihood: 0.6853430859696863\n",
      "ELBO Loss: 563.1213119786491\n",
      "training:  94%|█████████▍| 944/1000 [03:28<00:11,  4.95it/s]Encodings MP Likelihood: 1.521704498402042\n",
      "ELBO Loss: 567.5511240224752\n",
      "training:  94%|█████████▍| 945/1000 [03:28<00:11,  5.00it/s]Encodings MP Likelihood: 0.8798450799652405\n",
      "ELBO Loss: 562.2828129349119\n",
      "training:  95%|█████████▍| 946/1000 [03:28<00:10,  4.94it/s]Encodings MP Likelihood: 0.8503810597454148\n",
      "ELBO Loss: 561.2510755298842\n",
      "training:  95%|█████████▍| 947/1000 [03:29<00:10,  4.92it/s]Encodings MP Likelihood: 0.6250177852049615\n",
      "ELBO Loss: 561.0045496361521\n",
      "training:  95%|█████████▍| 948/1000 [03:29<00:10,  4.93it/s]Encodings MP Likelihood: 1.0981461921734867\n",
      "ELBO Loss: 562.7764541769461\n",
      "training:  95%|█████████▍| 949/1000 [03:29<00:10,  4.66it/s]Encodings MP Likelihood: 0.7341722118601061\n",
      "ELBO Loss: 561.147506897048\n",
      "training:  95%|█████████▌| 950/1000 [03:29<00:11,  4.47it/s]Encodings MP Likelihood: 7.876912619504035\n",
      "ELBO Loss: 567.0277321977866\n",
      "training:  95%|█████████▌| 951/1000 [03:30<00:11,  4.35it/s]Encodings MP Likelihood: 1.865321370318055\n",
      "ELBO Loss: 564.0020477038353\n",
      "training:  95%|█████████▌| 952/1000 [03:30<00:10,  4.55it/s]Encodings MP Likelihood: 1.7500906022384326\n",
      "ELBO Loss: 562.0160267163436\n",
      "training:  95%|█████████▌| 953/1000 [03:30<00:10,  4.63it/s]Encodings MP Likelihood: 0.7388748742283343\n",
      "ELBO Loss: 564.7276354235156\n",
      "training:  95%|█████████▌| 954/1000 [03:30<00:10,  4.53it/s]Encodings MP Likelihood: 0.7827650663592933\n",
      "ELBO Loss: 560.2681094341351\n",
      "training:  96%|█████████▌| 955/1000 [03:30<00:09,  4.67it/s]Encodings MP Likelihood: 1.4677158877433334\n",
      "ELBO Loss: 561.6094417859562\n",
      "training:  96%|█████████▌| 956/1000 [03:31<00:09,  4.74it/s]Encodings MP Likelihood: 0.6370985919318871\n",
      "ELBO Loss: 563.4755589622937\n",
      "training:  96%|█████████▌| 957/1000 [03:31<00:08,  4.82it/s]Encodings MP Likelihood: 0.9024538076389438\n",
      "ELBO Loss: 561.3144380740056\n",
      "training:  96%|█████████▌| 958/1000 [03:31<00:08,  4.89it/s]Encodings MP Likelihood: 0.9585524577943643\n",
      "ELBO Loss: 560.2392609599145\n",
      "training:  96%|█████████▌| 959/1000 [03:31<00:08,  4.90it/s]Encodings MP Likelihood: 1.71320960335254\n",
      "ELBO Loss: 561.8856238646075\n",
      "training:  96%|█████████▌| 960/1000 [03:31<00:08,  4.92it/s]Encodings MP Likelihood: 0.8214872513518999\n",
      "ELBO Loss: 562.1524205137856\n",
      "training:  96%|█████████▌| 961/1000 [03:32<00:08,  4.61it/s]Encodings MP Likelihood: 0.9514441848065587\n",
      "ELBO Loss: 561.1810690582038\n",
      "training:  96%|█████████▌| 962/1000 [03:32<00:08,  4.74it/s]Encodings MP Likelihood: 0.5258910539391723\n",
      "ELBO Loss: 559.3112809774345\n",
      "training:  96%|█████████▋| 963/1000 [03:32<00:07,  4.69it/s]Encodings MP Likelihood: 0.7093810441680148\n",
      "ELBO Loss: 559.781574386467\n",
      "training:  96%|█████████▋| 964/1000 [03:32<00:07,  4.80it/s]Encodings MP Likelihood: 0.952077578784964\n",
      "ELBO Loss: 559.2645588055707\n",
      "training:  96%|█████████▋| 965/1000 [03:32<00:07,  4.84it/s]Encodings MP Likelihood: 7.6799034361066205\n",
      "ELBO Loss: 566.528493777002\n",
      "training:  97%|█████████▋| 966/1000 [03:33<00:06,  4.92it/s]Encodings MP Likelihood: 1.4886084777652226\n",
      "ELBO Loss: 561.6190838746312\n",
      "training:  97%|█████████▋| 967/1000 [03:33<00:06,  4.94it/s]Encodings MP Likelihood: 2.8780318438854526\n",
      "ELBO Loss: 561.4798786549079\n",
      "training:  97%|█████████▋| 968/1000 [03:33<00:06,  4.95it/s]Encodings MP Likelihood: 0.9447656479702112\n",
      "ELBO Loss: 561.6916726736576\n",
      "training:  97%|█████████▋| 969/1000 [03:33<00:06,  4.97it/s]Encodings MP Likelihood: 0.893736123737575\n",
      "ELBO Loss: 562.3647837919377\n",
      "training:  97%|█████████▋| 970/1000 [03:33<00:06,  4.96it/s]Encodings MP Likelihood: 7.364313269033986\n",
      "ELBO Loss: 566.7258303095268\n",
      "training:  97%|█████████▋| 971/1000 [03:34<00:06,  4.34it/s]Encodings MP Likelihood: 2.9848364488144616\n",
      "ELBO Loss: 565.0354920856284\n",
      "training:  97%|█████████▋| 972/1000 [03:34<00:07,  4.00it/s]Encodings MP Likelihood: 1.3070479220175917\n",
      "ELBO Loss: 562.7600669124372\n",
      "training:  97%|█████████▋| 973/1000 [03:34<00:07,  3.80it/s]Encodings MP Likelihood: 0.6791209089281645\n",
      "ELBO Loss: 558.3902406358428\n",
      "training:  97%|█████████▋| 974/1000 [03:35<00:06,  3.78it/s]Encodings MP Likelihood: 0.8393972990383384\n",
      "ELBO Loss: 561.808051731926\n",
      "training:  98%|█████████▊| 975/1000 [03:35<00:06,  4.00it/s]Encodings MP Likelihood: 1.0927721378442796\n",
      "ELBO Loss: 558.4772572568984\n",
      "training:  98%|█████████▊| 976/1000 [03:35<00:05,  4.19it/s]Encodings MP Likelihood: 0.7626977293367397\n",
      "ELBO Loss: 558.6674027657787\n",
      "training:  98%|█████████▊| 977/1000 [03:35<00:05,  4.32it/s]Encodings MP Likelihood: 1.1652824248690077\n",
      "ELBO Loss: 561.4059298643441\n",
      "training:  98%|█████████▊| 978/1000 [03:35<00:04,  4.42it/s]Encodings MP Likelihood: 0.5475673482390934\n",
      "ELBO Loss: 560.412112214494\n",
      "training:  98%|█████████▊| 979/1000 [03:36<00:04,  4.45it/s]Encodings MP Likelihood: 2.1027924000588234\n",
      "ELBO Loss: 562.0719724591964\n",
      "training:  98%|█████████▊| 980/1000 [03:36<00:04,  4.50it/s]Encodings MP Likelihood: 1.4309635749582184\n",
      "ELBO Loss: 564.737890357641\n",
      "training:  98%|█████████▊| 981/1000 [03:36<00:04,  4.51it/s]Encodings MP Likelihood: 0.2073063849737378\n",
      "ELBO Loss: 561.5866201266872\n",
      "training:  98%|█████████▊| 982/1000 [03:36<00:03,  4.62it/s]Encodings MP Likelihood: 1.812271230579774\n",
      "ELBO Loss: 563.4181983668261\n",
      "training:  98%|█████████▊| 983/1000 [03:37<00:03,  4.74it/s]Encodings MP Likelihood: 1.2679555378256704\n",
      "ELBO Loss: 564.2432889137655\n",
      "training:  98%|█████████▊| 984/1000 [03:37<00:03,  4.88it/s]Encodings MP Likelihood: 0.8221462984224347\n",
      "ELBO Loss: 558.7445570304593\n",
      "training:  98%|█████████▊| 985/1000 [03:37<00:03,  4.96it/s]Encodings MP Likelihood: 1.2033764415791157\n",
      "ELBO Loss: 562.3123081052742\n",
      "training:  99%|█████████▊| 986/1000 [03:37<00:02,  4.99it/s]Encodings MP Likelihood: 2.5314650903951357\n",
      "ELBO Loss: 561.9805464407018\n",
      "training:  99%|█████████▊| 987/1000 [03:37<00:02,  5.03it/s]Encodings MP Likelihood: 1.9770575350107886\n",
      "ELBO Loss: 559.7983520509417\n",
      "training:  99%|█████████▉| 988/1000 [03:38<00:02,  5.02it/s]Encodings MP Likelihood: 1.389443899397246\n",
      "ELBO Loss: 558.2056918814379\n",
      "training:  99%|█████████▉| 989/1000 [03:38<00:02,  5.04it/s]Encodings MP Likelihood: 1.4354360191012399\n",
      "ELBO Loss: 560.7648105373243\n",
      "training:  99%|█████████▉| 990/1000 [03:38<00:01,  5.05it/s]Encodings MP Likelihood: 1.8191795249497418\n",
      "ELBO Loss: 561.3035277283419\n",
      "training:  99%|█████████▉| 991/1000 [03:38<00:01,  5.05it/s]Encodings MP Likelihood: 4.2443409017565\n",
      "ELBO Loss: 561.493282163593\n",
      "training:  99%|█████████▉| 992/1000 [03:38<00:01,  5.04it/s]Encodings MP Likelihood: 0.7105613955604954\n",
      "ELBO Loss: 560.4484033226769\n",
      "training:  99%|█████████▉| 993/1000 [03:39<00:01,  5.02it/s]Encodings MP Likelihood: 1.6712480109690782\n",
      "ELBO Loss: 563.7072432805863\n",
      "training:  99%|█████████▉| 994/1000 [03:39<00:01,  5.04it/s]Encodings MP Likelihood: 1.4467757206303646\n",
      "ELBO Loss: 561.1771409684811\n",
      "training: 100%|█████████▉| 995/1000 [03:39<00:00,  5.08it/s]Encodings MP Likelihood: 1.1094255504563626\n",
      "ELBO Loss: 560.5939956982788\n",
      "training: 100%|█████████▉| 996/1000 [03:39<00:00,  5.11it/s]Encodings MP Likelihood: 1.8233498903905265\n",
      "ELBO Loss: 561.3057705558718\n",
      "training: 100%|█████████▉| 997/1000 [03:39<00:00,  5.16it/s]Encodings MP Likelihood: 3.5478237530241272\n",
      "ELBO Loss: 564.0619979908829\n",
      "training: 100%|█████████▉| 998/1000 [03:39<00:00,  5.19it/s]Encodings MP Likelihood: 0.8522816743823435\n",
      "ELBO Loss: 560.7789625507204\n",
      "training: 100%|█████████▉| 999/1000 [03:40<00:00,  5.18it/s]Encodings MP Likelihood: 2.835477598087881\n",
      "ELBO Loss: 560.8728526758847\n",
      "computing elbo\n",
      "training: 100%|██████████| 1000/1000 [03:40<00:00,  4.54it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=n_epochs,\n",
    "              lr=lr\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Loss Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dashboard(trainer, treevae.encoder_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Posterior and MV imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance is 1.5378348446839363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "full_posterior = trainer.create_posterior(trainer.model, cas_dataset, trainer.clades,\n",
    "                                indices=np.arange(len(cas_dataset))\n",
    "                                         )\n",
    "error = mean_squared_error(full_posterior.get_latent(), leaves_z)\n",
    "print(\"the distance is {}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Missing Value imputation By Posterior Predictive sampling***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_l = np.mean(np.sum(glm.X, axis=1))\n",
    "\n",
    "# CascVI impitations\n",
    "imputed = {}\n",
    "imputed_z = {}\n",
    "imputed_gt = {}\n",
    "\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        imputed[n.name], imputed_z[n.name] = full_posterior.imputation_internal(n.name,\n",
    "                                                            give_mean=False,\n",
    "                                                            library_size=empirical_l\n",
    "                                                           )\n",
    "        imputed_gt[n.name] = glm.X[n.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed_X = [x for x in imputed.values()]\n",
    "imputed_X = np.array(imputed_X).reshape(-1, cas_dataset.X.shape[1])\n",
    "#plot_histograms(imputed_X, \"Histogram of CasscVI imputed gene expression data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CascVI Baseline 1 (MP Oracle)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CascVI impitations\n",
    "imputed_cascvi_1 = {}\n",
    "imputed_cascvi_1_z ={}\n",
    "\n",
    "for n in tree.traverse('levelorder'):\n",
    "    if not n.is_leaf():\n",
    "        _, imputed_cascvi_1_z[n.name] = full_posterior.imputation_internal(n.name,\n",
    "                                                                    give_mean=False,\n",
    "                                                                    library_size=empirical_l,\n",
    "                                                                    known_latent=leaves_z\n",
    "        )\n",
    "        mu_z = np.clip(a=np.exp(glm.W @ imputed_cascvi_1_z[n.name].cpu().numpy() + glm.beta),\n",
    "                        a_min=0,\n",
    "                        a_max=1e8\n",
    "                        )\n",
    "        samples = np.array([np.random.poisson(mu_z) for i in range(100)])\n",
    "        imputed_cascvi_1[n.name] = np.clip(a=np.mean(samples, axis=0),\n",
    "                                           a_min=0,\n",
    "                                           a_max=1e8\n",
    "                                           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CascVI Baseline 2 (Reconstruction of Averaged latent space)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_cascvi_2, imputed_cascvi_2_z, _ = avg_baseline_z(tree=tree,\n",
    "                                   model=treevae,\n",
    "                                   posterior=full_posterior,\n",
    "                                   weighted=False,\n",
    "                                   n_samples_z=1,\n",
    "                                   library_size=empirical_l,\n",
    "                                   gaussian=False,\n",
    "                                   use_cuda=True\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1: Unweighted Average of gene expression in Clade\n",
    "\n",
    "The simple idea here is to impute the value of an internal node, with the (un)weighted average of the gene expression values of the leaves, taking the query internal node as the root of the subtree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted = False\n",
    "imputed_avg = avg_weighted_baseline(tree, weighted, glm.X, rounding=True)\n",
    "\n",
    "#get internal nodes\n",
    "avg_X = np.array([x for x in imputed_avg.values()]).reshape(-1, glm.X.shape[1])\n",
    "internal_avg_X, _, _ = get_internal(avg_X, glm.mu, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2: (Un)weighted Average of decoded latent vectors, with scVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same averaging of the subtrees leaves in **Baseline 1**, only this time, the gene expression data is recovered with scVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2021-05-10 13:50:15,165] INFO - scvi.dataset.dataset | Remapping batch_indices to [0,N]\n",
      "[2021-05-10 13:50:15,167] INFO - scvi.dataset.dataset | Remapping labels to [0,N]\n"
     ]
    }
   ],
   "source": [
    "# anndata\n",
    "gene_dataset = GeneExpressionDataset()\n",
    "gene_dataset.populate_from_data(leaves_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecoderSCVI(\n",
       "  (px_decoder): FCLayers(\n",
       "    (fc_layers): Sequential(\n",
       "      (Layer 0): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=128, bias=True)\n",
       "        (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): None\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (px_scale_decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=1000, bias=True)\n",
       "    (1): Softmax(dim=-1)\n",
       "  )\n",
       "  (px_r_decoder): Linear(in_features=128, out_features=1000, bias=True)\n",
       "  (px_dropout_decoder): Linear(in_features=128, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "n_epochs =800\n",
    "use_batches = False\n",
    "\n",
    "vae = VAE(gene_dataset.nb_genes,\n",
    "                  n_batch=cas_dataset.n_batches * use_batches,\n",
    "                  n_hidden=128,\n",
    "                  n_layers=1,\n",
    "                  reconstruction_loss='poisson',\n",
    "                  n_latent=glm.latent,\n",
    "                  ldvae=ldvae\n",
    "              )\n",
    "\n",
    "if freeze:\n",
    "    new_weight = torch.from_numpy(glm.W).float()\n",
    "    new_bias = torch.from_numpy(glm.beta).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        vae.decoder.factor_regressor.fc_layers[0][0].weight = torch.nn.Parameter(new_weight)\n",
    "        vae.decoder.factor_regressor.fc_layers[0][0].bias = torch.nn.Parameter(new_bias)\n",
    "        \n",
    "    for param in vae.decoder.factor_regressor.fc_layers[0][0].parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "vae.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance between the Poisson and the NB means is 1463076.6425772563\n"
     ]
    }
   ],
   "source": [
    "px_scale, px_r, px_rate, px_dropout = vae.decoder.forward(vae.dispersion,\n",
    "                                        torch.from_numpy(leaves_z).float(),\n",
    "                                        torch.from_numpy(np.array([np.log(10000)])).float(),\n",
    "                                        None\n",
    "                                        )\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "if ldvae:\n",
    "    foo = np.clip(a=np.exp(px_r.detach().numpy()),\n",
    "            a_min=0,\n",
    "            a_max=5000\n",
    "    )\n",
    "    mse = mean_squared_error(mu, foo)\n",
    "else:\n",
    "    mse = mean_squared_error(mu, px_rate.detach().numpy())\n",
    "\n",
    "print(\"the distance between the Poisson and the NB means is {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training: 100%|██████████| 800/800 [00:48<00:00, 16.54it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer_scvi = UnsupervisedTrainer(model=vae,\n",
    "                              gene_dataset=gene_dataset,\n",
    "                              train_size=1.0,\n",
    "                              use_cuda=use_cuda,\n",
    "                              frequency=10,\n",
    "                              n_epochs_kl_warmup=200)\n",
    "\n",
    "# train scVI\n",
    "trainer_scvi.train(n_epochs=n_epochs, lr=1e-3) \n",
    "                                        \n",
    "elbo_train_scvi = trainer_scvi.history[\"elbo_train_set\"]\n",
    "x = np.linspace(0, 100, (len(elbo_train_scvi)))\n",
    "plt.plot(np.log(elbo_train_scvi), \n",
    "         label=\"train\", color='blue',\n",
    "         linestyle=':',\n",
    "         linewidth=3\n",
    "        )\n",
    "        \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.legend()\n",
    "plt.title(\"Train history scVI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the distance is 8.892578060195763\n"
     ]
    }
   ],
   "source": [
    "scvi_posterior = trainer_scvi.create_posterior(model=vae,\n",
    "                                               gene_dataset=gene_dataset \n",
    "                                                )\n",
    "\n",
    "error = mean_squared_error(scvi_posterior.get_latent()[0], leaves_z)\n",
    "print(\"the distance is {}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***scVI Baseline 2 (Decoded Average Latent space)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_size = np.mean(np.sum(glm.X, axis=1))\n",
    "scvi_latent = np.array([scvi_posterior.get_latent(give_mean=False)[0] for i in range(10)])\n",
    "\n",
    "imputed_scvi_2, imputed_scvi_2_z = scvi_baseline_z(tree,\n",
    "                                        posterior=scvi_posterior,\n",
    "                                        model=vae,\n",
    "                                        weighted=False,\n",
    "                                        n_samples_z=1,\n",
    "                                        library_size=library_size,\n",
    "                                        use_cuda=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Likelihood Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((500, 10), (500, 10))"
      ]
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "source": [
    "cascvi_latent = full_posterior.get_latent()\n",
    "scvi_latent = scvi_posterior.get_latent()[0]\n",
    "\n",
    "scvi_latent.shape, cascvi_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood of scVI encodings:  -89983.96007352648\n"
     ]
    }
   ],
   "source": [
    "treevae.initialize_visit()\n",
    "treevae.initialize_messages(scvi_latent, cas_dataset.barcodes, scvi_latent.shape[1])\n",
    "treevae.perform_message_passing((treevae.tree & treevae.root), scvi_latent.shape[1], False)\n",
    "mp_lik_scvi = treevae.aggregate_messages_into_leaves_likelihood(d, add_prior=True)\n",
    "print(\"Likelihood of scVI encodings: \", mp_lik_scvi.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood of cascVI encodings:  -3151.64372982798\n"
     ]
    }
   ],
   "source": [
    "treevae.initialize_visit()\n",
    "treevae.initialize_messages(cascvi_latent, cas_dataset.barcodes, cascvi_latent.shape[1])\n",
    "treevae.perform_message_passing((treevae.tree & treevae.root), cascvi_latent.shape[1], False)\n",
    "mp_lik_cascvi = treevae.aggregate_messages_into_leaves_likelihood(d, add_prior=True)\n",
    "print(\"Likelihood of cascVI encodings: \", mp_lik_cascvi.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood of observations:  -11128.761668907146\n"
     ]
    }
   ],
   "source": [
    "treevae.initialize_visit()\n",
    "treevae.initialize_messages(leaves_z, cas_dataset.barcodes, cascvi_latent.shape[1])\n",
    "treevae.perform_message_passing((treevae.tree & treevae.root), cascvi_latent.shape[1], False)\n",
    "mp_lik_cascvi = treevae.aggregate_messages_into_leaves_likelihood(d, add_prior=True)\n",
    "print(\"Likelihood of observations: \", mp_lik_cascvi.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Likelihood Ratio: tensor(78855.1984, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Likelihood ratio\n",
    "lambda_ = (mp_lik_cascvi - mp_lik_scvi)\n",
    "print(\"Likelihood Ratio:\", lambda_)"
   ]
  },
  {
   "source": [
    "# 6. Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CPM Normalization (for sample-sample correlation)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get imputations into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((500, 1000), (500, 1000), (500, 1000), (500, 1000), (500, 1000), (500, 1000))"
      ]
     },
     "metadata": {},
     "execution_count": 187
    }
   ],
   "source": [
    "internal_scvi_X_2 = np.array([x for x in imputed_scvi_2.values()]).reshape(-1, glm.X.shape[1])\n",
    "internal_cascvi_X = np.array([x for x in imputed_cascvi_1.values()]).reshape(-1, glm.X.shape[1])\n",
    "internal_cascvi_X_2 = np.array([x for x in imputed_cascvi_2.values()]).reshape(-1, glm.X.shape[1])\n",
    "\n",
    "internal_cascvi_X_2.shape, internal_cascvi_X.shape, internal_scvi_X_2.shape, imputed_X.shape, internal_avg_X.shape, internal_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(500, 1000)"
      ]
     },
     "metadata": {},
     "execution_count": 188
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "norm_internal_X = sc.pp.normalize_total(AnnData(internal_X), target_sum=1e4, inplace=False)['X'] \n",
    "norm_scvi_X_2 = sc.pp.normalize_total(AnnData(internal_scvi_X_2), target_sum=1e4, inplace=False)['X']\n",
    "norm_avg_X = sc.pp.normalize_total(AnnData(internal_avg_X), target_sum=1e4, inplace=False)['X']\n",
    "norm_imputed_X = sc.pp.normalize_total(AnnData(imputed_X), target_sum=1e4, inplace=False)['X']\n",
    "norm_cascvi_X = sc.pp.normalize_total(AnnData(internal_cascvi_X), target_sum=1e4, inplace=False)['X']\n",
    "norm_cascvi_X_2 = sc.pp.normalize_total(AnnData(internal_cascvi_X_2), target_sum=1e4, inplace=False)['X']\n",
    "\n",
    "norm_internal_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((0.713590996797604, 5.38753823209405e-79),\n",
       " KendalltauResult(correlation=0.47277619054185444, pvalue=6.927823772966586e-45))"
      ]
     },
     "metadata": {},
     "execution_count": 189
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "data0 = internal_X[:, 0]\n",
    "data1 = imputed_X[:, 0]\n",
    "\n",
    "stats.pearsonr(data1, data0), stats.kendalltau(data1, data0), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Sample-Sample Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1. Sample-Sample correlation (Without Normalization)***\n",
    "\n",
    "We will use Scipy to compute a nonparametric rank correlation between the imputed and the groundtruth profiles. The correlation is based on the Spearman Correlation Coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {'groundtruth': internal_X.T, 'cascVI': imputed_X.T, 'scVI': internal_scvi_X_2.T,\n",
    "        'Average': internal_avg_X.T , 'cascVI + Avg': internal_cascvi_X_2.T,\n",
    "        'MP Oracle': internal_cascvi_X.T\n",
    "        }\n",
    "df1 = correlations(data, 'None', True)\n",
    "df1.head(5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2. Sample-Sample correlation (With ScanPy Normalization)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/external/utils/metrics.py:90: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n  fig, axes = plt.subplots(1, 3, figsize=(20, 5), sharey=True)\n"
     ]
    }
   ],
   "source": [
    "data = {'groundtruth': norm_internal_X.T, 'cascVI': norm_imputed_X.T, 'scVI': norm_scvi_X_2.T, \n",
    "        'Average': norm_avg_X.T , 'cascVI + Avg': norm_cascvi_X_2.T,\n",
    "        'MP Oracle': norm_cascvi_X.T\n",
    "        }\n",
    "\n",
    "df2 = correlations(data, 'None', True)\n",
    "df2.head(5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## II. Gene-Gene Correlations"
   ]
  },
  {
   "source": [
    "***2. Gene-Gene correlation (With Normalization)***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:4264: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(SpearmanRConstantInputWarning())\n/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "data = {'groundtruth': internal_X, 'cascVI': imputed_X, 'scVI': internal_scvi_X_2,\n",
    "        'Average': internal_avg_X , 'cascVI + Avg': internal_cascvi_X_2,\n",
    "        'MP Oracle': internal_cascvi_X\n",
    "        }\n",
    "\n",
    "df3 = correlations(data, 'None', True)\n",
    "df3.head(5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2. Gene-Gene correlation (With Normalization)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:4264: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(SpearmanRConstantInputWarning())\n/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "data = {'groundtruth': norm_internal_X, 'cascVI': norm_imputed_X, 'scVI': norm_scvi_X_2, \n",
    "        'Average': norm_avg_X , 'cascVI + Avg': norm_cascvi_X_2,\n",
    "        'MP Oracle': norm_cascvi_X\n",
    "        }\n",
    "\n",
    "df4 = correlations(data, 'None', True)\n",
    "df4.head(5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***3. Gene-Gene correlation (With Rank Normalization)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:4264: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(SpearmanRConstantInputWarning())\n/home/eecs/khalil.ouardini/miniconda3/envs/scvi-env/lib/python3.7/site-packages/scipy/stats/stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "#data = {'groundtruth': norm_internal_X, 'cascVI': norm_imputed_X, 'scVI': norm_scvi_X_2, \n",
    "#        'Average': norm_avg_X , 'cascVI + Avg': norm_cascvi_X_2,\n",
    "#        'MP Oracle': norm_cascvi_X\n",
    "#        }\n",
    "\n",
    "data = {'groundtruth': internal_X, 'cascVI': imputed_X, 'scVI': internal_scvi_X_2,\n",
    "        'Average': internal_avg_X , 'cascVI + Avg': internal_cascvi_X_2,\n",
    "        'MP Oracle': internal_cascvi_X\n",
    "        }\n",
    "        \n",
    "df5 = correlations(data, 'rank', True)\n",
    "df5.head(5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Table Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Method\", \"Spearman CC\", \"Pearson CC\", \"Kendall Tau\"]\n",
    "data = [df1, df2, df3, df4, df5]\n",
    "#data = [df2, df4]\n",
    "\n",
    "data \n",
    "tables = [[] for i in range(len(data))]\n",
    "\n",
    "#task = [\"Sample-Sample (None)\", \"Sample-Sample (CPM)\", \"Gene-Gene (None)\", \n",
    "           #\"Gene-Gene(CPM)\", \"Gene-Gene (Rank)\" ]\n",
    "\n",
    "for (df, t) in zip(data, tables):\n",
    "    for m in np.unique(df.Method):\n",
    "        sub_df = np.round(df[df['Method'] == m].mean(), decimals=3)\n",
    "        t.append([m, sub_df['Spearman CC'], sub_df['Pearson CC'], sub_df['Kendall Tau']])\n",
    "        \n",
    "# Create and style Data Frames\n",
    "df_table1 = pd.DataFrame(tables[0], columns=columns)\n",
    "df_table2 = pd.DataFrame(tables[1], columns=columns)\n",
    "df_table3 = pd.DataFrame(tables[2], columns=columns)\n",
    "df_table4 = pd.DataFrame(tables[3], columns=columns)\n",
    "df_table5 = pd.DataFrame(tables[4], columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " >>> Sample-Sample | No Normalization <<<\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Method  Spearman CC  Pearson CC  Kendall Tau\n",
       "0       Average        0.904       0.944        0.824\n",
       "1     MP Oracle        0.913       0.969        0.801\n",
       "2        cascVI        0.911       0.966        0.795\n",
       "3  cascVI + Avg        0.906       0.945        0.790\n",
       "4          scVI        0.904       0.936        0.784"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendall Tau</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Average</td>\n      <td>0.904</td>\n      <td>0.944</td>\n      <td>0.824</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MP Oracle</td>\n      <td>0.913</td>\n      <td>0.969</td>\n      <td>0.801</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cascVI</td>\n      <td>0.911</td>\n      <td>0.966</td>\n      <td>0.795</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cascVI + Avg</td>\n      <td>0.906</td>\n      <td>0.945</td>\n      <td>0.790</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scVI</td>\n      <td>0.904</td>\n      <td>0.936</td>\n      <td>0.784</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 196
    }
   ],
   "source": [
    "print(\" >>> Sample-Sample | No Normalization <<<\")\n",
    "df_table1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> Sample-Sample | CPM Normalization <<<\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Method  Spearman CC  Pearson CC  Kendall Tau\n",
       "0       Average        0.904       0.944        0.824\n",
       "1     MP Oracle        0.913       0.969        0.801\n",
       "2        cascVI        0.911       0.966        0.795\n",
       "3  cascVI + Avg        0.906       0.945        0.790\n",
       "4          scVI        0.904       0.936        0.784"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendall Tau</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Average</td>\n      <td>0.904</td>\n      <td>0.944</td>\n      <td>0.824</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MP Oracle</td>\n      <td>0.913</td>\n      <td>0.969</td>\n      <td>0.801</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cascVI</td>\n      <td>0.911</td>\n      <td>0.966</td>\n      <td>0.795</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cascVI + Avg</td>\n      <td>0.906</td>\n      <td>0.945</td>\n      <td>0.790</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scVI</td>\n      <td>0.904</td>\n      <td>0.936</td>\n      <td>0.784</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 197
    }
   ],
   "source": [
    "print(\">>> Sample-Sample | CPM Normalization <<<\")\n",
    "df_table2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> Gene-Gene | No Normalization <<<\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Method  Spearman CC  Pearson CC  Kendall Tau\n",
       "0       Average        0.620       0.680        0.529\n",
       "1     MP Oracle        0.666       0.746        0.551\n",
       "2        cascVI        0.586       0.569        0.460\n",
       "3  cascVI + Avg        0.570       0.542        0.446\n",
       "4          scVI        0.534       0.427        0.413"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendall Tau</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Average</td>\n      <td>0.620</td>\n      <td>0.680</td>\n      <td>0.529</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MP Oracle</td>\n      <td>0.666</td>\n      <td>0.746</td>\n      <td>0.551</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cascVI</td>\n      <td>0.586</td>\n      <td>0.569</td>\n      <td>0.460</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cascVI + Avg</td>\n      <td>0.570</td>\n      <td>0.542</td>\n      <td>0.446</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scVI</td>\n      <td>0.534</td>\n      <td>0.427</td>\n      <td>0.413</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 198
    }
   ],
   "source": [
    "print(\">>> Gene-Gene | No Normalization <<<\")\n",
    "df_table3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> Gene-Gene | CPM Normalization <<<\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Method  Spearman CC  Pearson CC  Kendall Tau\n",
       "0       Average        0.614       0.674        0.504\n",
       "1     MP Oracle        0.654       0.735        0.529\n",
       "2        cascVI        0.646       0.718        0.520\n",
       "3  cascVI + Avg        0.630       0.692        0.503\n",
       "4          scVI        0.604       0.590        0.479"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendall Tau</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Average</td>\n      <td>0.614</td>\n      <td>0.674</td>\n      <td>0.504</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MP Oracle</td>\n      <td>0.654</td>\n      <td>0.735</td>\n      <td>0.529</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cascVI</td>\n      <td>0.646</td>\n      <td>0.718</td>\n      <td>0.520</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cascVI + Avg</td>\n      <td>0.630</td>\n      <td>0.692</td>\n      <td>0.503</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scVI</td>\n      <td>0.604</td>\n      <td>0.590</td>\n      <td>0.479</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 199
    }
   ],
   "source": [
    "print(\">>> Gene-Gene | CPM Normalization <<<\")\n",
    "df_table4.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> Gene-Gene | Rank Normalization <<<\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Method  Spearman CC  Pearson CC  Kendall Tau\n",
       "0       Average        0.620       0.620        0.529\n",
       "1     MP Oracle        0.666       0.666        0.551\n",
       "2        cascVI        0.586       0.586        0.460\n",
       "3  cascVI + Avg        0.570       0.570        0.446\n",
       "4          scVI        0.534       0.534        0.413"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Spearman CC</th>\n      <th>Pearson CC</th>\n      <th>Kendall Tau</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Average</td>\n      <td>0.620</td>\n      <td>0.620</td>\n      <td>0.529</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MP Oracle</td>\n      <td>0.666</td>\n      <td>0.666</td>\n      <td>0.551</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cascVI</td>\n      <td>0.586</td>\n      <td>0.586</td>\n      <td>0.460</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cascVI + Avg</td>\n      <td>0.570</td>\n      <td>0.570</td>\n      <td>0.446</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scVI</td>\n      <td>0.534</td>\n      <td>0.534</td>\n      <td>0.413</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "print(\">>> Gene-Gene | Rank Normalization <<<\")\n",
    "df_table5.head(10)"
   ]
  },
  {
   "source": [
    "# 8. Latent Space Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***cascVI***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge internal nodes and leaves\n",
    "#full_cascvi_latent = construct_latent(tree, cascvi_latent, imputed_z)\n",
    "\n",
    "\n",
    "#print(\"CascVI latent space\")\n",
    "#plot_common_ancestor(tree,\n",
    "#                     full_cascvi_latent,\n",
    "#                     embedding='umap',\n",
    "#                     give_labels=False\n",
    "#                             )"
   ]
  },
  {
   "source": [
    "***CascVI + avg***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_cascvi_latent_2 = construct_latent(tree, cascvi_latent, imputed_cascvi_2_z)\n",
    "\n",
    "#print(\"CascVI + averaging latent space\")\n",
    "#plot_common_ancestor(tree,\n",
    "#                     full_cascvi_latent_2,\n",
    "#                     embedding='umap',\n",
    "#                     give_labels=False\n",
    "#                             )"
   ]
  },
  {
   "source": [
    "***scVI***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge internal nodes and leaves\n",
    "#full_scvi_latent = construct_latent(tree, scvi_latent, imputed_scvi_2_z)\n",
    "\n",
    "#print(\"scVI latent space\")\n",
    "#plot_common_ancestor(tree,\n",
    " #                full_scvi_latent,\n",
    " #                embedding='umap',\n",
    " #                give_labels=False\n",
    " #                   )"
   ]
  },
  {
   "source": [
    "### k-NN purity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***LEAVES only***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Leaves Only\")\n",
    "#data = {'groundtruth': leaves_z, 'scVI': scvi_latent,\n",
    "#        'cascVI': cascvi_latent\n",
    "#        }\n",
    "#scores = knn_purity(max_neighbors=50,\n",
    "#                    data=data,\n",
    "#                    plot=True,\n",
    "#                    save_fig='/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/tmp'\n",
    "#                    )"
   ]
  },
  {
   "source": [
    "*** Internal nodes only***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Internal nodes Only\")\n",
    "#internal_z, internal_idx, internal_mu = get_internal(glm.z, glm.mu, tree)\n",
    "#internal_scvi_z, _, _ = get_internal(full_scvi_latent, glm.mu, tree)\n",
    "#internal_cascvi_z, _, _ = get_internal(full_cascvi_latent, glm.mu, tree)\n",
    "#internal_cascvi_z_2, _, _ = get_internal(full_cascvi_latent_2, glm.mu, tree)\n",
    "\n",
    "#data = {'groundtruth': internal_z, 'scVI + avg': internal_scvi_z,\n",
    "#        'cascVI': internal_cascvi_z, 'cascVI + avg': internal_cascvi_z_2\n",
    "#        }\n",
    "\n",
    "#scores = knn_purity(max_neighbors=50,\n",
    "#              data=data,\n",
    "#              plot=True,\n",
    "#              save_fig='/home/eecs/khalil.ouardini/Cassiopeia_Transcriptome/scvi/tmp/'\n",
    "#              )"
   ]
  },
  {
   "source": [
    "***Full tree***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Full tree\")\n",
    "#data = {'groundtruth': glm.z, 'scVI + avg': full_scvi_latent,\n",
    "#        'cascVI': full_cascvi_latent, 'cascVI + avg': full_cascvi_latent_2\n",
    "#        }\n",
    "#scores = knn_purity(max_neighbors=50,\n",
    "#              data=data,\n",
    "#              plot=True)"
   ]
  },
  {
   "source": [
    "***Stratified k-NN purity***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = {'groundtruth': glm.z, 'scVI + avg': full_scvi_latent,\n",
    "#        'cascVI': full_cascvi_latent, 'cascVI + avg': full_cascvi_latent_2\n",
    "#        }\n",
    "\n",
    "#for k in [2, 5, 10, 20, 35, 50]:\n",
    "#    print(\"For {} neighbors\".format(k))\n",
    "#    if k == 10:\n",
    "#        min_depth = 3\n",
    "#    elif k == 20:\n",
    "#        min_depth = 4\n",
    "#    elif k == 35:\n",
    "#        min_depth = 6\n",
    "#    elif k == 50:\n",
    "#        min_depth = 7\n",
    "#    else:\n",
    "#        min_depth = 2\n",
    "#    scores = knn_purity_stratified(n_neighbors=k,\n",
    "#                                   tree=tree,\n",
    "#                                   data=data,\n",
    "#                                   min_depth=min_depth,\n",
    "#                                   plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd08038a79804d646dd36b3762b0d60c87c86d89e40c61f6758cc1d2f18aca59864",
   "display_name": "Python 3.7  ('scvi-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "8038a79804d646dd36b3762b0d60c87c86d89e40c61f6758cc1d2f18aca59864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}